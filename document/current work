1. 当前应该把重点放在处理ocnli和tnews数据集上，两个数据集都有提升的可能，！！！！！

数据增强：1.eda：考虑多少数据采用，尤其是低数据量
        2.翻译工具：将语句翻译成外文，在进行回译
        3.对于异常数据进行处理


分析：
    考虑对ocnli的第二个数据进行回译增加数据样本
    eda增加样本，





数据分析：
https://zhuanlan.zhihu.com/p/49745985
目前最重要任务：一个是数据的初步处理，另一个就是考虑数据的分布，多样性，均衡性，复杂性等来对数据分布进行调整
在一个就是采用知识蒸馏的方式来进行模型的构建。
类别多样性： 考虑增加类别数据量的方法
类别干扰：过滤噪声，切割文本，重新标注，
类别不平衡：扩充数据，基于词库的方法，词向量扰动的方法。 欠采样或过采样技术，可以进行迁移学习的方法来进行学习
最好的方法是采用这篇文章的方法来对数据集进行测评，衡量数据集难度。
跑完最好的分析一下

2020 12 22
模型层面的考虑
https://github.com/codedecde/Recognizing-Textual-Entailment
work: 考虑文本蕴含采用BERT+LSTM实现，首先进行第一个方式， 这个方式暂时不考虑
            具体分开两个ocnli的两个string,否则不容易做数据分开， 做这个方式的，
      其余两个文本任务可以考虑使用BERT作为句向量的方式实现。
构建RTE任务的模型，2-LSTM + attention的尝试，模型层面的尝试
今天晚上确定获取词向量的方式，然后构建好三个任务的LSTM任务分类模型
效果一般

2020 12 24
学会如何可视化训练过程，然后分析
1.可视化loss

2020 12 25
重点：一定要有耐心，每次的尝试都能清楚该变量是什么
可以不断尝试拿出bert不同层次的state结果来进行分类
重点放在数据层面的优化和loss的优化上面。
以及调参，这个才是重点。


2020 12 26尝试对loss函数进行调整。
目前对loss进行有两个可行方案，
一个是控制loss的更新速率保持一致
GradNorm 方法   效果未曾看出来但是实在是loss更新太慢，将速度限制太慢，无法满足要求，待定 20201228
UW方法   明天尝试
另一个是仍然采用kpi方法，但是将准确率换成F1值的更新，因为我们最终测度还是F1值，loss的更新会更加客观。  效果很不好

尝试对数据进行数据处理，就是那些噪声数据

2020 12 27
新的一个思路
修改bert的输出层数，以及融合的新的token表示方式  效果一般，单独输出还是最后一层比较好
递进式修改学习率进行学习率
固定embedding层，然后尝试输出，用最后一层进行训练  无法有效的降低valid loss，基本一个epoch之后就已经要过拟合了，可以看出更容易过拟合效果一般
固定整个bert层，然后接全连接层，前面层不进行训练
处理类别不均匀问题  focal loss  泛化效果一般
处理脏数据的方法,
    考虑这样一个套路将之前训练过的数据经过模型的计算后，得出噪声和难以处理的，然后将这样的数据处理，在送入只经过容易样本训练的模型中。
    采用cleanlab工具对标签数据进行置信学习
可以尝试剔除一些层数，比如剔除dropout层
尝试将新的tnews数据放入模型中进行训练。
将回译得出的结果放入模型中参与训练

2020 12 28
修改轮次的学习率不断调整达到最优点，只是寻找模型的最优点，实际并没有修改什么结果。 验证集效果有提升，但是测试集没有很好
对训练好的模型再在完整数据集（包括验证集和训练集）上用小的学习率训练一个epoch

总结：
    意识到如果想达到更高的结果，必须处理数据问题，或者模型，目前模型的最高效果应该无法提高2个点。在查看当前最优模型，发现ocemotion任务很难取得一个
    的F1值，基本变动很小，然后ocnli 任务变动幅度2个点左右，tnews变化辅导不到3个点，
    ocemotion任务很容易在初始F1值较为可观，但是基本一直在下降，除却数据问题，基本很难改变。
    存在一个问题，无法有一个性能的更好的突破

    数据层面工具： 数据噪声处理， 回译法进行数据增强
    模型层面：考虑再次叠加多个预训练模型，考虑学习率问题， 逐层考虑不同学习率
    loss优化方面，考虑自己优化损失函数

    先考虑文本增强在进行噪声处理
    数据的噪声处理，发现一个问题，同一个模型对于同一个验证集存在很大程度的相似性，所以考虑排除噪声数据的时候采取多个模型共同给出决策，这里可以采用多次
    不同训练的模型，也可以，但是最好尝试不同的模型，增加多样性。

2020 12 29  今天这个跑出结果
这个方法主要剔除标注错误的数据，也就是所谓的脏样本，所以可考虑采用多个分开分类器进行训练。
尝试方法重新训练三个分类器，这次tnews不使用外部数据，然后进行分类处理，
多次训练出5个训练器，然后对训练数据进行5次预测选出决策错误的数据，然后将数据标出来，导出文件。


2020 12 31
回译效果很不好，出现严重过拟合问题，接下来应该好好理解数据，分析如下：
对于分类问题，考虑数据的四个属性：类别干扰，类别多样性，类别均衡，数据复杂性。（数据噪声同样会对分类结果产生干扰，但是对于噪声的处理成本较高，暂时不做
处理，有过尝试，但是时间成本较高）

类别多样性，通过分析，分类种类，增加，类别特性，干脆点说就是某些类别的数据特征较少，无法有效的被分类器学习到
类别均衡：平衡数据集不一定是一个很好的选择，这可能会改变原有的数据分布，也就是改变了事实。 目前在尝试的方法： focal loss, 回译， metacost
数据复杂性：算了吧
类别干扰：这个可以尝试进行使用，

202 1 1分析数据集ocemotion, tnews 发现了一些数据存在特征不明的问题，需要处理
可以从两个角度考虑
一个是数据层面
欠采样：可能改变原有的数据分布
过采样：
正则化：
三者同时进行
对抗扰动：有一定效果
另一个就是损失层面，考虑对应不同数据分错的数据惩罚。

2021 1 4 损失层面尝试有效果，经过两次尝试，发现损失差距必须足够大才会有效果，也就是说，去掉math.log函数，换成新的函数，使得前期的差距和后面的差距
保证在同一个层面
换成下面函数
    不断获取当前精确度然后考虑减去最小值，放大，差距值


2021 1 4
看样我还是理解错误了，对于一个由数据，模型，优化构成的任务来说，数据不变动的情况，模型决定了你的拟合结果，也就是说你的上限，优化器或者说优化算法只是会
帮助你更好的寻找到最优的结果，也就是最优的泛化结果，但是注意这是基于模型来说的，所以在数据相同的情况下，模型决定了你的结果上线。优化只是会决定你的迭代
是否更快的找到一个最优点。但是实际你的最优点已经被你的模型所决定了。
所以我最大的失误就是这个比赛没有尝试去进行预训练啊。
今天晚上看能不能预训练一下，这样还可以训练1天，明天晚上进行的测试。 机器不够用，算了吧






