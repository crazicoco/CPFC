Parameters:
root    :    /share/home/crazicoco/competition/CPFC
vocabIdName    :    vocab.txt
tokenizeModel    :    hfl/chinese-roberta-wwm-ext-large
pretrainModel    :    hfl/chinese-roberta-wwm-ext-large
saveModelAddress    :    saveModelBin/
processedDataDir    :    preprocessed_data
saveLabelIdName    :    label.pt
saveTrainIdName    :    train.pt
saveValidIdName    :    valid.pt
saveTestIdName    :    test.pt
batch_size    :    9
epoch_size    :    20
loss_calculate    :    cross-entroy
lr    :    2e-05
device    :    0
max_len    :    512
lossCalculateWay    :    general
accumulate    :    True
ifparallel    :    True
debug    :    False
logfileName    :    public
a_step    :    16
description    :    use the -2 layer cls representation
record_addr    :    /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_27_8_6
*********************************************train model**************************************
current epoch:0
[ 1000 - th batch: valid loss is 6.562162 valid total precise is 0.332777 ]
[ 2000 - th batch: valid loss is 4.719025 valid total precise is 0.409983 ]
[ 3000 - th batch: valid loss is 3.862326 valid total precise is 0.455819 ]
[ 4000 - th batch: valid loss is 3.338207 valid total precise is 0.486927 ]
[ 5000 - th batch: valid loss is 2.976528 valid total precise is 0.511147 ]
[ 6000 - th batch: valid loss is 2.716542 valid total precise is 0.526773 ]
[ 7000 - th batch: valid loss is 2.517670 valid total precise is 0.538871 ]
[ 8000 - th batch: valid loss is 2.361345 valid total precise is 0.549527 ]
[ 9000 - th batch: valid loss is 2.234123 valid total precise is 0.557519 ]
[ 10000 - th batch: valid loss is 2.125724 valid total precise is 0.565657 ]
[ 11000 - th batch: valid loss is 2.036335 valid total precise is 0.571799 ]
[ 12000 - th batch: valid loss is 1.957949 valid total precise is 0.577844 ]
[ 13000 - th batch: valid loss is 1.892548 valid total precise is 0.582669 ]
[ 14000 - th batch: valid loss is 1.834208 valid total precise is 0.586494 ]
[ 15000 - th batch: valid loss is 1.781864 valid total precise is 0.590187 ]
The epoch:0,marcoF1ScoresOcemotion:0.446323
********************************confusion_matrix********************************
[[1209  325    8  438   65 1720   18]
 [ 421 1269   10  578   93 1643   17]
 [  25   23  149   50   25  275    1]
 [ 201  244    7 5750  532 1450   16]
 [  88   65   10 1100 1429 1037    5]
 [ 640  454   27 1051  387 8988   21]
 [  81   73    2  206   44  331   93]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.45      0.32      0.38      3783
           1       0.52      0.31      0.39      4031
           2       0.70      0.27      0.39       548
           3       0.63      0.70      0.66      8200
           4       0.55      0.38      0.45      3734
           5       0.58      0.78      0.67     11568
           6       0.54      0.11      0.19       830

    accuracy                           0.58     32694
   macro avg       0.57      0.41      0.45     32694
weighted avg       0.57      0.58      0.56     32694

The epoch:0,marcoF1ScoresOcnli:0.663303
********************************confusion_matrix********************************
[[11159  3862  1694]
 [ 3601 10685  2998]
 [ 1677  3195 11516]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.68      0.67      0.67     16715
           1       0.60      0.62      0.61     17284
           2       0.71      0.70      0.71     16388

    accuracy                           0.66     50387
   macro avg       0.66      0.66      0.66     50387
weighted avg       0.66      0.66      0.66     50387

The epoch:0,marcoF1ScoresTnews:0.523252
********************************confusion_matrix********************************
[[ 532  130  227    7   21   18   24   45   55   16   28   65    0   80
    18]
 [  51 2619  427   49   88   25   21  293  231   81  398  120    0  136
    53]
 [ 180  463 3373  246   57   22   60  146  320   99   95  200    0   75
   270]
 [   9  103  433 3023   75   12   76  113  171   67   81  118    0   22
   234]
 [  10   91   71   48 2809  272  163  186 1352   68  120  306   29  299
    57]
 [  16   64   31   12  308 1355   48   74  149    6  156   46    0   94
     7]
 [  25   78  156   53  193   36 2952   69  505   81  259  132    0   70
    66]
 [  33  331  177   93  128   55   39 2260  337   59  102  110    0  101
    58]
 [   6   76  143   51 1311   88  404  236 3611  158   68  187    4   71
   274]
 [  15  138  134   61   74    7   88   97  251 1935   81 1067    0   39
   141]
 [  32  437  139   47  112   98  183  113  220   47 1756  377    0  272
    43]
 [  70  115  309  104  265   36  106  131  336  814  298 2742    0   99
    45]
 [   0    0    0    2  235    4    1    0   16    0    1    0   30    1
     0]
 [  85  190   68   17  305  113   53  119  197   34  293   97    0 1638
    22]
 [  16   88  407  203   35    5   49   65  441  135   42   43    0   35
  2307]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.49      0.42      0.45      1266
           1       0.53      0.57      0.55      4592
           2       0.55      0.60      0.58      5606
           3       0.75      0.67      0.71      4537
           4       0.47      0.48      0.47      5881
           5       0.63      0.57      0.60      2366
           6       0.69      0.63      0.66      4675
           7       0.57      0.58      0.58      3883
           8       0.44      0.54      0.49      6688
           9       0.54      0.47      0.50      4128
          10       0.46      0.45      0.46      3876
          11       0.49      0.50      0.49      5470
          12       0.48      0.10      0.17       290
          13       0.54      0.51      0.52      3231
          14       0.64      0.60      0.62      3871

    accuracy                           0.55     60360
   macro avg       0.55      0.51      0.52     60360
weighted avg       0.55      0.55      0.55     60360

The epoch:0,marcoF1ScoresTotal:0.544293
*********************************************start valid model**************************************
[ 1000 - th batch: valid loss is 0.832353 valid total precise is 0.660661 ]
The epoch:0,marcoF1ScoresOcemotion:0.507708
********************************confusion_matrix********************************
[[130  21   1  36   9 131   4]
 [ 63 134   1  44   9 120   3]
 [  1   2  16   9   3  14   1]
 [ 22  19   1 582  48 108   1]
 [ 10   8   2  91 157  83   2]
 [ 63  42   7  70  42 812   0]
 [  8   9   0  19   1  22  19]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.44      0.39      0.41       332
           1       0.57      0.36      0.44       374
           2       0.57      0.35      0.43        46
           3       0.68      0.75      0.71       781
           4       0.58      0.44      0.50       353
           5       0.63      0.78      0.70      1036
           6       0.63      0.24      0.35        78

    accuracy                           0.62      3000
   macro avg       0.59      0.47      0.51      3000
weighted avg       0.61      0.62      0.60      3000

The epoch:0 ,marcoF1ScoresOcnli:0.798101
********************************confusion_matrix********************************
[[890  79  42]
 [175 715 111]
 [ 70 125 793]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.78      0.88      0.83      1011
           1       0.78      0.71      0.74      1001
           2       0.84      0.80      0.82       988

    accuracy                           0.80      3000
   macro avg       0.80      0.80      0.80      3000
weighted avg       0.80      0.80      0.80      3000

The epoch:0,marcoF1ScoresTnews:0.558076
********************************confusion_matrix********************************
[[ 31   9   5   0   2   0   0   6   0   1   0   1   0   3   2]
 [ 13 122  22   1   4   2   1  14   3   4  21   5   0  11   2]
 [ 16  31 154  11   2   3   2  13   7   7   8  11   0   3  12]
 [  1   5  17 166   5   1   5   7   4   1   2   3   0   0   4]
 [  4   5   2   1 101  17   6   7  89   2   4   7   8  20   2]
 [  1   1   0   1  14  71   2   8   7   1   9   1   0   3   0]
 [  5   3   4   3   6   3 148   5  32   1  11   7   1   2   3]
 [  5  20   5   5   7   1   1 114  21   4   1   5   0   9   2]
 [  0   2  10   3  40   3   9  15 224   9   2   8   1   7  23]
 [  2   5   6   4   3   0   4   8   9 121   2  45   0   3   8]
 [  3  15   8   5   3   5   6   8   4   4  93  12   0  19   0]
 [ 10  12  11   6   9   4   2   7  13  57  16 131   0   6   2]
 [  0   0   0   0   4   0   0   0   1   0   0   0   7   0   0]
 [  3   5   2   1  10   2   4   2   8   0   7   1   0 103   1]
 [  3   3  22   8   0   1   2   1  18   2   4   1   0   2 111]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.32      0.52      0.39        60
           1       0.51      0.54      0.53       225
           2       0.57      0.55      0.56       280
           3       0.77      0.75      0.76       221
           4       0.48      0.37      0.42       275
           5       0.63      0.60      0.61       119
           6       0.77      0.63      0.69       234
           7       0.53      0.57      0.55       200
           8       0.51      0.63      0.56       356
           9       0.57      0.55      0.56       220
          10       0.52      0.50      0.51       185
          11       0.55      0.46      0.50       286
          12       0.41      0.58      0.48        12
          13       0.54      0.69      0.61       149
          14       0.65      0.62      0.63       178

    accuracy                           0.57      3000
   macro avg       0.56      0.57      0.56      3000
weighted avg       0.57      0.57      0.57      3000

The epoch:0,marcoF1ScoresTotal:0.621295
save the pretrainModel in /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_27_8_6/save_model/roberta_best_dev_f1_0.6212952563875197.pt and the classifierModel in /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_27_8_6/save_model/classifier_best_dev_f1_0.6212952563875197.pt
best epoch is:0 with best f1 is: 0.621295
*********************************************train model**************************************
current epoch:1
[ 1000 - th batch: valid loss is 0.560509 valid total precise is 0.698365 ]
[ 2000 - th batch: valid loss is 0.546506 valid total precise is 0.698294 ]
[ 3000 - th batch: valid loss is 0.540709 valid total precise is 0.699529 ]
[ 4000 - th batch: valid loss is 0.540556 valid total precise is 0.698313 ]
[ 5000 - th batch: valid loss is 0.539612 valid total precise is 0.698117 ]
[ 6000 - th batch: valid loss is 0.538406 valid total precise is 0.698894 ]
[ 7000 - th batch: valid loss is 0.538559 valid total precise is 0.699608 ]
[ 8000 - th batch: valid loss is 0.539823 valid total precise is 0.698351 ]
[ 9000 - th batch: valid loss is 0.539539 valid total precise is 0.698510 ]
[ 10000 - th batch: valid loss is 0.542469 valid total precise is 0.696425 ]
[ 11000 - th batch: valid loss is 0.543092 valid total precise is 0.697649 ]
[ 12000 - th batch: valid loss is 0.544216 valid total precise is 0.698354 ]
[ 13000 - th batch: valid loss is 0.545628 valid total precise is 0.698695 ]
[ 14000 - th batch: valid loss is 0.546063 valid total precise is 0.699209 ]
[ 15000 - th batch: valid loss is 0.546078 valid total precise is 0.699713 ]
The epoch:1,marcoF1ScoresOcemotion:0.570190
********************************confusion_matrix********************************
[[1700  380   11  262   68 1331   31]
 [ 443 1856   12  399   79 1211   31]
 [  16   22  230   37   23  215    5]
 [ 141  234   20 6363  547  867   28]
 [  58   67    7  855 2061  671   15]
 [ 628  497   35  621  349 9404   34]
 [ 104   69    3  171   36  234  213]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.55      0.45      0.49      3783
           1       0.59      0.46      0.52      4031
           2       0.72      0.42      0.53       548
           3       0.73      0.78      0.75      8200
           4       0.65      0.55      0.60      3734
           5       0.67      0.81      0.74     11568
           6       0.60      0.26      0.36       830

    accuracy                           0.67     32694
   macro avg       0.65      0.53      0.57     32694
weighted avg       0.66      0.67      0.66     32694

The epoch:1,marcoF1ScoresOcnli:0.805780
********************************confusion_matrix********************************
[[13740  2308   667]
 [ 2338 13138  1808]
 [  828  1879 13681]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.81      0.82      0.82     16715
           1       0.76      0.76      0.76     17284
           2       0.85      0.83      0.84     16388

    accuracy                           0.80     50387
   macro avg       0.81      0.81      0.81     50387
weighted avg       0.81      0.80      0.81     50387

The epoch:1,marcoF1ScoresTnews:0.618222
********************************confusion_matrix********************************
[[ 725   95  176    1   14   14   15   29    8   11   19   60    0   80
    19]
 [  76 3066  314   36   53   20   22  267   69   68  356   90    1  119
    35]
 [ 206  372 3739  212   49   20   56  153  104   98   89  202    0   63
   243]
 [  12   97  340 3397   47   11   65   94   37   69   64   98    1   11
   194]
 [  15   81   43   35 3281  261  121  142 1124   49   89  257   71  282
    30]
 [  16   48   24    9  251 1602   37   57   65    1  125   34    0   94
     3]
 [  28   63  120   41  161   35 3300   62  313   79  239  115    0   71
    48]
 [  42  309  127   89  100   52   33 2577  178   55   82  112    0   87
    40]
 [   5   54  107   35 1251   67  338  227 3962  118   53  148    5   59
   259]
 [  13  108  106   52   65    3   71   84  118 2340   68  957    0   36
   107]
 [  28  407   91   42   90   93  148   85   72   47 2136  354    0  248
    35]
 [  75  108  239   80  234   26   97  118  164  782  277 3156    0   82
    32]
 [   0    0    0    0  176    3    2    0    8    0    0    0   99    1
     1]
 [  93  146   43    6  296   99   47   96   75   28  231   86    0 1970
    15]
 [  17   73  322  149   35    7   46   54  280  120   34   36    0   25
  2673]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.54      0.57      0.55      1266
           1       0.61      0.67      0.64      4592
           2       0.65      0.67      0.66      5606
           3       0.81      0.75      0.78      4537
           4       0.54      0.56      0.55      5881
           5       0.69      0.68      0.68      2366
           6       0.75      0.71      0.73      4675
           7       0.64      0.66      0.65      3883
           8       0.60      0.59      0.60      6688
           9       0.61      0.57      0.59      4128
          10       0.55      0.55      0.55      3876
          11       0.55      0.58      0.56      5470
          12       0.56      0.34      0.42       290
          13       0.61      0.61      0.61      3231
          14       0.72      0.69      0.70      3871

    accuracy                           0.63     60360
   macro avg       0.63      0.61      0.62     60360
weighted avg       0.63      0.63      0.63     60360

The epoch:1,marcoF1ScoresTotal:0.664731
*********************************************start valid model**************************************
[ 1000 - th batch: valid loss is 0.827723 valid total precise is 0.661328 ]
The epoch:1,marcoF1ScoresOcemotion:0.518869
********************************confusion_matrix********************************
[[161  33   1  29  13  88   7]
 [ 76 164   0  51  12  68   3]
 [  6   1  16  10   3  10   0]
 [ 32  34   1 583  59  72   0]
 [ 17  13   2  85 185  50   1]
 [110  71   2  91  74 687   1]
 [ 13   9   0  21   2  14  19]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.39      0.48      0.43       332
           1       0.50      0.44      0.47       374
           2       0.73      0.35      0.47        46
           3       0.67      0.75      0.71       781
           4       0.53      0.52      0.53       353
           5       0.69      0.66      0.68      1036
           6       0.61      0.24      0.35        78

    accuracy                           0.60      3000
   macro avg       0.59      0.49      0.52      3000
weighted avg       0.61      0.60      0.60      3000

The epoch:1 ,marcoF1ScoresOcnli:0.805500
********************************confusion_matrix********************************
[[871  92  48]
 [134 721 146]
 [ 52 108 828]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.82      0.86      0.84      1011
           1       0.78      0.72      0.75      1001
           2       0.81      0.84      0.82       988

    accuracy                           0.81      3000
   macro avg       0.81      0.81      0.81      3000
weighted avg       0.81      0.81      0.81      3000

The epoch:1,marcoF1ScoresTnews:0.542122
********************************confusion_matrix********************************
[[ 20   3  12   1   0   0   3   4   0   1   3   2   0   9   2]
 [  3 119  30   1   4   2   1   7   3   7  28   4   0  13   3]
 [  3  18 164  12   1   1   6   9  11   6  11   9   0   6  23]
 [  0   4  15 164   4   1   6   3   3   1   4   5   0   0  11]
 [  2   0   1   1 151  18   9   5  34   3  10  14   0  24   3]
 [  0   2   0   1  17  75   2   3   2   0  12   2   0   2   1]
 [  2   2   2   2   6   5 158   2  21   1  17   7   0   5   4]
 [  1  18  14   7   4   1   3 105  18   6   6   7   0   7   3]
 [  0   1   8   4  85   6  29  12 154   6   4  10   0  10  27]
 [  1   7   4   4   3   0   6   1  11 101   3  66   0   4   9]
 [  2  10   8   3   1   3   6   5   3   4 112   9   0  19   0]
 [  3   6  11   6  10   4   5   4   7  19  29 172   0   8   2]
 [  0   0   0   0  10   0   0   0   1   0   0   0   1   0   0]
 [  3   4   4   0  11   3   5   2   4   0  12   1   0  99   1]
 [  0   1  20   5   3   1   1   2   9   2   6   2   0   2 124]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.50      0.33      0.40        60
           1       0.61      0.53      0.57       225
           2       0.56      0.59      0.57       280
           3       0.78      0.74      0.76       221
           4       0.49      0.55      0.52       275
           5       0.62      0.63      0.63       119
           6       0.66      0.68      0.67       234
           7       0.64      0.53      0.58       200
           8       0.55      0.43      0.48       356
           9       0.64      0.46      0.54       220
          10       0.44      0.61      0.51       185
          11       0.55      0.60      0.58       286
          12       1.00      0.08      0.15        12
          13       0.48      0.66      0.55       149
          14       0.58      0.70      0.63       178

    accuracy                           0.57      3000
   macro avg       0.61      0.54      0.54      3000
weighted avg       0.58      0.57      0.57      3000

The epoch:1,marcoF1ScoresTotal:0.622164
save the pretrainModel in /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_27_8_6/save_model/roberta_best_dev_f1_0.6221638440807307.pt and the classifierModel in /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_27_8_6/save_model/classifier_best_dev_f1_0.6221638440807307.pt
best epoch is:1 with best f1 is: 0.622164
*********************************************train model**************************************
current epoch:2
[ 1000 - th batch: valid loss is 0.297387 valid total precise is 0.762207 ]
[ 2000 - th batch: valid loss is 0.276482 valid total precise is 0.769218 ]
[ 3000 - th batch: valid loss is 0.269344 valid total precise is 0.770183 ]
[ 4000 - th batch: valid loss is 0.265773 valid total precise is 0.770943 ]
[ 5000 - th batch: valid loss is 0.262038 valid total precise is 0.772177 ]
[ 6000 - th batch: valid loss is 0.261121 valid total precise is 0.771777 ]
[ 7000 - th batch: valid loss is 0.259528 valid total precise is 0.772063 ]
[ 8000 - th batch: valid loss is 0.259528 valid total precise is 0.770207 ]
[ 9000 - th batch: valid loss is 0.260159 valid total precise is 0.768814 ]
[ 10000 - th batch: valid loss is 0.260575 valid total precise is 0.768288 ]
[ 11000 - th batch: valid loss is 0.261443 valid total precise is 0.768292 ]
[ 12000 - th batch: valid loss is 0.263048 valid total precise is 0.767805 ]
[ 13000 - th batch: valid loss is 0.264321 valid total precise is 0.767700 ]
[ 14000 - th batch: valid loss is 0.265455 valid total precise is 0.767682 ]
[ 15000 - th batch: valid loss is 0.266298 valid total precise is 0.767510 ]
The epoch:2,marcoF1ScoresOcemotion:0.675014
********************************confusion_matrix********************************
[[2174  366   10  174   43  983   33]
 [ 396 2418    8  247   65  863   34]
 [  24   22  289   27   31  152    3]
 [ 115  190    8 6938  419  499   31]
 [  34   63    9  649 2562  405   12]
 [ 587  440   30  365  271 9856   19]
 [ 118   74    4  127   33  154  320]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.63      0.57      0.60      3783
           1       0.68      0.60      0.64      4031
           2       0.81      0.53      0.64       548
           3       0.81      0.85      0.83      8200
           4       0.75      0.69      0.72      3734
           5       0.76      0.85      0.81     11568
           6       0.71      0.39      0.50       830

    accuracy                           0.75     32694
   macro avg       0.74      0.64      0.68     32694
weighted avg       0.75      0.75      0.75     32694

The epoch:2,marcoF1ScoresOcnli:0.849201
********************************confusion_matrix********************************
[[14384  1870   461]
 [ 1831 14016  1437]
 [  595  1439 14354]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.86      0.86      0.86     16715
           1       0.81      0.81      0.81     17284
           2       0.88      0.88      0.88     16388

    accuracy                           0.85     50387
   macro avg       0.85      0.85      0.85     50387
weighted avg       0.85      0.85      0.85     50387

The epoch:2,marcoF1ScoresTnews:0.699062
********************************confusion_matrix********************************
[[ 855   63  152    1    9    7   13   16   10   14   16   38    0   56
    16]
 [  60 3422  250   24   40   19   15  189   47   45  296   61    1   97
    26]
 [ 148  280 4171  159   27   19   46  104   91   78   60  175    0   60
   188]
 [   6   73  272 3656   33    6   38   74   30   59   62   72    0   20
   136]
 [  15   57   23   23 3745  219  106  105  995   46   63  180   63  220
    21]
 [  11   27   14    9  241 1758   33   38   45    2  102   24    1   58
     3]
 [  21   45   84   39  127   28 3579   47  256   55  232   89    0   41
    32]
 [  30  235  102   61   82   31   23 2901  131   49   71   76    0   63
    28]
 [   2   38   81   21 1127   53  291  151 4422  106   35  112    5   44
   200]
 [  13   72   62   38   43    1   70   69   97 2628   64  863    0   26
    82]
 [  20  348   65   29   76   73  137   58   53   32 2470  298    0  188
    29]
 [  50   77  168   59  204   26   73   91  116  668  217 3653    0   49
    19]
 [   0    0    0    0  142    2    1    0   15    0    0    0  130    0
     0]
 [  73   91   30    9  238   63   38   82   54   15  178   70    0 2281
     9]
 [  14   53  218  113   26    3   34   38  202   95   18   31    0    7
  3019]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.65      0.68      0.66      1266
           1       0.70      0.75      0.72      4592
           2       0.73      0.74      0.74      5606
           3       0.86      0.81      0.83      4537
           4       0.61      0.64      0.62      5881
           5       0.76      0.74      0.75      2366
           6       0.80      0.77      0.78      4675
           7       0.73      0.75      0.74      3883
           8       0.67      0.66      0.67      6688
           9       0.68      0.64      0.66      4128
          10       0.64      0.64      0.64      3876
          11       0.64      0.67      0.65      5470
          12       0.65      0.45      0.53       290
          13       0.71      0.71      0.71      3231
          14       0.79      0.78      0.79      3871

    accuracy                           0.71     60360
   macro avg       0.71      0.69      0.70     60360
weighted avg       0.71      0.71      0.71     60360

The epoch:2,marcoF1ScoresTotal:0.741092
*********************************************start valid model**************************************
[ 1000 - th batch: valid loss is 0.895174 valid total precise is 0.665221 ]
The epoch:2,marcoF1ScoresOcemotion:0.514832
********************************confusion_matrix********************************
[[119  29   2  42  12 119   9]
 [ 50 172   2  48  10  87   5]
 [  1   2  17  10   2  14   0]
 [ 21  32   0 596  48  81   3]
 [  9  12   3  92 172  63   2]
 [ 52  74   4  96  48 754   8]
 [  6   9   0  21   2  20  20]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.46      0.36      0.40       332
           1       0.52      0.46      0.49       374
           2       0.61      0.37      0.46        46
           3       0.66      0.76      0.71       781
           4       0.59      0.49      0.53       353
           5       0.66      0.73      0.69      1036
           6       0.43      0.26      0.32        78

    accuracy                           0.62      3000
   macro avg       0.56      0.49      0.51      3000
weighted avg       0.61      0.62      0.61      3000

The epoch:2 ,marcoF1ScoresOcnli:0.800762
********************************confusion_matrix********************************
[[854 105  52]
 [128 720 153]
 [ 44 113 831]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.83      0.84      0.84      1011
           1       0.77      0.72      0.74      1001
           2       0.80      0.84      0.82       988

    accuracy                           0.80      3000
   macro avg       0.80      0.80      0.80      3000
weighted avg       0.80      0.80      0.80      3000

The epoch:2,marcoF1ScoresTnews:0.569397
********************************confusion_matrix********************************
[[ 27   8   6   1   1   1   1   4   0   3   2   3   0   2   1]
 [  7 120  21   3   5   2   1  11   2   9  27   8   0   7   2]
 [ 10  28 157  17   1   2   7  11   6   8   7  16   0   5   5]
 [  0   5  11 180   5   1   4   1   3   3   1   4   0   0   3]
 [  2   4   2   1 139  19   5   7  43   3   8  15   5  20   2]
 [  0   1   1   2  15  82   0   6   1   1   9   1   0   0   0]
 [  2   3   4   4   7   7 141   4  27   3  16  11   0   3   2]
 [  3  18   7   7   4   3   1 118  12   6   5  10   0   6   0]
 [  0   2   9   4  63   3  17  18 188  11   5  11   2   8  15]
 [  1   5   4   4   3   0   3   2   7 142   2  40   0   3   4]
 [  2  11   8   7   3   8   7   8   2   2 106   8   0  13   0]
 [  6   7   8   7   9   4   3   5   4  65  23 138   0   7   0]
 [  0   0   0   0   5   0   0   0   1   0   0   0   6   0   0]
 [  1   2   3   0  11   9   3   6   7   2  13   4   0  87   1]
 [  1   3  22  10   2   2   0   3  16   8   5   4   0   1 101]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.44      0.45      0.44        60
           1       0.55      0.53      0.54       225
           2       0.60      0.56      0.58       280
           3       0.73      0.81      0.77       221
           4       0.51      0.51      0.51       275
           5       0.57      0.69      0.63       119
           6       0.73      0.60      0.66       234
           7       0.58      0.59      0.58       200
           8       0.59      0.53      0.56       356
           9       0.53      0.65      0.58       220
          10       0.46      0.57      0.51       185
          11       0.51      0.48      0.49       286
          12       0.46      0.50      0.48        12
          13       0.54      0.58      0.56       149
          14       0.74      0.57      0.64       178

    accuracy                           0.58      3000
   macro avg       0.57      0.58      0.57      3000
weighted avg       0.58      0.58      0.58      3000

The epoch:2,marcoF1ScoresTotal:0.628330
save the pretrainModel in /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_27_8_6/save_model/roberta_best_dev_f1_0.6283301153169715.pt and the classifierModel in /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_27_8_6/save_model/classifier_best_dev_f1_0.6283301153169715.pt
best epoch is:2 with best f1 is: 0.628330
*********************************************train model**************************************
current epoch:3
[ 1000 - th batch: valid loss is 0.118750 valid total precise is 0.834501 ]
[ 2000 - th batch: valid loss is 0.109734 valid total precise is 0.838030 ]
[ 3000 - th batch: valid loss is 0.105106 valid total precise is 0.840095 ]
[ 4000 - th batch: valid loss is 0.102522 valid total precise is 0.840599 ]
[ 5000 - th batch: valid loss is 0.101016 valid total precise is 0.840590 ]
[ 6000 - th batch: valid loss is 0.099983 valid total precise is 0.840510 ]
[ 7000 - th batch: valid loss is 0.099378 valid total precise is 0.841088 ]
[ 8000 - th batch: valid loss is 0.099033 valid total precise is 0.840049 ]
[ 9000 - th batch: valid loss is 0.098417 valid total precise is 0.840550 ]
[ 10000 - th batch: valid loss is 0.098462 valid total precise is 0.839862 ]
[ 11000 - th batch: valid loss is 0.098394 valid total precise is 0.839753 ]
[ 12000 - th batch: valid loss is 0.098196 valid total precise is 0.839727 ]
[ 13000 - th batch: valid loss is 0.098124 valid total precise is 0.839406 ]
[ 14000 - th batch: valid loss is 0.098251 valid total precise is 0.839092 ]
[ 15000 - th batch: valid loss is 0.098393 valid total precise is 0.838945 ]
The epoch:3,marcoF1ScoresOcemotion:0.800556
********************************confusion_matrix********************************
[[ 2731   287     8    89    21   614    33]
 [  301  3124     5   114    35   434    18]
 [   11    16   367    21    25   104     4]
 [   61   120     6  7489   282   221    21]
 [   18    24     8   390  3114   173     7]
 [  397   284    20   184   136 10527    20]
 [   96    52     3    63    34    99   483]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.76      0.72      0.74      3783
           1       0.80      0.77      0.79      4031
           2       0.88      0.67      0.76       548
           3       0.90      0.91      0.91      8200
           4       0.85      0.83      0.84      3734
           5       0.86      0.91      0.89     11568
           6       0.82      0.58      0.68       830

    accuracy                           0.85     32694
   macro avg       0.84      0.77      0.80     32694
weighted avg       0.85      0.85      0.85     32694

The epoch:3,marcoF1ScoresOcnli:0.883767
********************************confusion_matrix********************************
[[14924  1451   340]
 [ 1431 14749  1104]
 [  412  1147 14829]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.89      0.89      0.89     16715
           1       0.85      0.85      0.85     17284
           2       0.91      0.90      0.91     16388

    accuracy                           0.88     50387
   macro avg       0.88      0.88      0.88     50387
weighted avg       0.88      0.88      0.88     50387

The epoch:3,marcoF1ScoresTnews:0.791783
********************************confusion_matrix********************************
[[ 990   45  107    3    1    5   11   15    5    6    6   29    0   36
     7]
 [  38 3846  152   18   24   13    8  125   22   26  204   45    0   54
    17]
 [ 126  201 4616  121   23   17   31   80   53   44   36  107    0   30
   121]
 [   4   51  174 3937   24    9   33   62   25   43   30   55    1    2
    87]
 [   7   37   16   14 4309  148   70   70  781   32   36  137   55  158
    11]
 [   5   22   12    4  151 1954   23   21   28    1   80   18    0   47
     0]
 [  18   36   81   24   78   17 3873   26  189   44  172   61    1   32
    23]
 [  16  156   62   39   40   20   21 3265   80   25   54   52    0   40
    13]
 [   2   19   50    7  901   34  198   88 5042   72   24   88    9   35
   119]
 [   9   42   43   29   30    4   47   48   56 3018   38  690    0   21
    53]
 [  16  239   40   12   37   48   99   39   30   23 2938  208    0  128
    19]
 [  30   43  113   31  141   14   45   45   81  562  158 4160    0   30
    17]
 [   0    0    0    1   99    1    1    0    7    0    0    0  181    0
     0]
 [  45   58   25    2  178   39   22   50   32    7  121   34    0 2616
     2]
 [   9   25  141   72   21    1   20   17  149   79   12   21    0    5
  3299]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.75      0.78      0.77      1266
           1       0.80      0.84      0.82      4592
           2       0.82      0.82      0.82      5606
           3       0.91      0.87      0.89      4537
           4       0.71      0.73      0.72      5881
           5       0.84      0.83      0.83      2366
           6       0.86      0.83      0.84      4675
           7       0.83      0.84      0.83      3883
           8       0.77      0.75      0.76      6688
           9       0.76      0.73      0.74      4128
          10       0.75      0.76      0.75      3876
          11       0.73      0.76      0.74      5470
          12       0.73      0.62      0.67       290
          13       0.81      0.81      0.81      3231
          14       0.87      0.85      0.86      3871

    accuracy                           0.80     60360
   macro avg       0.80      0.79      0.79     60360
weighted avg       0.80      0.80      0.80     60360

The epoch:3,marcoF1ScoresTotal:0.825369
*********************************************start valid model**************************************
[ 1000 - th batch: valid loss is 1.049189 valid total precise is 0.653876 ]
The epoch:3,marcoF1ScoresOcemotion:0.490951
********************************confusion_matrix********************************
[[122  48   3  28  13 103  15]
 [ 56 161   3  47  18  78  11]
 [  1   5  18   4   6  11   1]
 [ 20  42   0 534  82  94   9]
 [ 13  11   5  67 199  53   5]
 [ 62  76   9  79  84 713  13]
 [ 11  10   1  17   4  13  22]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.43      0.37      0.40       332
           1       0.46      0.43      0.44       374
           2       0.46      0.39      0.42        46
           3       0.69      0.68      0.69       781
           4       0.49      0.56      0.52       353
           5       0.67      0.69      0.68      1036
           6       0.29      0.28      0.29        78

    accuracy                           0.59      3000
   macro avg       0.50      0.49      0.49      3000
weighted avg       0.59      0.59      0.59      3000

The epoch:3 ,marcoF1ScoresOcnli:0.795989
********************************confusion_matrix********************************
[[862 102  47]
 [172 699 130]
 [ 44 113 831]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.80      0.85      0.83      1011
           1       0.76      0.70      0.73      1001
           2       0.82      0.84      0.83       988

    accuracy                           0.80      3000
   macro avg       0.80      0.80      0.80      3000
weighted avg       0.80      0.80      0.80      3000

The epoch:3,marcoF1ScoresTnews:0.561926
********************************confusion_matrix********************************
[[ 33   9   3   0   0   1   2   5   0   1   1   2   0   2   1]
 [ 13 134  15   1   7   2   2  11   3   4  18   4   0   8   3]
 [ 11  34 152  11   2   3   8  11  10   6   6   8   0   5  13]
 [  0   7  16 173   3   1   5   2   3   2   0   3   0   0   6]
 [  2   6   1   0 147  13   5   8  49   2  10  12   7  11   2]
 [  0   3   1   0  15  83   1   3   3   0   7   2   0   0   1]
 [  2   6   4   4   8   5 157   5  22   3  13   2   0   1   2]
 [  9  21   5   5   8   4   1 115  15   6   2   3   0   4   2]
 [  0   4   8   5  66   4  22  16 182   8   5   5   1   3  27]
 [  1   9   7   6   6   0   5   3  13 128   0  34   0   2   6]
 [  3  18   7   5   2   5  10   9   3   2  97  10   0  13   1]
 [  9   9   9   7  12   4   5   6   6  59  20 131   0   5   4]
 [  0   0   0   0   6   0   0   0   1   0   0   0   5   0   0]
 [  3   6   2   0  20   8   8   8  10   0  11   3   0  69   1]
 [  1   5  18   8   3   2   1   2  13   4   4   0   0   0 117]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.38      0.55      0.45        60
           1       0.49      0.60      0.54       225
           2       0.61      0.54      0.58       280
           3       0.77      0.78      0.78       221
           4       0.48      0.53      0.51       275
           5       0.61      0.70      0.65       119
           6       0.68      0.67      0.67       234
           7       0.56      0.57      0.57       200
           8       0.55      0.51      0.53       356
           9       0.57      0.58      0.58       220
          10       0.50      0.52      0.51       185
          11       0.60      0.46      0.52       286
          12       0.38      0.42      0.40        12
          13       0.56      0.46      0.51       149
          14       0.63      0.66      0.64       178

    accuracy                           0.57      3000
   macro avg       0.56      0.57      0.56      3000
weighted avg       0.58      0.57      0.57      3000

The epoch:3,marcoF1ScoresTotal:0.616289
best epoch is:2 with best f1 is: 0.628330
*********************************************train model**************************************
current epoch:4
[ 1000 - th batch: valid loss is 0.063188 valid total precise is 0.877544 ]
[ 2000 - th batch: valid loss is 0.052909 valid total precise is 0.885276 ]
[ 3000 - th batch: valid loss is 0.047754 valid total precise is 0.889222 ]
[ 4000 - th batch: valid loss is 0.044134 valid total precise is 0.891473 ]
[ 5000 - th batch: valid loss is 0.042031 valid total precise is 0.892912 ]
[ 6000 - th batch: valid loss is 0.040658 valid total precise is 0.892723 ]
[ 7000 - th batch: valid loss is 0.039502 valid total precise is 0.893350 ]
[ 8000 - th batch: valid loss is 0.038647 valid total precise is 0.893459 ]
[ 9000 - th batch: valid loss is 0.037940 valid total precise is 0.893519 ]
[ 10000 - th batch: valid loss is 0.037324 valid total precise is 0.894089 ]
[ 11000 - th batch: valid loss is 0.037002 valid total precise is 0.893829 ]
[ 12000 - th batch: valid loss is 0.036866 valid total precise is 0.893297 ]
[ 13000 - th batch: valid loss is 0.036585 valid total precise is 0.893453 ]
[ 14000 - th batch: valid loss is 0.036525 valid total precise is 0.893286 ]
[ 15000 - th batch: valid loss is 0.036427 valid total precise is 0.893141 ]
The epoch:4,marcoF1ScoresOcemotion:0.875754
********************************confusion_matrix********************************
[[ 3144   190     1    51    14   352    31]
 [  193  3432     5    72    15   296    18]
 [    7    12   431     6    26    62     4]
 [   32    57     1  7813   155   130    12]
 [   14    21     2   207  3406    79     5]
 [  258   170    13   105    75 10928    19]
 [   72    32     5    37    22    76   586]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.85      0.83      0.84      3783
           1       0.88      0.85      0.86      4031
           2       0.94      0.79      0.86       548
           3       0.94      0.95      0.95      8200
           4       0.92      0.91      0.91      3734
           5       0.92      0.94      0.93     11568
           6       0.87      0.71      0.78       830

    accuracy                           0.91     32694
   macro avg       0.90      0.85      0.88     32694
weighted avg       0.91      0.91      0.91     32694

The epoch:4,marcoF1ScoresOcnli:0.914264
********************************confusion_matrix********************************
[[15386  1106   223]
 [ 1070 15439   775]
 [  278   892 15218]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.92      0.92      0.92     16715
           1       0.89      0.89      0.89     17284
           2       0.94      0.93      0.93     16388

    accuracy                           0.91     50387
   macro avg       0.91      0.91      0.91     50387
weighted avg       0.91      0.91      0.91     50387

The epoch:4,marcoF1ScoresTnews:0.864643
********************************confusion_matrix********************************
[[1110   28   70    1    2    4    7    5    2    2    1   13    0   17
     4]
 [  24 4131  107    8   16    7    2   81   12   18  109   22    0   46
     9]
 [  84  115 4961   78   13   13   28   43   46   32   31   70    0   19
    73]
 [   0   35  114 4151   12    8   41   19   15   30   25   32    2    4
    49]
 [   2   18    7    9 4790   89   51   37  590   16   28   94   37  103
    10]
 [   3   15    7    3  112 2085   18   10   17    1   55   12    0   26
     2]
 [   9   26   38   18   47   17 4170   15  120   16  132   33    0   23
    11]
 [   9   82   39   20   26    7    8 3540   40   19   24   30    0   29
    10]
 [   1   14   35   11  672   18  112   51 5551   49   15   49    4   17
    89]
 [   6   30   29   18   22    1   26   32   45 3330   20  515    0   20
    34]
 [   5  135   29   13   18   35   73   20   16   15 3298  123    0   88
     8]
 [  14   25   63   17   95    6   21   39   48  435  112 4577    1   13
     4]
 [   0    0    0    1   71    1    0    0    5    0    0    0  212    0
     0]
 [  23   28   11    1  117   35   13   29   20    6   65   16    0 2866
     1]
 [   2   16   98   40   10    1   14   11   96   46    6    7    0    5
  3519]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.86      0.88      0.87      1266
           1       0.88      0.90      0.89      4592
           2       0.88      0.88      0.88      5606
           3       0.95      0.91      0.93      4537
           4       0.80      0.81      0.80      5881
           5       0.90      0.88      0.89      2366
           6       0.91      0.89      0.90      4675
           7       0.90      0.91      0.91      3883
           8       0.84      0.83      0.83      6688
           9       0.83      0.81      0.82      4128
          10       0.84      0.85      0.85      3876
          11       0.82      0.84      0.83      5470
          12       0.83      0.73      0.78       290
          13       0.87      0.89      0.88      3231
          14       0.92      0.91      0.91      3871

    accuracy                           0.87     60360
   macro avg       0.87      0.86      0.86     60360
weighted avg       0.87      0.87      0.87     60360

The epoch:4,marcoF1ScoresTotal:0.884887
*********************************************start valid model**************************************
[ 1000 - th batch: valid loss is 1.187368 valid total precise is 0.655211 ]
The epoch:4,marcoF1ScoresOcemotion:0.491890
********************************confusion_matrix********************************
[[116  52   2  35  11 104  12]
 [ 55 156   1  47  15  92   8]
 [  1   5  21   7   4   8   0]
 [ 21  35   0 567  62  92   4]
 [ 10  10   7  76 175  70   5]
 [ 59  82  14  93  67 710  11]
 [ 10   7   2  17   3  18  21]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.43      0.35      0.38       332
           1       0.45      0.42      0.43       374
           2       0.45      0.46      0.45        46
           3       0.67      0.73      0.70       781
           4       0.52      0.50      0.51       353
           5       0.65      0.69      0.67      1036
           6       0.34      0.27      0.30        78

    accuracy                           0.59      3000
   macro avg       0.50      0.49      0.49      3000
weighted avg       0.58      0.59      0.58      3000

The epoch:4 ,marcoF1ScoresOcnli:0.795331
********************************confusion_matrix********************************
[[846 119  46]
 [149 727 125]
 [ 43 131 814]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.82      0.84      0.83      1011
           1       0.74      0.73      0.74      1001
           2       0.83      0.82      0.83       988

    accuracy                           0.80      3000
   macro avg       0.80      0.80      0.80      3000
weighted avg       0.80      0.80      0.80      3000

The epoch:4,marcoF1ScoresTnews:0.580647
********************************confusion_matrix********************************
[[ 29   8   7   1   0   0   2   4   0   1   0   4   0   3   1]
 [  9 132  18   0   6   2   2   8   6   5  20   4   0  10   3]
 [  4  27 171   8   3   2   3  10  11   7   8  11   0   3  12]
 [  0   7  13 167   3   1   5   1   3   3   1   6   0   0  11]
 [  2   3   4   0 146  14   6   5  46   2   5  16   6  17   3]
 [  0   3   0   1  12  82   1   1   7   1   8   2   0   1   0]
 [  2   5   4   3   7   3 153   6  28   1  10   7   0   4   1]
 [  6  20   6   4   7   2   1 113  17   7   2   4   0   8   3]
 [  0   1   7   6  69   2  18  11 190  11   6  11   0   6  18]
 [  1   5   3   4   5   0   4   1  12 121   0  53   0   3   8]
 [  2  19  10   0   4   5   9   9   4   2  95  11   0  15   0]
 [  5   7  12   8  11   4   5   6   5  49  17 150   0   7   0]
 [  0   0   0   0   3   0   0   0   2   0   0   0   7   0   0]
 [  2   7   4   0  17   9   4   6  10   1  10   4   0  75   0]
 [  0   3  20   3   3   1   0   2  18   5   6   3   0   0 114]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.47      0.48      0.48        60
           1       0.53      0.59      0.56       225
           2       0.61      0.61      0.61       280
           3       0.81      0.76      0.78       221
           4       0.49      0.53      0.51       275
           5       0.65      0.69      0.67       119
           6       0.72      0.65      0.68       234
           7       0.62      0.56      0.59       200
           8       0.53      0.53      0.53       356
           9       0.56      0.55      0.56       220
          10       0.51      0.51      0.51       185
          11       0.52      0.52      0.52       286
          12       0.54      0.58      0.56        12
          13       0.49      0.50      0.50       149
          14       0.66      0.64      0.65       178

    accuracy                           0.58      3000
   macro avg       0.58      0.58      0.58      3000
weighted avg       0.59      0.58      0.58      3000

The epoch:4,marcoF1ScoresTotal:0.622623
best epoch is:2 with best f1 is: 0.628330
*********************************************train model**************************************
current epoch:5
[ 1000 - th batch: valid loss is 0.009428 valid total precise is 0.936047 ]
[ 2000 - th batch: valid loss is 0.009669 valid total precise is 0.936024 ]
[ 3000 - th batch: valid loss is 0.009726 valid total precise is 0.935201 ]
[ 4000 - th batch: valid loss is 0.009931 valid total precise is 0.934789 ]
[ 5000 - th batch: valid loss is 0.009967 valid total precise is 0.934631 ]
[ 6000 - th batch: valid loss is 0.010003 valid total precise is 0.934785 ]
[ 7000 - th batch: valid loss is 0.010009 valid total precise is 0.934578 ]
[ 8000 - th batch: valid loss is 0.010003 valid total precise is 0.934631 ]
[ 9000 - th batch: valid loss is 0.010037 valid total precise is 0.934227 ]
[ 10000 - th batch: valid loss is 0.010011 valid total precise is 0.934049 ]
[ 11000 - th batch: valid loss is 0.010037 valid total precise is 0.934065 ]
[ 12000 - th batch: valid loss is 0.010068 valid total precise is 0.934207 ]
[ 13000 - th batch: valid loss is 0.010106 valid total precise is 0.933944 ]
