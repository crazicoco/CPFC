Parameters:
root    :    /share/home/crazicoco/competition/CPFC
vocabIdName    :    vocab.txt
tokenizeModel    :    hfl/chinese-roberta-wwm-ext-large
pretrainModel    :    hfl/chinese-roberta-wwm-ext-large
saveModelAddress    :    saveModelBin/
processedDataDir    :    preprocessed_data
saveLabelIdName    :    label.pt
saveTrainIdName    :    train.pt
saveValidIdName    :    valid.pt
saveTestIdName    :    test.pt
batch_size    :    9
epoch_size    :    20
loss_calculate    :    cross-entroy
lr    :    2e-05
device    :    0
max_len    :    512
lossCalculateWay    :    general
accumulate    :    True
ifparallel    :    True
debug    :    False
logfileName    :    public
a_step    :    16
description    :    the fgm parameters 0.25
use_bert_layer    :    -1
record_addr    :    /share/home/crazicoco/competition/CPFC/record_analysis/2021_1_1_18_1
*********************************************train model**************************************
current epoch:0
[ 1000 - th batch: valid loss is 4.520064 valid total precise is 0.402291 ]
[ 2000 - th batch: valid loss is 3.358621 valid total precise is 0.468790 ]
[ 3000 - th batch: valid loss is 2.788923 valid total precise is 0.508021 ]
[ 4000 - th batch: valid loss is 2.441563 valid total precise is 0.533494 ]
[ 5000 - th batch: valid loss is 2.210262 valid total precise is 0.550999 ]
[ 6000 - th batch: valid loss is 2.046297 valid total precise is 0.562353 ]
[ 7000 - th batch: valid loss is 1.921508 valid total precise is 0.570637 ]
[ 8000 - th batch: valid loss is 1.822769 valid total precise is 0.577517 ]
[ 9000 - th batch: valid loss is 1.740934 valid total precise is 0.582645 ]
[ 10000 - th batch: valid loss is 1.673934 valid total precise is 0.587059 ]
[ 11000 - th batch: valid loss is 1.616839 valid total precise is 0.591680 ]
[ 12000 - th batch: valid loss is 1.567527 valid total precise is 0.596003 ]
[ 13000 - th batch: valid loss is 1.523951 valid total precise is 0.600277 ]
[ 14000 - th batch: valid loss is 1.487123 valid total precise is 0.603892 ]
[ 15000 - th batch: valid loss is 1.452685 valid total precise is 0.606966 ]
The epoch:0,marcoF1ScoresOcemotion:0.448232
********************************confusion_matrix********************************
[[1105  331    9  417   79 1826   16]
 [ 381 1238   12  556   91 1733   20]
 [  21   24  148   55   19  281    0]
 [ 172  208    7 5843  474 1480   16]
 [  63   65   11 1054 1466 1069    6]
 [ 562  409   29  977  371 9206   14]
 [  76   72    2  219   36  329   96]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.46      0.29      0.36      3783
           1       0.53      0.31      0.39      4031
           2       0.68      0.27      0.39       548
           3       0.64      0.71      0.67      8200
           4       0.58      0.39      0.47      3734
           5       0.58      0.80      0.67     11568
           6       0.57      0.12      0.19       830

    accuracy                           0.58     32694
   macro avg       0.58      0.41      0.45     32694
weighted avg       0.58      0.58      0.56     32694

The epoch:0,marcoF1ScoresOcnli:0.690439
********************************confusion_matrix********************************
[[11638  3509  1568]
 [ 3382 11162  2740]
 [ 1540  2912 11936]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.70      0.70      0.70     16715
           1       0.63      0.65      0.64     17284
           2       0.73      0.73      0.73     16388

    accuracy                           0.69     50387
   macro avg       0.69      0.69      0.69     50387
weighted avg       0.69      0.69      0.69     50387

The epoch:0,marcoF1ScoresTnews:0.531341
********************************confusion_matrix********************************
[[ 513  105  296    7   27   12   35   47   17   19   24   63    0   87
    14]
 [  42 2640  484   53   92   25   32  282  104   91  417  142    0  137
    51]
 [ 163  447 3509  234   78   21   65  155  169  112   92  214    0   78
   269]
 [   7  107  467 3063   76    8   80  108   78   70   79  130    0   23
   241]
 [   8   84   98   58 2915  270  168  178 1244   70  137  287   24  304
    36]
 [  20   58   38   18  312 1405   48   80   90    8  152   39    0   92
     6]
 [  28   88  176   53  220   33 3007   75  410   88  240  127    0   74
    56]
 [  28  328  216   90  165   46   51 2326  215   52  103  127    0   84
    52]
 [   5   82  160   49 1340   78  408  244 3556  150   69  196    2   88
   261]
 [  10  152  145   60   77    6   94   85  155 1954   76 1128    0   40
   146]
 [  24  460  178   42  117  104  190   85  137   49 1778  385    0  282
    45]
 [  62  127  350  100  287   45  100  130  202  791  282 2855    0   92
    47]
 [   0    0    1    0  234    3    1    0   19    0    0    1   30    1
     0]
 [  85  186   90   15  361  114   59  109  124   33  285   94    0 1659
    17]
 [  12   97  426  197   58    4   58   65  357  138   33   51    0   29
  2346]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.51      0.41      0.45      1266
           1       0.53      0.57      0.55      4592
           2       0.53      0.63      0.57      5606
           3       0.76      0.68      0.71      4537
           4       0.46      0.50      0.48      5881
           5       0.65      0.59      0.62      2366
           6       0.68      0.64      0.66      4675
           7       0.59      0.60      0.59      3883
           8       0.52      0.53      0.52      6688
           9       0.54      0.47      0.50      4128
          10       0.47      0.46      0.47      3876
          11       0.49      0.52      0.50      5470
          12       0.54      0.10      0.17       290
          13       0.54      0.51      0.53      3231
          14       0.65      0.61      0.63      3871

    accuracy                           0.56     60360
   macro avg       0.56      0.52      0.53     60360
weighted avg       0.56      0.56      0.56     60360

The epoch:0,marcoF1ScoresTotal:0.556671
*********************************************start valid model**************************************
[ 1000 - th batch: valid loss is 0.840355 valid total precise is 0.658659 ]
The epoch:0,marcoF1ScoresOcemotion:0.448232
********************************confusion_matrix********************************
[[ 87  10   0  27   3 203   2]
 [ 28 111   1  40   2 191   1]
 [  0   1  15   5   2  23   0]
 [  6  13   1 589  29 143   0]
 [  3   3   3  99 133 111   1]
 [ 28  19   7  59  22 901   0]
 [  5   1   0  21   0  40  11]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.55      0.26      0.36       332
           1       0.70      0.30      0.42       374
           2       0.56      0.33      0.41        46
           3       0.70      0.75      0.73       781
           4       0.70      0.38      0.49       353
           5       0.56      0.87      0.68      1036
           6       0.73      0.14      0.24        78

    accuracy                           0.62      3000
   macro avg       0.64      0.43      0.47      3000
weighted avg       0.63      0.62      0.59      3000

The epoch:0 ,marcoF1ScoresOcnli:0.690439
********************************confusion_matrix********************************
[[890  60  61]
 [181 674 146]
 [ 49  83 856]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.79      0.88      0.84      1011
           1       0.82      0.67      0.74      1001
           2       0.81      0.87      0.83       988

    accuracy                           0.81      3000
   macro avg       0.81      0.81      0.80      3000
weighted avg       0.81      0.81      0.80      3000

The epoch:0,marcoF1ScoresTnews:0.531341
********************************confusion_matrix********************************
[[ 11  11  10   0   2   1   2   6   0   2   1   4   0   9   1]
 [  2 141  31   1   5   2   1  12   2   2   6   4   0  14   2]
 [  1  30 159   7   4   3   5  15   9   7   6  10   0   4  20]
 [  0  12  19 149   3   1   7   5   4   2   1   5   0   0  13]
 [  1   5   3   1 199  14   3   5  17   2   1   9   0  13   2]
 [  0   3   0   2  23  73   0   4   2   1   8   1   0   2   0]
 [  1   4   4   3  22   3 140   2  24   2  17   7   0   2   3]
 [  1  26   3   7  14   1   3 111  14   4   1   6   0   8   1]
 [  0   2   7   3 125   3  10  15 138  10   4   8   0   7  24]
 [  0   9   3   4  11   0   4   5   6 141   1  23   0   4   9]
 [  0  27   9   6   6   6   5   4   4   4  86  12   0  16   0]
 [  0  12  17   3  19   3   4  10   7  85  19  98   0   8   1]
 [  0   0   0   0  10   0   0   0   0   0   0   0   2   0   0]
 [  1   6   5   0  23   6   4   4   6   0   6   0   0  87   1]
 [  1   3  16   5   1   0   1   2  16   2   3   2   0   2 124]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.58      0.18      0.28        60
           1       0.48      0.63      0.55       225
           2       0.56      0.57      0.56       280
           3       0.78      0.67      0.72       221
           4       0.43      0.72      0.54       275
           5       0.63      0.61      0.62       119
           6       0.74      0.60      0.66       234
           7       0.56      0.56      0.56       200
           8       0.55      0.39      0.46       356
           9       0.53      0.64      0.58       220
          10       0.54      0.46      0.50       185
          11       0.52      0.34      0.41       286
          12       1.00      0.17      0.29        12
          13       0.49      0.58      0.54       149
          14       0.62      0.70      0.65       178

    accuracy                           0.55      3000
   macro avg       0.60      0.52      0.53      3000
weighted avg       0.57      0.55      0.55      3000

The epoch:0,marcoF1ScoresTotal:0.601669
save the pretrainModel in /share/home/crazicoco/competition/CPFC/record_analysis/2021_1_1_18_1/save_model/roberta_best_dev_f1_0.6016689888363219.pt and the classifierModel in /share/home/crazicoco/competition/CPFC/record_analysis/2021_1_1_18_1/save_model/classifier_best_dev_f1_0.6016689888363219.pt
best epoch is:0 with best f1 is: 0.601669
*********************************************train model**************************************
current epoch:1
[ 1000 - th batch: valid loss is 0.547667 valid total precise is 0.700812 ]
[ 2000 - th batch: valid loss is 0.533832 valid total precise is 0.700517 ]
[ 3000 - th batch: valid loss is 0.534082 valid total precise is 0.701567 ]
[ 4000 - th batch: valid loss is 0.531503 valid total precise is 0.702148 ]
[ 5000 - th batch: valid loss is 0.528831 valid total precise is 0.702785 ]
[ 6000 - th batch: valid loss is 0.530010 valid total precise is 0.701784 ]
[ 7000 - th batch: valid loss is 0.526430 valid total precise is 0.702624 ]
[ 8000 - th batch: valid loss is 0.526984 valid total precise is 0.702824 ]
[ 9000 - th batch: valid loss is 0.527619 valid total precise is 0.702189 ]
[ 10000 - th batch: valid loss is 0.526922 valid total precise is 0.702815 ]
[ 11000 - th batch: valid loss is 0.525409 valid total precise is 0.704508 ]
[ 12000 - th batch: valid loss is 0.524152 valid total precise is 0.705475 ]
[ 13000 - th batch: valid loss is 0.524687 valid total precise is 0.705900 ]
[ 14000 - th batch: valid loss is 0.524762 valid total precise is 0.706376 ]
[ 15000 - th batch: valid loss is 0.524264 valid total precise is 0.706603 ]
The epoch:1,marcoF1ScoresOcemotion:0.580259
********************************confusion_matrix********************************
[[1650  334   15  291   62 1398   33]
 [ 433 1812    7  416   81 1247   35]
 [  17   21  238   33   24  212    3]
 [ 131  208   15 6465  499  848   34]
 [  59   56    7  791 2123  689    9]
 [ 581  417   28  597  302 9617   26]
 [  96   77    3  146   40  246  222]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.56      0.44      0.49      3783
           1       0.62      0.45      0.52      4031
           2       0.76      0.43      0.55       548
           3       0.74      0.79      0.76      8200
           4       0.68      0.57      0.62      3734
           5       0.67      0.83      0.74     11568
           6       0.61      0.27      0.37       830

    accuracy                           0.68     32694
   macro avg       0.66      0.54      0.58     32694
weighted avg       0.67      0.68      0.67     32694

The epoch:1,marcoF1ScoresOcnli:0.818260
********************************confusion_matrix********************************
[[13981  2136   598]
 [ 2255 13364  1665]
 [  765  1778 13845]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.82      0.84      0.83     16715
           1       0.77      0.77      0.77     17284
           2       0.86      0.84      0.85     16388

    accuracy                           0.82     50387
   macro avg       0.82      0.82      0.82     50387
weighted avg       0.82      0.82      0.82     50387

The epoch:1,marcoF1ScoresTnews:0.619665
********************************confusion_matrix********************************
[[ 723   93  185    2   11   11   19   37   11   20   28   48    0   65
    13]
 [  70 3077  318   30   61   20   20  256   66   71  322  111    2  137
    31]
 [ 178  377 3752  207   43   22   67  156  126   90   83  200    0   60
   245]
 [  16  100  365 3368   48    9   67   98   49   54   67   99    0   16
   181]
 [  12   76   48   38 3330  264  141  133 1067   43  103  259   53  280
    34]
 [  19   44   22   12  264 1594   41   71   61    2  124   30    0   79
     3]
 [  28   70  115   37  158   36 3326   67  321   77  231  105    1   57
    46]
 [  35  299  141   75  118   50   39 2609  167   60   82   93    0   81
    34]
 [   2   59  102   34 1284   74  345  220 3941  124   54  144    7   61
   237]
 [  12  124   95   38   55    3   83   88  121 2290   79  989    0   37
   114]
 [  25  418  103   39   91   88  178   97   81   45 2103  340    0  237
    31]
 [  75  104  245   72  243   27   88  123  135  722  266 3261    0   81
    28]
 [   0    1    0    0  176    2    2    0   11    0    0    0   97    0
     1]
 [  93  147   46    9  287   93   52  104   78   33  236   84    0 1959
    10]
 [  17   73  341  156   40    3   45   57  274  119   28   37    0   26
  2655]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.55      0.57      0.56      1266
           1       0.61      0.67      0.64      4592
           2       0.64      0.67      0.65      5606
           3       0.82      0.74      0.78      4537
           4       0.54      0.57      0.55      5881
           5       0.69      0.67      0.68      2366
           6       0.74      0.71      0.72      4675
           7       0.63      0.67      0.65      3883
           8       0.61      0.59      0.60      6688
           9       0.61      0.55      0.58      4128
          10       0.55      0.54      0.55      3876
          11       0.56      0.60      0.58      5470
          12       0.61      0.33      0.43       290
          13       0.62      0.61      0.61      3231
          14       0.72      0.69      0.70      3871

    accuracy                           0.63     60360
   macro avg       0.63      0.61      0.62     60360
weighted avg       0.63      0.63      0.63     60360

The epoch:1,marcoF1ScoresTotal:0.672728
*********************************************start valid model**************************************
[ 1000 - th batch: valid loss is 0.733822 valid total precise is 0.670115 ]
The epoch:1,marcoF1ScoresOcemotion:0.580259
********************************confusion_matrix********************************
[[106  26   2  25   9 158   6]
 [ 40 155   0  41  12 122   4]
 [  1   4  17   8   3  13   0]
 [ 13  18   1 586  49 113   1]
 [  3  11   3  82 175  75   4]
 [ 35  51  11  66  49 822   2]
 [  5   3   0  18   2  31  19]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.52      0.32      0.40       332
           1       0.58      0.41      0.48       374
           2       0.50      0.37      0.42        46
           3       0.71      0.75      0.73       781
           4       0.59      0.50      0.54       353
           5       0.62      0.79      0.69      1036
           6       0.53      0.24      0.33        78

    accuracy                           0.63      3000
   macro avg       0.58      0.48      0.51      3000
weighted avg       0.62      0.63      0.61      3000

The epoch:1 ,marcoF1ScoresOcnli:0.818260
********************************confusion_matrix********************************
[[895  75  41]
 [180 696 125]
 [ 54  98 836]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.79      0.89      0.84      1011
           1       0.80      0.70      0.74      1001
           2       0.83      0.85      0.84       988

    accuracy                           0.81      3000
   macro avg       0.81      0.81      0.81      3000
weighted avg       0.81      0.81      0.81      3000

The epoch:1,marcoF1ScoresTnews:0.619665
********************************confusion_matrix********************************
[[ 17  10   9   1   2   1   2   5   0   1   0   4   0   6   2]
 [  4 138  28   1   4   2   1   5   4   3  16  10   0   7   2]
 [  5  27 177  12   1   3   4   8   7   4   7  11   0   3  11]
 [  0   8  11 173   5   1   7   4   3   0   1   4   0   0   4]
 [  2   4   3   2 139  22   7   3  52   3   4  11   6  15   2]
 [  0   2   0   2  13  84   0   3   4   1   9   1   0   0   0]
 [  1   3   4   2   8   5 153   2  26   1  17   8   0   2   2]
 [  2  26   6   6  11   2   1 110  14   4   3   8   0   6   1]
 [  0   2   8   6  66   6  22  12 185   7   5   9   1   5  22]
 [  1  10   7   5   7   0   4   3   8  89   1  72   0   4   9]
 [  1  22   8   2   3   9   8   4   3   1  91  17   0  16   0]
 [  1  14  16   4  13   5   5   6   8  31  11 165   0   7   0]
 [  0   0   0   0   4   0   0   0   1   0   0   0   7   0   0]
 [  1   7   6   0  16   7   3   1   8   1  10   2   0  86   1]
 [  1   2  20  12   1   1   1   1  17   3   4   5   0   1 109]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.47      0.28      0.35        60
           1       0.50      0.61      0.55       225
           2       0.58      0.63      0.61       280
           3       0.76      0.78      0.77       221
           4       0.47      0.51      0.49       275
           5       0.57      0.71      0.63       119
           6       0.70      0.65      0.68       234
           7       0.66      0.55      0.60       200
           8       0.54      0.52      0.53       356
           9       0.60      0.40      0.48       220
          10       0.51      0.49      0.50       185
          11       0.50      0.58      0.54       286
          12       0.50      0.58      0.54        12
          13       0.54      0.58      0.56       149
          14       0.66      0.61      0.64       178

    accuracy                           0.57      3000
   macro avg       0.57      0.57      0.56      3000
weighted avg       0.58      0.57      0.57      3000

The epoch:1,marcoF1ScoresTotal:0.628428
save the pretrainModel in /share/home/crazicoco/competition/CPFC/record_analysis/2021_1_1_18_1/save_model/roberta_best_dev_f1_0.6284279409699912.pt and the classifierModel in /share/home/crazicoco/competition/CPFC/record_analysis/2021_1_1_18_1/save_model/classifier_best_dev_f1_0.6284279409699912.pt
best epoch is:1 with best f1 is: 0.628428
*********************************************train model**************************************
current epoch:2
[ 1000 - th batch: valid loss is 0.333388 valid total precise is 0.742743 ]
[ 2000 - th batch: valid loss is 0.337430 valid total precise is 0.745484 ]
[ 3000 - th batch: valid loss is 0.336085 valid total precise is 0.747620 ]
[ 4000 - th batch: valid loss is 0.335637 valid total precise is 0.747631 ]
[ 5000 - th batch: valid loss is 0.336036 valid total precise is 0.747927 ]
[ 6000 - th batch: valid loss is 0.334621 valid total precise is 0.749403 ]
[ 7000 - th batch: valid loss is 0.333854 valid total precise is 0.749758 ]
[ 8000 - th batch: valid loss is 0.332752 valid total precise is 0.750747 ]
[ 9000 - th batch: valid loss is 0.331401 valid total precise is 0.751429 ]
[ 10000 - th batch: valid loss is 0.330936 valid total precise is 0.751420 ]
[ 11000 - th batch: valid loss is 0.330584 valid total precise is 0.752281 ]
[ 12000 - th batch: valid loss is 0.330356 valid total precise is 0.752859 ]
[ 13000 - th batch: valid loss is 0.329760 valid total precise is 0.753178 ]
[ 14000 - th batch: valid loss is 0.329338 valid total precise is 0.753506 ]
[ 15000 - th batch: valid loss is 0.328523 valid total precise is 0.754243 ]
The epoch:2,marcoF1ScoresOcemotion:0.658365
********************************confusion_matrix********************************
[[2008  352   12  202   49 1127   33]
 [ 424 2219    8  291   73  985   31]
 [  21   20  291   31   24  158    3]
 [ 111  192   12 6851  430  576   28]
 [  45   58    6  672 2466  477   10]
 [ 562  387   17  372  271 9936   23]
 [  92   79    4  128   37  190  300]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.62      0.53      0.57      3783
           1       0.67      0.55      0.60      4031
           2       0.83      0.53      0.65       548
           3       0.80      0.84      0.82      8200
           4       0.74      0.66      0.70      3734
           5       0.74      0.86      0.79     11568
           6       0.70      0.36      0.48       830

    accuracy                           0.74     32694
   macro avg       0.73      0.62      0.66     32694
weighted avg       0.73      0.74      0.73     32694

The epoch:2,marcoF1ScoresOcnli:0.848727
********************************confusion_matrix********************************
[[14433  1821   461]
 [ 1926 13989  1369]
 [  624  1456 14308]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.85      0.86      0.86     16715
           1       0.81      0.81      0.81     17284
           2       0.89      0.87      0.88     16388

    accuracy                           0.85     50387
   macro avg       0.85      0.85      0.85     50387
weighted avg       0.85      0.85      0.85     50387

The epoch:2,marcoF1ScoresTnews:0.677822
********************************confusion_matrix********************************
[[ 810   83  158    2   12   13   13   24    6   15   13   46    0   61
    10]
 [  55 3359  282   30   47   16   19  209   45   52  281   69    2  106
    20]
 [ 164  324 4033  178   40   18   41  126   91   79   72  176    0   54
   210]
 [   9   88  313 3557   42    3   47   71   38   57   55   81    0   12
   164]
 [   8   56   30   25 3723  219   98  110  970   34   75  227   57  218
    31]
 [  15   41   20   10  226 1715   28   46   55    1  110   32    0   66
     1]
 [  21   66  104   22  142   31 3517   44  280   64  212   87    0   49
    36]
 [  27  267  110   56   84   42   29 2820  144   55   64   91    0   62
    32]
 [   4   41   82   30 1187   55  278  175 4303  113   41  118    3   56
   202]
 [  17  102   79   33   57    1   57   63  102 2507   55  918    0   29
   108]
 [  22  397   81   35   55   69  148   65   57   36 2360  319    0  199
    33]
 [  57   79  205   59  245   30   79   91  102  643  246 3549    0   60
    25]
 [   0    1    0    0  148    3    1    0   14    0    0    1  122    0
     0]
 [  74  133   36   11  281   60   33   68   53   27  188   69    0 2186
    12]
 [  11   67  274  130   36    2   32   44  231  117   21   37    0   16
  2853]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.63      0.64      0.63      1266
           1       0.66      0.73      0.69      4592
           2       0.69      0.72      0.71      5606
           3       0.85      0.78      0.82      4537
           4       0.59      0.63      0.61      5881
           5       0.75      0.72      0.74      2366
           6       0.80      0.75      0.77      4675
           7       0.71      0.73      0.72      3883
           8       0.66      0.64      0.65      6688
           9       0.66      0.61      0.63      4128
          10       0.62      0.61      0.62      3876
          11       0.61      0.65      0.63      5470
          12       0.66      0.42      0.51       290
          13       0.69      0.68      0.68      3231
          14       0.76      0.74      0.75      3871

    accuracy                           0.69     60360
   macro avg       0.69      0.67      0.68     60360
weighted avg       0.69      0.69      0.69     60360

The epoch:2,marcoF1ScoresTotal:0.728304
*********************************************start valid model**************************************
[ 1000 - th batch: valid loss is 0.780738 valid total precise is 0.670448 ]
The epoch:2,marcoF1ScoresOcemotion:0.658365
********************************confusion_matrix********************************
[[109  33   2  31   9 141   7]
 [ 43 171   0  43  12 100   5]
 [  0   5  16   9   2  14   0]
 [ 12  24   1 594  53  96   1]
 [  5  12   3  92 168  69   4]
 [ 42  60   6  81  47 798   2]
 [  9   7   1  19   2  19  21]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.50      0.33      0.39       332
           1       0.55      0.46      0.50       374
           2       0.55      0.35      0.43        46
           3       0.68      0.76      0.72       781
           4       0.57      0.48      0.52       353
           5       0.65      0.77      0.70      1036
           6       0.53      0.27      0.36        78

    accuracy                           0.63      3000
   macro avg       0.57      0.49      0.52      3000
weighted avg       0.61      0.63      0.61      3000

The epoch:2 ,marcoF1ScoresOcnli:0.848727
********************************confusion_matrix********************************
[[866  97  48]
 [153 717 131]
 [ 44  96 848]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.81      0.86      0.84      1011
           1       0.79      0.72      0.75      1001
           2       0.83      0.86      0.84       988

    accuracy                           0.81      3000
   macro avg       0.81      0.81      0.81      3000
weighted avg       0.81      0.81      0.81      3000

The epoch:2,marcoF1ScoresTnews:0.677822
********************************confusion_matrix********************************
[[ 27  10   6   1   2   0   1   5   0   1   1   3   0   1   2]
 [  7 124  25   1   5   2   2  12   4   6  19   9   0   8   1]
 [ 10  22 169  10   2   3   6  14   9   6   8  12   0   2   7]
 [  0   5  15 168   5   1   6   5   3   0   2   7   0   0   4]
 [  2   2   3   3 140  15   6   7  61   2   4  10   4  15   1]
 [  0   3   0   2  18  78   0   3   5   1   8   1   0   0   0]
 [  2   2   5   2   6   4 151   3  27   1  19   8   0   2   2]
 [  3  24   4   4   8   1   1 119  17   4   1   7   0   6   1]
 [  0   2   8   6  72   2  16  14 184   9   6  11   0   2  24]
 [  1   7   6   5   5   0   4   3  11 100   1  65   0   3   9]
 [  2  18   8   4   3   8   6   5   2   1 111   8   0   9   0]
 [  5  10   9   4  12   5   2   9   7  37  22 160   0   4   0]
 [  0   0   0   0   5   0   0   0   1   0   0   0   6   0   0]
 [  2   7   5   1  15   7   5   4   8   0  15   1   0  78   1]
 [  3   3  18   7   3   1   0   2  14   3   6   4   0   1 113]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.42      0.45      0.44        60
           1       0.52      0.55      0.53       225
           2       0.60      0.60      0.60       280
           3       0.77      0.76      0.77       221
           4       0.47      0.51      0.49       275
           5       0.61      0.66      0.63       119
           6       0.73      0.65      0.69       234
           7       0.58      0.59      0.59       200
           8       0.52      0.52      0.52       356
           9       0.58      0.45      0.51       220
          10       0.50      0.60      0.54       185
          11       0.52      0.56      0.54       286
          12       0.60      0.50      0.55        12
          13       0.60      0.52      0.56       149
          14       0.68      0.63      0.66       178

    accuracy                           0.58      3000
   macro avg       0.58      0.57      0.57      3000
weighted avg       0.58      0.58      0.58      3000

The epoch:2,marcoF1ScoresTotal:0.633296
save the pretrainModel in /share/home/crazicoco/competition/CPFC/record_analysis/2021_1_1_18_1/save_model/roberta_best_dev_f1_0.6332959942600825.pt and the classifierModel in /share/home/crazicoco/competition/CPFC/record_analysis/2021_1_1_18_1/save_model/classifier_best_dev_f1_0.6332959942600825.pt
best epoch is:2 with best f1 is: 0.633296
*********************************************train model**************************************
current epoch:3
[ 1000 - th batch: valid loss is 0.240775 valid total precise is 0.781114 ]
[ 2000 - th batch: valid loss is 0.231077 valid total precise is 0.782502 ]
[ 3000 - th batch: valid loss is 0.225427 valid total precise is 0.785484 ]
[ 4000 - th batch: valid loss is 0.223922 valid total precise is 0.785030 ]
[ 5000 - th batch: valid loss is 0.221968 valid total precise is 0.785268 ]
[ 6000 - th batch: valid loss is 0.220993 valid total precise is 0.784872 ]
[ 7000 - th batch: valid loss is 0.221048 valid total precise is 0.784398 ]
[ 8000 - th batch: valid loss is 0.221518 valid total precise is 0.783987 ]
[ 9000 - th batch: valid loss is 0.221577 valid total precise is 0.783655 ]
[ 10000 - th batch: valid loss is 0.220764 valid total precise is 0.784278 ]
[ 11000 - th batch: valid loss is 0.220798 valid total precise is 0.784748 ]
[ 12000 - th batch: valid loss is 0.220680 valid total precise is 0.785362 ]
[ 13000 - th batch: valid loss is 0.220682 valid total precise is 0.786026 ]
[ 14000 - th batch: valid loss is 0.220632 valid total precise is 0.786659 ]
[ 15000 - th batch: valid loss is 0.220491 valid total precise is 0.787171 ]
The epoch:3,marcoF1ScoresOcemotion:0.712843
********************************confusion_matrix********************************
[[ 2265   339    10   153    43   939    34]
 [  405  2489    12   224    49   827    25]
 [   15    18   320    25    26   142     2]
 [   99   161     9  7186   329   399    17]
 [   35    45     4   559  2711   372     8]
 [  523   361    12   269   190 10201    12]
 [  106    72     3   110    35   149   355]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.66      0.60      0.63      3783
           1       0.71      0.62      0.66      4031
           2       0.86      0.58      0.70       548
           3       0.84      0.88      0.86      8200
           4       0.80      0.73      0.76      3734
           5       0.78      0.88      0.83     11568
           6       0.78      0.43      0.55       830

    accuracy                           0.78     32694
   macro avg       0.78      0.67      0.71     32694
weighted avg       0.78      0.78      0.78     32694

The epoch:3,marcoF1ScoresOcnli:0.863393
********************************confusion_matrix********************************
[[14638  1686   391]
 [ 1776 14297  1211]
 [  547  1306 14535]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.86      0.88      0.87     16715
           1       0.83      0.83      0.83     17284
           2       0.90      0.89      0.89     16388

    accuracy                           0.86     50387
   macro avg       0.86      0.86      0.86     50387
weighted avg       0.86      0.86      0.86     50387

The epoch:3,marcoF1ScoresTnews:0.722939
********************************confusion_matrix********************************
[[ 890   77  130    1    9    8   12   20    4    8   16   43    0   41
     7]
 [  60 3515  242   21   40   12   17  192   37   43  238   66    0   86
    23]
 [ 149  276 4247  183   24   14   41  103   85   63   59  158    0   45
   159]
 [   5   70  262 3696   30    7   41   67   33   46   58   80    0   15
   127]
 [   3   49   26   23 3947  190   82   94  893   33   64  187   45  222
    23]
 [   8   23   17    6  207 1824   22   36   47    1   93   27    0   55
     0]
 [  19   56   76   32  110   22 3659   51  253   53  197   80    1   39
    27]
 [  24  227   91   45   89   29   25 2996  106   40   65   70    0   47
    29]
 [   7   36   62   22 1077   49  235  141 4602   97   29  100    3   44
   184]
 [   9   80   66   38   42    7   54   50   82 2730   50  809    0   26
    85]
 [  24  330   69   30   63   67  144   49   48   27 2563  265    0  176
    21]
 [  53   69  152   54  188   17   71   86  105  599  226 3779    1   50
    20]
 [   0    0    0    0  137    3    1    0    7    0    0    0  142    0
     0]
 [  68   97   25    6  237   50   35   64   56   22  181   46    0 2338
     6]
 [   9   52  235   94   20    3   30   33  185   96   18   28    0   13
  3055]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.67      0.70      0.69      1266
           1       0.71      0.77      0.74      4592
           2       0.75      0.76      0.75      5606
           3       0.87      0.81      0.84      4537
           4       0.63      0.67      0.65      5881
           5       0.79      0.77      0.78      2366
           6       0.82      0.78      0.80      4675
           7       0.75      0.77      0.76      3883
           8       0.70      0.69      0.70      6688
           9       0.71      0.66      0.68      4128
          10       0.66      0.66      0.66      3876
          11       0.66      0.69      0.67      5470
          12       0.74      0.49      0.59       290
          13       0.73      0.72      0.73      3231
          14       0.81      0.79      0.80      3871

    accuracy                           0.73     60360
   macro avg       0.73      0.72      0.72     60360
weighted avg       0.73      0.73      0.73     60360

The epoch:3,marcoF1ScoresTotal:0.766391
*********************************************start valid model**************************************
[ 1000 - th batch: valid loss is 0.780621 valid total precise is 0.668780 ]
The epoch:3,marcoF1ScoresOcemotion:0.712843
********************************confusion_matrix********************************
[[137  27   2  22  10 122  12]
 [ 62 160   0  41  13  91   7]
 [  2   3  14   6   5  16   0]
 [ 22  22   1 570  58 105   3]
 [  9  13   3  70 182  70   6]
 [ 60  60   3  68  57 785   3]
 [ 12   6   1  19   3  16  21]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.45      0.41      0.43       332
           1       0.55      0.43      0.48       374
           2       0.58      0.30      0.40        46
           3       0.72      0.73      0.72       781
           4       0.55      0.52      0.53       353
           5       0.65      0.76      0.70      1036
           6       0.40      0.27      0.32        78

    accuracy                           0.62      3000
   macro avg       0.56      0.49      0.51      3000
weighted avg       0.61      0.62      0.62      3000

The epoch:3 ,marcoF1ScoresOcnli:0.863393
********************************confusion_matrix********************************
[[878  83  50]
 [166 698 137]
 [ 45  96 847]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.81      0.87      0.84      1011
           1       0.80      0.70      0.74      1001
           2       0.82      0.86      0.84       988

    accuracy                           0.81      3000
   macro avg       0.81      0.81      0.81      3000
weighted avg       0.81      0.81      0.81      3000

The epoch:3,marcoF1ScoresTnews:0.722939
********************************confusion_matrix********************************
[[ 22  12   5   1   2   0   1   5   0   2   0   4   0   4   2]
 [  8 132  17   1   5   2   2  12   4   6  16   8   0  10   2]
 [  9  27 155  10   2   3   5  15   8   6   6  15   0   3  16]
 [  0   5  15 167   5   1   6   4   2   1   0   8   0   0   7]
 [  2   2   4   2 140  15   8   7  50   2   5  12   4  19   3]
 [  0   3   0   2  16  77   1   3   5   1   9   2   0   0   0]
 [  2   2   3   3   9   3 160   4  17   2  18   7   0   3   1]
 [  4  25   2   6   6   1   3 117  15   4   1   7   0   7   2]
 [  0   2   7   6  67   2  28  14 173  11   5  10   1   6  24]
 [  1   8   6   5   5   0   4   5   9 111   1  54   0   3   8]
 [  1  21   7   3   3   7  10   5   2   1  97  14   0  14   0]
 [  4   9   9   4  10   4   3   9   7  43  14 166   0   4   0]
 [  0   0   0   0   5   0   0   0   1   0   0   0   6   0   0]
 [  1   6   4   0  13   5   4   5   8   1  14   2   0  85   1]
 [  2   3  14   7   2   1   2   2  14   3   4   4   0   1 119]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.39      0.37      0.38        60
           1       0.51      0.59      0.55       225
           2       0.62      0.55      0.59       280
           3       0.77      0.76      0.76       221
           4       0.48      0.51      0.50       275
           5       0.64      0.65      0.64       119
           6       0.68      0.68      0.68       234
           7       0.57      0.58      0.57       200
           8       0.55      0.49      0.52       356
           9       0.57      0.50      0.54       220
          10       0.51      0.52      0.52       185
          11       0.53      0.58      0.55       286
          12       0.55      0.50      0.52        12
          13       0.53      0.57      0.55       149
          14       0.64      0.67      0.66       178

    accuracy                           0.58      3000
   macro avg       0.57      0.57      0.57      3000
weighted avg       0.58      0.58      0.58      3000

The epoch:3,marcoF1ScoresTotal:0.629048
best epoch is:2 with best f1 is: 0.633296
*********************************************train model**************************************
current epoch:4
[ 1000 - th batch: valid loss is 0.182009 valid total precise is 0.801357 ]
[ 2000 - th batch: valid loss is 0.178063 valid total precise is 0.802068 ]
[ 3000 - th batch: valid loss is 0.178420 valid total precise is 0.801082 ]
[ 4000 - th batch: valid loss is 0.177167 valid total precise is 0.802673 ]
[ 5000 - th batch: valid loss is 0.176437 valid total precise is 0.802494 ]
[ 6000 - th batch: valid loss is 0.175881 valid total precise is 0.803023 ]
[ 7000 - th batch: valid loss is 0.175010 valid total precise is 0.803400 ]
[ 8000 - th batch: valid loss is 0.174713 valid total precise is 0.803100 ]
[ 9000 - th batch: valid loss is 0.174169 valid total precise is 0.803163 ]
[ 10000 - th batch: valid loss is 0.174103 valid total precise is 0.802780 ]
[ 11000 - th batch: valid loss is 0.173570 valid total precise is 0.803871 ]
[ 12000 - th batch: valid loss is 0.173301 valid total precise is 0.804724 ]
[ 13000 - th batch: valid loss is 0.173103 valid total precise is 0.805447 ]
[ 14000 - th batch: valid loss is 0.173415 valid total precise is 0.805335 ]
[ 15000 - th batch: valid loss is 0.173428 valid total precise is 0.805298 ]
The epoch:4,marcoF1ScoresOcemotion:0.738525
********************************confusion_matrix********************************
[[ 2364   317    10   136    34   895    27]
 [  387  2667     7   202    43   693    32]
 [   18    19   327    22    25   133     4]
 [   87   134     7  7276   335   344    17]
 [   33    43     3   501  2835   312     7]
 [  458   325    12   223   173 10360    17]
 [   87    74     4    96    42   132   395]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.69      0.62      0.66      3783
           1       0.75      0.66      0.70      4031
           2       0.88      0.60      0.71       548
           3       0.86      0.89      0.87      8200
           4       0.81      0.76      0.79      3734
           5       0.81      0.90      0.85     11568
           6       0.79      0.48      0.59       830

    accuracy                           0.80     32694
   macro avg       0.80      0.70      0.74     32694
weighted avg       0.80      0.80      0.80     32694

The epoch:4,marcoF1ScoresOcnli:0.871657
********************************confusion_matrix********************************
[[14757  1592   366]
 [ 1695 14453  1136]
 [  477  1233 14678]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.87      0.88      0.88     16715
           1       0.84      0.84      0.84     17284
           2       0.91      0.90      0.90     16388

    accuracy                           0.87     50387
   macro avg       0.87      0.87      0.87     50387
weighted avg       0.87      0.87      0.87     50387

The epoch:4,marcoF1ScoresTnews:0.747001
********************************confusion_matrix********************************
[[ 918   78  109    1    5    9   10   18    5    7   11   39    0   45
    11]
 [  46 3674  193   20   32    7   11  167   36   34  225   47    0   80
    20]
 [ 137  263 4350  152   21   15   31   99   72   62   51  149    0   42
   162]
 [   5   74  233 3794   25    6   37   51   25   46   39   78    0   13
   111]
 [   4   36   20   19 4099  164   71   88  859   28   51  183   45  193
    21]
 [   6   24   17    9  191 1868   26   26   46    0   79   30    0   44
     0]
 [  21   46   79   27   91   25 3723   35  227   48  208   78    0   48
    19]
 [  23  189   78   48   72   31   21 3105   93   37   56   65    0   45
    20]
 [   5   30   58   22 1036   38  232  135 4712   86   28   96    7   48
   155]
 [  12   66   59   31   40    2   51   52   86 2808   48  783    0   21
    69]
 [  19  323   54   24   46   60  110   53   40   27 2674  241    0  182
    23]
 [  40   57  143   36  163   17   56   75   83  549  194 3997    1   43
    16]
 [   0    0    0    0  129    3    1    0    5    0    0    0  152    0
     0]
 [  67   92   21    8  218   45   26   49   40   11  141   47    0 2458
     8]
 [  11   49  202   99   26    1   22   29  182   89   17   29    0   17
  3098]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.70      0.73      0.71      1266
           1       0.73      0.80      0.77      4592
           2       0.77      0.78      0.78      5606
           3       0.88      0.84      0.86      4537
           4       0.66      0.70      0.68      5881
           5       0.82      0.79      0.80      2366
           6       0.84      0.80      0.82      4675
           7       0.78      0.80      0.79      3883
           8       0.72      0.70      0.71      6688
           9       0.73      0.68      0.71      4128
          10       0.70      0.69      0.69      3876
          11       0.68      0.73      0.71      5470
          12       0.74      0.52      0.61       290
          13       0.75      0.76      0.76      3231
          14       0.83      0.80      0.81      3871

    accuracy                           0.75     60360
   macro avg       0.76      0.74      0.75     60360
weighted avg       0.75      0.75      0.75     60360

The epoch:4,marcoF1ScoresTotal:0.785728
*********************************************start valid model**************************************
[ 1000 - th batch: valid loss is 0.863653 valid total precise is 0.668113 ]
The epoch:4,marcoF1ScoresOcemotion:0.738525
********************************confusion_matrix********************************
[[132  26   2  25  12 122  13]
 [ 60 155   1  47  13  93   5]
 [  2   3  14   7   6  14   0]
 [ 19  18   1 585  55 100   3]
 [  8  13   3  79 176  68   6]
 [ 59  51   3  77  64 778   4]
 [ 12   4   1  19   3  16  23]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.45      0.40      0.42       332
           1       0.57      0.41      0.48       374
           2       0.56      0.30      0.39        46
           3       0.70      0.75      0.72       781
           4       0.53      0.50      0.52       353
           5       0.65      0.75      0.70      1036
           6       0.43      0.29      0.35        78

    accuracy                           0.62      3000
   macro avg       0.56      0.49      0.51      3000
weighted avg       0.61      0.62      0.61      3000

The epoch:4 ,marcoF1ScoresOcnli:0.871657
********************************confusion_matrix********************************
[[862 103  46]
 [154 718 129]
 [ 39  93 856]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.82      0.85      0.83      1011
           1       0.79      0.72      0.75      1001
           2       0.83      0.87      0.85       988

    accuracy                           0.81      3000
   macro avg       0.81      0.81      0.81      3000
weighted avg       0.81      0.81      0.81      3000

The epoch:4,marcoF1ScoresTnews:0.747001
********************************confusion_matrix********************************
[[ 22  11   7   1   1   0   1   5   0   2   1   4   0   3   2]
 [  7 134  19   1   5   2   2  11   4   4  19   8   0   8   1]
 [  8  29 160  11   2   3   5  12   7   6   7  11   0   2  17]
 [  0   5  15 169   5   1   7   2   2   2   0   6   0   0   7]
 [  2   5   4   2 130  17   7   4  60   4   6  10   5  16   3]
 [  0   3   0   2  14  82   0   3   5   1   8   1   0   0   0]
 [  2   2   4   3   7   3 159   4  21   2  18   7   0   1   1]
 [  3  26   5   6   7   1   1 114  17   4   2   6   0   6   2]
 [  0   2   8   6  61   2  28  14 180  13   5   8   1   4  24]
 [  1   9   6   5   5   1   3   4  10 118   1  46   0   2   9]
 [  1  20  10   3   3   7  10   5   2   2  98  12   0  12   0]
 [  3  10  12   5  13   5   3   9   5  54  17 145   0   4   1]
 [  0   0   0   0   5   0   0   0   1   0   0   0   6   0   0]
 [  1   7   5   1  16   6   4   5   8   1  15   1   0  77   2]
 [  2   3  15   5   2   1   1   2  14   3   5   4   0   0 121]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.42      0.37      0.39        60
           1       0.50      0.60      0.55       225
           2       0.59      0.57      0.58       280
           3       0.77      0.76      0.77       221
           4       0.47      0.47      0.47       275
           5       0.63      0.69      0.66       119
           6       0.69      0.68      0.68       234
           7       0.59      0.57      0.58       200
           8       0.54      0.51      0.52       356
           9       0.55      0.54      0.54       220
          10       0.49      0.53      0.51       185
          11       0.54      0.51      0.52       286
          12       0.50      0.50      0.50        12
          13       0.57      0.52      0.54       149
          14       0.64      0.68      0.66       178

    accuracy                           0.57      3000
   macro avg       0.56      0.57      0.56      3000
weighted avg       0.57      0.57      0.57      3000

The epoch:4,marcoF1ScoresTotal:0.629108
best epoch is:2 with best f1 is: 0.633296
*********************************************train model**************************************
current epoch:5
[ 1000 - th batch: valid loss is 0.165696 valid total precise is 0.805917 ]
[ 2000 - th batch: valid loss is 0.159625 valid total precise is 0.810739 ]
[ 3000 - th batch: valid loss is 0.158106 valid total precise is 0.812123 ]
[ 4000 - th batch: valid loss is 0.155064 valid total precise is 0.815037 ]
[ 5000 - th batch: valid loss is 0.153881 valid total precise is 0.812763 ]
[ 6000 - th batch: valid loss is 0.153224 valid total precise is 0.813136 ]
[ 7000 - th batch: valid loss is 0.152366 valid total precise is 0.813529 ]
[ 8000 - th batch: valid loss is 0.152475 valid total precise is 0.812810 ]
[ 9000 - th batch: valid loss is 0.151636 valid total precise is 0.813658 ]
[ 10000 - th batch: valid loss is 0.151124 valid total precise is 0.813848 ]
[ 11000 - th batch: valid loss is 0.150551 valid total precise is 0.814286 ]
