Parameters:
root    :    /share/home/crazicoco/competition/CPFC
vocabIdName    :    vocab.txt
tokenizeModel    :    hfl/chinese-roberta-wwm-ext-large
pretrainModel    :    hfl/chinese-roberta-wwm-ext-large
saveModelAddress    :    saveModelBin/
processedDataDir    :    preprocessed_data
saveLabelIdName    :    label.pt
saveTrainIdName    :    train.pt
saveValidIdName    :    valid.pt
saveTestIdName    :    test.pt
batch_size    :    9
epoch_size    :    20
loss_calculate    :    cross-entroy
lr    :    2e-05
device    :    0
max_len    :    512
lossCalculateWay    :    general
accumulate    :    True
ifparallel    :    True
debug    :    False
logfileName    :    public
a_step    :    16
description    :    try to add the lr decay
use_bert_layer    :    -1
record_addr    :    /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_28_14_42
*********************************************train model**************************************
current epoch:0
[ 1000 - th batch: valid loss is 4.966649 valid total precise is 0.395952 ]
[ 2000 - th batch: valid loss is 3.647990 valid total precise is 0.456117 ]
[ 3000 - th batch: valid loss is 3.028829 valid total precise is 0.493498 ]
[ 4000 - th batch: valid loss is 2.645095 valid total precise is 0.522381 ]
[ 5000 - th batch: valid loss is 2.385767 valid total precise is 0.541064 ]
[ 6000 - th batch: valid loss is 2.196548 valid total precise is 0.553314 ]
[ 7000 - th batch: valid loss is 2.055456 valid total precise is 0.563223 ]
[ 8000 - th batch: valid loss is 1.943509 valid total precise is 0.571280 ]
[ 9000 - th batch: valid loss is 1.851581 valid total precise is 0.577546 ]
[ 10000 - th batch: valid loss is 1.774745 valid total precise is 0.582647 ]
[ 11000 - th batch: valid loss is 1.711080 valid total precise is 0.587447 ]
[ 12000 - th batch: valid loss is 1.655179 valid total precise is 0.592633 ]
[ 13000 - th batch: valid loss is 1.605000 valid total precise is 0.596943 ]
[ 14000 - th batch: valid loss is 1.563711 valid total precise is 0.600154 ]
[ 15000 - th batch: valid loss is 1.526869 valid total precise is 0.602892 ]
The epoch:0,marcoF1ScoresOcemotion:0.445658
********************************confusion_matrix********************************
[[1148  388   13  439   84 1689   22]
 [ 451 1349   13  576   87 1542   13]
 [  26   33  153   49   27  259    1]
 [ 185  253   24 5817  516 1396    9]
 [  70   70   12 1103 1512  957   10]
 [ 598  487   40 1010  385 9035   13]
 [  91   81    1  226   46  308   77]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.45      0.30      0.36      3783
           1       0.51      0.33      0.40      4031
           2       0.60      0.28      0.38       548
           3       0.63      0.71      0.67      8200
           4       0.57      0.40      0.47      3734
           5       0.59      0.78      0.68     11568
           6       0.53      0.09      0.16       830

    accuracy                           0.58     32694
   macro avg       0.55      0.42      0.45     32694
weighted avg       0.57      0.58      0.56     32694

The epoch:0,marcoF1ScoresOcnli:0.683304
********************************confusion_matrix********************************
[[11515  3542  1658]
 [ 3411 11065  2808]
 [ 1600  2990 11798]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.70      0.69      0.69     16715
           1       0.63      0.64      0.63     17284
           2       0.73      0.72      0.72     16388

    accuracy                           0.68     50387
   macro avg       0.68      0.68      0.68     50387
weighted avg       0.68      0.68      0.68     50387

The epoch:0,marcoF1ScoresTnews:0.529084
********************************confusion_matrix********************************
[[ 521  113  268    9   15   13   36   35   18   16   32   88    0   80
    22]
 [  48 2647  443   45   83   24   38  277  123   95  421  151    0  158
    39]
 [ 162  418 3467  250   71   27   88  163  179   90  102  220    0   90
   279]
 [   6  112  439 3047   73   13  119  115   69   72   81  115    2   26
   248]
 [   9  105   69   54 2791  278  183  178 1289   54  134  339   29  310
    59]
 [  20   49   38   15  297 1393   68   76   84    6  151   57    0  106
     6]
 [  23   80  159   69  183   32 3027   75  414   78  245  147    0   78
    65]
 [  31  322  194  100  128   49   50 2293  259   67   93  140    0  114
    43]
 [   4   73  146   40 1304   73  438  258 3550  153   79  200    5   88
   277]
 [  13  139  136   65   83    6  105   89  154 1972   79 1108    2   37
   140]
 [  22  435  153   38  122  119  202  103  117   61 1773  400    0  284
    47]
 [  72  113  328   93  278   35  129  130  205  863  316 2762    1   96
    49]
 [   0    0    0    0  228    3    3    0   16    0    0    3   35    1
     1]
 [  80  172   84   15  329  101   78  109  120   38  268  118    0 1702
    17]
 [  13   91  421  210   51    8   69   67  337  148   33   50    0   39
  2334]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.51      0.41      0.46      1266
           1       0.54      0.58      0.56      4592
           2       0.55      0.62      0.58      5606
           3       0.75      0.67      0.71      4537
           4       0.46      0.47      0.47      5881
           5       0.64      0.59      0.61      2366
           6       0.65      0.65      0.65      4675
           7       0.58      0.59      0.58      3883
           8       0.51      0.53      0.52      6688
           9       0.53      0.48      0.50      4128
          10       0.47      0.46      0.46      3876
          11       0.47      0.50      0.49      5470
          12       0.47      0.12      0.19       290
          13       0.53      0.53      0.53      3231
          14       0.64      0.60      0.62      3871

    accuracy                           0.55     60360
   macro avg       0.55      0.52      0.53     60360
weighted avg       0.55      0.55      0.55     60360

The epoch:0,marcoF1ScoresTotal:0.552682
*********************************************start valid model**************************************
[ 1000 - th batch: valid loss is 0.807852 valid total precise is 0.657658 ]
The epoch:0,marcoF1ScoresOcemotion:0.503236
********************************confusion_matrix********************************
[[ 97  16   0  42   9 163   5]
 [ 36 129   1  60  12 133   3]
 [  1   1  16  10   3  15   0]
 [ 10  18   1 627  39  86   0]
 [  2  10   2 120 152  65   2]
 [ 36  26   1 115  53 805   0]
 [  6   2   0  26   1  25  18]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.52      0.29      0.37       332
           1       0.64      0.34      0.45       374
           2       0.76      0.35      0.48        46
           3       0.63      0.80      0.70       781
           4       0.57      0.43      0.49       353
           5       0.62      0.78      0.69      1036
           6       0.64      0.23      0.34        78

    accuracy                           0.61      3000
   macro avg       0.62      0.46      0.50      3000
weighted avg       0.61      0.61      0.59      3000

The epoch:0 ,marcoF1ScoresOcnli:0.798106
********************************confusion_matrix********************************
[[838 102  71]
 [126 709 166]
 [ 44  93 851]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.83      0.83      0.83      1011
           1       0.78      0.71      0.74      1001
           2       0.78      0.86      0.82       988

    accuracy                           0.80      3000
   macro avg       0.80      0.80      0.80      3000
weighted avg       0.80      0.80      0.80      3000

The epoch:0,marcoF1ScoresTnews:0.549077
********************************confusion_matrix********************************
[[ 18  11  11   1   0   1   1   5   1   3   2   1   0   4   1]
 [  4 139  30   0   3   2   2   5   2   3  18   9   0   6   2]
 [  6  25 165  12   3   2   3  12  12   4   7  10   0   3  16]
 [  0   7  18 156   2   1   6   2   5   1   2   5   0   0  16]
 [  1   5   4   1 113  11   7   3  83   2   8   9   9  16   3]
 [  1   2   0   2  14  71   1   4   7   1  13   1   0   2   0]
 [  1   3   6   2   4   3 159   2  24   2  16   7   0   3   2]
 [  0  22  10  11   8   1   0  99  22   5   5   9   0   5   3]
 [  0   2  10   4  39   3  29  12 200   8   4  10   4   3  28]
 [  1   6   6   4   6   0   4   4   7 127   2  37   0   3  13]
 [  2  22  12   4   1   3   5   5   4   3  94  16   0  13   1]
 [  5  14  12   7  12   3   4   4   7  70  19 122   0   6   1]
 [  0   0   0   0   3   0   0   0   1   0   0   0   8   0   0]
 [  1   7   3   0  15   6   5   6  10   1  13   1   0  78   3]
 [  1   2  19   3   1   1   0   1  14   1   4   1   0   1 129]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.44      0.30      0.36        60
           1       0.52      0.62      0.57       225
           2       0.54      0.59      0.56       280
           3       0.75      0.71      0.73       221
           4       0.50      0.41      0.45       275
           5       0.66      0.60      0.63       119
           6       0.70      0.68      0.69       234
           7       0.60      0.49      0.54       200
           8       0.50      0.56      0.53       356
           9       0.55      0.58      0.56       220
          10       0.45      0.51      0.48       185
          11       0.51      0.43      0.47       286
          12       0.38      0.67      0.48        12
          13       0.55      0.52      0.53       149
          14       0.59      0.72      0.65       178

    accuracy                           0.56      3000
   macro avg       0.55      0.56      0.55      3000
weighted avg       0.56      0.56      0.56      3000

The epoch:0,marcoF1ScoresTotal:0.616806
save the pretrainModel in /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_28_14_42/save_model/roberta_best_dev_f1_0.6168061676295598.pt and the classifierModel in /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_28_14_42/save_model/classifier_best_dev_f1_0.6168061676295598.pt
best epoch is:0 with best f1 is: 0.616806
*********************************************train model**************************************
current epoch:1
[ 1000 - th batch: valid loss is 0.537427 valid total precise is 0.697030 ]
[ 2000 - th batch: valid loss is 0.529982 valid total precise is 0.702407 ]
[ 3000 - th batch: valid loss is 0.521973 valid total precise is 0.704865 ]
[ 4000 - th batch: valid loss is 0.518021 valid total precise is 0.704704 ]
[ 5000 - th batch: valid loss is 0.518786 valid total precise is 0.704474 ]
[ 6000 - th batch: valid loss is 0.518632 valid total precise is 0.704710 ]
[ 7000 - th batch: valid loss is 0.518290 valid total precise is 0.704418 ]
[ 8000 - th batch: valid loss is 0.516874 valid total precise is 0.703657 ]
[ 9000 - th batch: valid loss is 0.516995 valid total precise is 0.703424 ]
[ 10000 - th batch: valid loss is 0.515667 valid total precise is 0.703993 ]
[ 11000 - th batch: valid loss is 0.514621 valid total precise is 0.705438 ]
[ 12000 - th batch: valid loss is 0.513973 valid total precise is 0.706235 ]
[ 13000 - th batch: valid loss is 0.513385 valid total precise is 0.707448 ]
[ 14000 - th batch: valid loss is 0.512781 valid total precise is 0.708011 ]
[ 15000 - th batch: valid loss is 0.512578 valid total precise is 0.708566 ]
The epoch:1,marcoF1ScoresOcemotion:0.584747
********************************confusion_matrix********************************
[[1714  331   10  266   74 1349   39]
 [ 476 1866   13  403   85 1147   41]
 [  18   30  236   41   32  187    4]
 [ 171  231    9 6497  462  798   32]
 [  64   58    3  817 2148  638    6]
 [ 564  405   31  594  332 9604   38]
 [ 100   80    3  148   48  225  226]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.55      0.45      0.50      3783
           1       0.62      0.46      0.53      4031
           2       0.77      0.43      0.55       548
           3       0.74      0.79      0.77      8200
           4       0.68      0.58      0.62      3734
           5       0.69      0.83      0.75     11568
           6       0.59      0.27      0.37       830

    accuracy                           0.68     32694
   macro avg       0.66      0.55      0.58     32694
weighted avg       0.67      0.68      0.67     32694

The epoch:1,marcoF1ScoresOcnli:0.815223
********************************confusion_matrix********************************
[[13810  2218   687]
 [ 2137 13351  1796]
 [  758  1751 13879]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.83      0.83      0.83     16715
           1       0.77      0.77      0.77     17284
           2       0.85      0.85      0.85     16388

    accuracy                           0.81     50387
   macro avg       0.82      0.82      0.82     50387
weighted avg       0.81      0.81      0.81     50387

The epoch:1,marcoF1ScoresTnews:0.627689
********************************confusion_matrix********************************
[[ 711   99  181    2   12   17   15   35    8   18   18   65    0   68
    17]
 [  57 3155  307   25   65   23   12  233   66   63  325  105    3  119
    34]
 [ 173  350 3773  196   56   19   52  151  115   94  104  207    0   61
   255]
 [  12   82  329 3424   40   12   57   73   47   54   67   93    0   19
   228]
 [  15   78   46   35 3281  230  116  135 1191   46  114  247   48  263
    36]
 [  16   35   23   14  270 1617   30   64   57    7  126   37    1   67
     2]
 [  23   58  120   35  163   39 3295   76  316   71  239  137    0   60
    43]
 [  34  310  142   83  110   52   32 2587  163   57   74  113    0   85
    41]
 [   3   52  118   28 1165   73  371  225 3997  121   57  126    7   63
   282]
 [   9   97  105   35   60    1   64   86  117 2339   80  968    0   32
   135]
 [  21  443  102   28   66   87  179   77   80   40 2081  377    0  265
    30]
 [  73  116  254   64  273   20   75   96  132  801  242 3214    0   76
    34]
 [   0    0    0    0  167    3    2    0    6    0    0    0  111    0
     1]
 [  86  138   48    9  295   95   46   97   83   34  212   69    0 2010
     9]
 [  16   69  319  122   28    4   49   49  258  100   25   43    0   25
  2764]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.57      0.56      0.57      1266
           1       0.62      0.69      0.65      4592
           2       0.64      0.67      0.66      5606
           3       0.84      0.75      0.79      4537
           4       0.54      0.56      0.55      5881
           5       0.71      0.68      0.69      2366
           6       0.75      0.70      0.73      4675
           7       0.65      0.67      0.66      3883
           8       0.60      0.60      0.60      6688
           9       0.61      0.57      0.59      4128
          10       0.55      0.54      0.54      3876
          11       0.55      0.59      0.57      5470
          12       0.65      0.38      0.48       290
          13       0.63      0.62      0.62      3231
          14       0.71      0.71      0.71      3871

    accuracy                           0.64     60360
   macro avg       0.64      0.62      0.63     60360
weighted avg       0.64      0.64      0.64     60360

The epoch:1,marcoF1ScoresTotal:0.675886
*********************************************start valid model**************************************
[ 1000 - th batch: valid loss is 0.762002 valid total precise is 0.666444 ]
The epoch:1,marcoF1ScoresOcemotion:0.518184
********************************confusion_matrix********************************
[[118  24   3  32   9 138   8]
 [ 45 154   1  40  11 119   4]
 [  0   4  17   6   3  16   0]
 [ 14  25   1 582  55 103   1]
 [  4  12   2  86 175  71   3]
 [ 45  47   6  75  46 815   2]
 [  9   5   0  19   1  25  19]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.50      0.36      0.42       332
           1       0.57      0.41      0.48       374
           2       0.57      0.37      0.45        46
           3       0.69      0.75      0.72       781
           4       0.58      0.50      0.54       353
           5       0.63      0.79      0.70      1036
           6       0.51      0.24      0.33        78

    accuracy                           0.63      3000
   macro avg       0.58      0.49      0.52      3000
weighted avg       0.62      0.63      0.61      3000

The epoch:1 ,marcoF1ScoresOcnli:0.804568
********************************confusion_matrix********************************
[[873  90  48]
 [159 720 122]
 [ 55 109 824]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.80      0.86      0.83      1011
           1       0.78      0.72      0.75      1001
           2       0.83      0.83      0.83       988

    accuracy                           0.81      3000
   macro avg       0.81      0.81      0.80      3000
weighted avg       0.81      0.81      0.80      3000

The epoch:1,marcoF1ScoresTnews:0.562938
********************************confusion_matrix********************************
[[ 22  11   8   1   0   1   1   5   1   1   1   3   0   3   2]
 [  6 135  25   0   4   2   1   6   2   5  19  10   0   7   3]
 [  8  32 163  10   3   2   4  12   8   8   7  13   0   2   8]
 [  0   6  20 155   3   2   8   4   4   1   1   4   0   0  13]
 [  2   5   4   1 136  22   6   5  53   2   4  13   3  17   2]
 [  1   2   0   2  15  76   1   4   4   1  10   1   0   2   0]
 [  1   3   4   2   6   4 156   2  24   2  15  10   0   3   2]
 [  2  22   7   7   6   2   2 112  16   6   1   7   0   9   1]
 [  0   2   9   4  61   3  23  14 184   9   5  12   0   6  24]
 [  1   6   6   6   4   0   4   4   8 106   3  60   0   4   8]
 [  2  22  11   4   1   9   7   5   4   3  89  13   0  14   1]
 [  7  13  12   5   8   3   3   3   4  47  19 158   0   4   0]
 [  0   0   0   0   5   0   0   0   1   0   0   0   6   0   0]
 [  1   7   4   1  14   6   1   3   8   0  10   3   0  90   1]
 [  1   4  23   5   2   1   0   1  15   2   4   7   0   1 112]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.41      0.37      0.39        60
           1       0.50      0.60      0.55       225
           2       0.55      0.58      0.57       280
           3       0.76      0.70      0.73       221
           4       0.51      0.49      0.50       275
           5       0.57      0.64      0.60       119
           6       0.72      0.67      0.69       234
           7       0.62      0.56      0.59       200
           8       0.55      0.52      0.53       356
           9       0.55      0.48      0.51       220
          10       0.47      0.48      0.48       185
          11       0.50      0.55      0.53       286
          12       0.67      0.50      0.57        12
          13       0.56      0.60      0.58       149
          14       0.63      0.63      0.63       178

    accuracy                           0.57      3000
   macro avg       0.57      0.56      0.56      3000
weighted avg       0.57      0.57      0.57      3000

The epoch:1,marcoF1ScoresTotal:0.628563
save the pretrainModel in /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_28_14_42/save_model/roberta_best_dev_f1_0.6285634742700346.pt and the classifierModel in /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_28_14_42/save_model/classifier_best_dev_f1_0.6285634742700346.pt
best epoch is:1 with best f1 is: 0.628563
*********************************************train model**************************************
current epoch:2
[ 1000 - th batch: valid loss is 0.454985 valid total precise is 0.721277 ]
[ 2000 - th batch: valid loss is 0.457759 valid total precise is 0.719304 ]
[ 3000 - th batch: valid loss is 0.458986 valid total precise is 0.716980 ]
[ 4000 - th batch: valid loss is 0.457123 valid total precise is 0.717568 ]
[ 5000 - th batch: valid loss is 0.453264 valid total precise is 0.719344 ]
[ 6000 - th batch: valid loss is 0.453168 valid total precise is 0.718694 ]
[ 7000 - th batch: valid loss is 0.453366 valid total precise is 0.717833 ]
[ 8000 - th batch: valid loss is 0.453633 valid total precise is 0.717840 ]
[ 9000 - th batch: valid loss is 0.452826 valid total precise is 0.717919 ]
[ 10000 - th batch: valid loss is 0.452618 valid total precise is 0.717794 ]
[ 11000 - th batch: valid loss is 0.452551 valid total precise is 0.718863 ]
[ 12000 - th batch: valid loss is 0.451468 valid total precise is 0.720356 ]
[ 13000 - th batch: valid loss is 0.450501 valid total precise is 0.721201 ]
[ 14000 - th batch: valid loss is 0.450170 valid total precise is 0.721575 ]
[ 15000 - th batch: valid loss is 0.449759 valid total precise is 0.721989 ]
The epoch:2,marcoF1ScoresOcemotion:0.604152
********************************confusion_matrix********************************
[[1851  352   12  245   63 1228   32]
 [ 463 1955   11  379   78 1107   38]
 [  22   28  251   30   32  183    2]
 [ 143  222   12 6574  483  742   24]
 [  57   54    5  750 2264  599    5]
 [ 568  427   35  513  330 9667   28]
 [ 100   78    5  149   45  219  234]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.58      0.49      0.53      3783
           1       0.63      0.48      0.55      4031
           2       0.76      0.46      0.57       548
           3       0.76      0.80      0.78      8200
           4       0.69      0.61      0.64      3734
           5       0.70      0.84      0.76     11568
           6       0.64      0.28      0.39       830

    accuracy                           0.70     32694
   macro avg       0.68      0.57      0.60     32694
weighted avg       0.69      0.70      0.69     32694

The epoch:2,marcoF1ScoresOcnli:0.821756
********************************confusion_matrix********************************
[[13982  2122   611]
 [ 2158 13475  1651]
 [  747  1731 13910]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.83      0.84      0.83     16715
           1       0.78      0.78      0.78     17284
           2       0.86      0.85      0.85     16388

    accuracy                           0.82     50387
   macro avg       0.82      0.82      0.82     50387
weighted avg       0.82      0.82      0.82     50387

The epoch:2,marcoF1ScoresTnews:0.642871
********************************confusion_matrix********************************
[[ 758   93  169    2    9   13   18   31    6   14   15   61    0   63
    14]
 [  65 3231  281   33   53   26   16  209   61   55  310   99    3  119
    31]
 [ 190  353 3847  182   45   19   52  150  107   85   90  205    0   61
   220]
 [  13   83  322 3473   37   10   53   77   35   63   63  105    0   16
   187]
 [  11   78   43   30 3438  268  111  130 1041   40   92  270   40  257
    32]
 [  14   44   24    7  244 1688   34   54   45    3  101   32    1   73
     2]
 [  34   61  104   37  145   35 3353   60  333   84  222  114    0   55
    38]
 [  37  282  136   65   98   56   33 2658  142   58   71  108    0   95
    44]
 [   3   54  110   21 1199   80  304  212 4085  112   53  149    5   62
   239]
 [  11  107   92   32   54    4   55   76  110 2401   71  977    0   34
   104]
 [  26  430   97   30   65  105  162   68   67   44 2215  288    0  254
    25]
 [  69   98  214   61  221   27   79   90  122  699  301 3392    0   67
    30]
 [   0    0    0    1  177    3    2    0    5    0    1    0  100    1
     0]
 [  85  125   46   13  285   91   38   87   65   28  204   88    0 2065
    11]
 [  13   67  301  120   29    4   41   47  270  119   32   41    0   23
  2764]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.57      0.60      0.58      1266
           1       0.63      0.70      0.67      4592
           2       0.66      0.69      0.68      5606
           3       0.85      0.77      0.80      4537
           4       0.56      0.58      0.57      5881
           5       0.69      0.71      0.70      2366
           6       0.77      0.72      0.74      4675
           7       0.67      0.68      0.68      3883
           8       0.63      0.61      0.62      6688
           9       0.63      0.58      0.61      4128
          10       0.58      0.57      0.57      3876
          11       0.57      0.62      0.60      5470
          12       0.67      0.34      0.46       290
          13       0.64      0.64      0.64      3231
          14       0.74      0.71      0.73      3871

    accuracy                           0.65     60360
   macro avg       0.66      0.64      0.64     60360
weighted avg       0.66      0.65      0.65     60360

The epoch:2,marcoF1ScoresTotal:0.689593
*********************************************start valid model**************************************
[ 1000 - th batch: valid loss is 0.788252 valid total precise is 0.665332 ]
The epoch:2,marcoF1ScoresOcemotion:0.521942
********************************confusion_matrix********************************
[[123  27   4  32   8 128  10]
 [ 48 160   1  42  11 106   6]
 [  0   4  17   7   4  14   0]
 [ 15  27   1 588  52  97   1]
 [  5  12   2  90 172  69   3]
 [ 50  52   7  82  44 798   3]
 [  9   5   0  18   1  23  22]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.49      0.37      0.42       332
           1       0.56      0.43      0.48       374
           2       0.53      0.37      0.44        46
           3       0.68      0.75      0.72       781
           4       0.59      0.49      0.53       353
           5       0.65      0.77      0.70      1036
           6       0.49      0.28      0.36        78

    accuracy                           0.63      3000
   macro avg       0.57      0.49      0.52      3000
weighted avg       0.62      0.63      0.62      3000

The epoch:2 ,marcoF1ScoresOcnli:0.803447
********************************confusion_matrix********************************
[[858  98  55]
 [150 715 136]
 [ 52  95 841]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.81      0.85      0.83      1011
           1       0.79      0.71      0.75      1001
           2       0.81      0.85      0.83       988

    accuracy                           0.80      3000
   macro avg       0.80      0.80      0.80      3000
weighted avg       0.80      0.80      0.80      3000

The epoch:2,marcoF1ScoresTnews:0.562625
********************************confusion_matrix********************************
[[ 21  11   8   1   0   1   1   5   1   2   1   3   0   3   2]
 [  6 131  26   0   4   2   1   6   2   8  19   9   0   8   3]
 [  7  30 158  13   5   2   4  13   8   8   7  14   0   2   9]
 [  0   5  17 160   4   1   8   4   4   1   1   4   0   0  12]
 [  2   5   2   3 137  20   6   5  54   2   5  12   3  17   2]
 [  1   2   0   2  16  75   1   4   4   1  10   1   0   2   0]
 [  1   3   4   2   6   3 156   3  24   2  15  10   0   3   2]
 [  1  21   6   7   8   1   1 116  16   5   2   6   0   9   1]
 [  0   2   9   4  64   3  22  12 184   9   5  12   0   5  25]
 [  1   6   6   6   4   0   4   4   9 111   2  55   0   4   8]
 [  2  20   9   5   2   7   6   5   5   4  91  13   0  15   1]
 [  6  13  10   5   8   3   3   4   6  60  17 147   0   4   0]
 [  0   0   0   0   5   0   0   0   1   0   0   0   6   0   0]
 [  1   7   3   1  14   6   1   3   8   0  10   3   0  90   2]
 [  1   4  21   6   2   1   0   1  15   2   4   7   0   1 113]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.42      0.35      0.38        60
           1       0.50      0.58      0.54       225
           2       0.57      0.56      0.57       280
           3       0.74      0.72      0.73       221
           4       0.49      0.50      0.49       275
           5       0.60      0.63      0.61       119
           6       0.73      0.67      0.70       234
           7       0.63      0.58      0.60       200
           8       0.54      0.52      0.53       356
           9       0.52      0.50      0.51       220
          10       0.48      0.49      0.49       185
          11       0.50      0.51      0.51       286
          12       0.67      0.50      0.57        12
          13       0.55      0.60      0.58       149
          14       0.63      0.63      0.63       178

    accuracy                           0.57      3000
   macro avg       0.57      0.56      0.56      3000
weighted avg       0.57      0.57      0.57      3000

The epoch:2,marcoF1ScoresTotal:0.629338
save the pretrainModel in /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_28_14_42/save_model/roberta_best_dev_f1_0.6293381969343871.pt and the classifierModel in /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_28_14_42/save_model/classifier_best_dev_f1_0.6293381969343871.pt
best epoch is:2 with best f1 is: 0.629338
*********************************************train model**************************************
current epoch:3
[ 1000 - th batch: valid loss is 0.426361 valid total precise is 0.723724 ]
[ 2000 - th batch: valid loss is 0.435544 valid total precise is 0.719415 ]
[ 3000 - th batch: valid loss is 0.434890 valid total precise is 0.721722 ]
[ 4000 - th batch: valid loss is 0.434877 valid total precise is 0.721847 ]
[ 5000 - th batch: valid loss is 0.435122 valid total precise is 0.721589 ]
[ 6000 - th batch: valid loss is 0.435708 valid total precise is 0.721491 ]
[ 7000 - th batch: valid loss is 0.435302 valid total precise is 0.721024 ]
[ 8000 - th batch: valid loss is 0.436911 valid total precise is 0.720632 ]
[ 9000 - th batch: valid loss is 0.437652 valid total precise is 0.720055 ]
[ 10000 - th batch: valid loss is 0.437910 valid total precise is 0.720150 ]
[ 11000 - th batch: valid loss is 0.438222 valid total precise is 0.720843 ]
[ 12000 - th batch: valid loss is 0.438197 valid total precise is 0.721810 ]
[ 13000 - th batch: valid loss is 0.437349 valid total precise is 0.722919 ]
[ 14000 - th batch: valid loss is 0.437099 valid total precise is 0.723814 ]
[ 15000 - th batch: valid loss is 0.437074 valid total precise is 0.724189 ]
The epoch:3,marcoF1ScoresOcemotion:0.607444
********************************confusion_matrix********************************
[[1892  352   15  247   57 1187   33]
 [ 464 2006   12  356   78 1082   33]
 [  27   23  246   34   28  188    2]
 [ 148  212   12 6589  471  739   29]
 [  52   61    7  747 2267  590   10]
 [ 572  423   33  519  311 9675   35]
 [ 104   83    3  147   46  206  241]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.58      0.50      0.54      3783
           1       0.63      0.50      0.56      4031
           2       0.75      0.45      0.56       548
           3       0.76      0.80      0.78      8200
           4       0.70      0.61      0.65      3734
           5       0.71      0.84      0.77     11568
           6       0.63      0.29      0.40       830

    accuracy                           0.70     32694
   macro avg       0.68      0.57      0.61     32694
weighted avg       0.70      0.70      0.69     32694

The epoch:3,marcoF1ScoresOcnli:0.823952
********************************confusion_matrix********************************
[[13964  2115   636]
 [ 2090 13471  1723]
 [  727  1612 14049]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.83      0.84      0.83     16715
           1       0.78      0.78      0.78     17284
           2       0.86      0.86      0.86     16388

    accuracy                           0.82     50387
   macro avg       0.82      0.82      0.82     50387
weighted avg       0.82      0.82      0.82     50387

The epoch:3,marcoF1ScoresTnews:0.642920
********************************confusion_matrix********************************
[[ 759   95  157    2    9   10   15   27    9   15   24   70    0   58
    16]
 [  67 3213  282   32   60   20   16  219   58   56  327  104    3  106
    29]
 [ 179  321 3851  183   40   16   47  145  118   99  105  210    0   67
   225]
 [   9   74  307 3514   44   10   40   80   41   59   66   90    0   12
   191]
 [  12   76   43   37 3417  261  110  137 1049   37   89  267   48  263
    35]
 [  17   41   23    8  251 1668   32   50   53    4  111   32    0   74
     2]
 [  30   55  105   45  148   36 3346   51  318   80  233  123    0   61
    44]
 [  40  283  131   73   92   46   28 2669  151   55   76  114    0   81
    44]
 [   5   49  111   25 1206   80  297  199 4093  108   48  135    5   63
   264]
 [  11   92   97   34   58    3   53   66  106 2403   72  990    0   30
   113]
 [  23  435   84   32   66   94  172   67   72   40 2224  308    0  231
    28]
 [  69   92  224   60  221   23   82   96  134  712  296 3358    0   68
    35]
 [   0    1    0    0  180    3    2    0    6    0    1    0   97    0
     0]
 [  87  116   46   10  275   85   36   87   70   29  214   86    0 2076
    14]
 [  12   70  286  121   25    4   37   47  243  114   20   42    0   22
  2828]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.57      0.60      0.59      1266
           1       0.64      0.70      0.67      4592
           2       0.67      0.69      0.68      5606
           3       0.84      0.77      0.81      4537
           4       0.56      0.58      0.57      5881
           5       0.71      0.70      0.71      2366
           6       0.78      0.72      0.74      4675
           7       0.68      0.69      0.68      3883
           8       0.63      0.61      0.62      6688
           9       0.63      0.58      0.61      4128
          10       0.57      0.57      0.57      3876
          11       0.57      0.61      0.59      5470
          12       0.63      0.33      0.44       290
          13       0.65      0.64      0.64      3231
          14       0.73      0.73      0.73      3871

    accuracy                           0.65     60360
   macro avg       0.66      0.64      0.64     60360
weighted avg       0.66      0.65      0.66     60360

The epoch:3,marcoF1ScoresTotal:0.691439
*********************************************start valid model**************************************
[ 1000 - th batch: valid loss is 0.779817 valid total precise is 0.664776 ]
The epoch:3,marcoF1ScoresOcemotion:0.521446
********************************confusion_matrix********************************
[[123  27   4  31   9 127  11]
 [ 46 159   1  43  11 108   6]
 [  0   4  17   7   4  14   0]
 [ 15  27   1 588  52  96   2]
 [  5  12   2  90 172  69   3]
 [ 47  52   7  82  44 801   3]
 [  9   5   0  18   1  23  22]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.50      0.37      0.43       332
           1       0.56      0.43      0.48       374
           2       0.53      0.37      0.44        46
           3       0.68      0.75      0.72       781
           4       0.59      0.49      0.53       353
           5       0.65      0.77      0.70      1036
           6       0.47      0.28      0.35        78

    accuracy                           0.63      3000
   macro avg       0.57      0.49      0.52      3000
weighted avg       0.62      0.63      0.62      3000

The epoch:3 ,marcoF1ScoresOcnli:0.800026
********************************confusion_matrix********************************
[[852 103  56]
 [155 708 138]
 [ 49  95 844]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.81      0.84      0.82      1011
           1       0.78      0.71      0.74      1001
           2       0.81      0.85      0.83       988

    accuracy                           0.80      3000
   macro avg       0.80      0.80      0.80      3000
weighted avg       0.80      0.80      0.80      3000

The epoch:3,marcoF1ScoresTnews:0.563411
********************************confusion_matrix********************************
[[ 22  11   7   1   0   1   1   5   1   2   1   3   0   3   2]
 [  6 131  26   0   4   2   1   6   2   8  19   9   0   8   3]
 [  7  30 158  13   5   2   4  13   8   8   7  14   0   2   9]
 [  0   5  17 160   4   1   8   4   4   1   1   4   0   0  12]
 [  2   5   2   3 138  19   6   5  54   2   5  12   3  17   2]
 [  1   2   0   2  16  75   1   4   4   1  10   1   0   2   0]
 [  1   3   4   2   6   3 156   3  24   2  15  10   0   3   2]
 [  1  21   6   7   8   1   1 116  16   5   2   6   0   9   1]
 [  0   2   9   4  64   3  22  12 184   9   5  12   0   5  25]
 [  1   6   6   6   4   0   4   4   9 111   2  55   0   4   8]
 [  2  20   9   5   2   7   6   5   5   4  90  14   0  15   1]
 [  6  13  10   5   8   3   4   4   6  60  17 146   0   4   0]
 [  0   0   0   0   5   0   0   0   1   0   0   0   6   0   0]
 [  1   7   3   1  14   6   1   3   8   0  10   3   0  90   2]
 [  1   4  21   6   2   1   0   1  15   2   4   7   0   1 113]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.43      0.37      0.40        60
           1       0.50      0.58      0.54       225
           2       0.57      0.56      0.57       280
           3       0.74      0.72      0.73       221
           4       0.49      0.50      0.50       275
           5       0.60      0.63      0.62       119
           6       0.73      0.67      0.69       234
           7       0.63      0.58      0.60       200
           8       0.54      0.52      0.53       356
           9       0.52      0.50      0.51       220
          10       0.48      0.49      0.48       185
          11       0.49      0.51      0.50       286
          12       0.67      0.50      0.57        12
          13       0.55      0.60      0.58       149
          14       0.63      0.63      0.63       178

    accuracy                           0.57      3000
   macro avg       0.57      0.56      0.56      3000
weighted avg       0.57      0.57      0.57      3000

The epoch:3,marcoF1ScoresTotal:0.628295
best epoch is:2 with best f1 is: 0.629338
*********************************************train model**************************************
current epoch:4
[ 1000 - th batch: valid loss is 0.443604 valid total precise is 0.728729 ]
[ 2000 - th batch: valid loss is 0.435486 valid total precise is 0.724696 ]
[ 3000 - th batch: valid loss is 0.442328 valid total precise is 0.720499 ]
[ 4000 - th batch: valid loss is 0.440233 valid total precise is 0.719847 ]
[ 5000 - th batch: valid loss is 0.441825 valid total precise is 0.719588 ]
[ 6000 - th batch: valid loss is 0.443369 valid total precise is 0.718786 ]
[ 7000 - th batch: valid loss is 0.443397 valid total precise is 0.719500 ]
[ 8000 - th batch: valid loss is 0.442612 valid total precise is 0.720062 ]
[ 9000 - th batch: valid loss is 0.443083 valid total precise is 0.719784 ]
[ 10000 - th batch: valid loss is 0.442219 valid total precise is 0.720761 ]
[ 11000 - th batch: valid loss is 0.441716 valid total precise is 0.721864 ]
[ 12000 - th batch: valid loss is 0.440946 valid total precise is 0.722597 ]
[ 13000 - th batch: valid loss is 0.440685 valid total precise is 0.723380 ]
[ 14000 - th batch: valid loss is 0.440229 valid total precise is 0.723631 ]
[ 15000 - th batch: valid loss is 0.440069 valid total precise is 0.724033 ]
The epoch:4,marcoF1ScoresOcemotion:0.604383
********************************confusion_matrix********************************
[[1853  356   12  257   64 1213   28]
 [ 456 1994   11  360   79 1092   39]
 [  22   28  245   30   30  190    3]
 [ 162  220   14 6585  473  711   35]
 [  59   60    7  770 2262  570    6]
 [ 577  421   29  493  311 9702   35]
 [ 102   83    4  143   47  216  235]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.57      0.49      0.53      3783
           1       0.63      0.49      0.55      4031
           2       0.76      0.45      0.56       548
           3       0.76      0.80      0.78      8200
           4       0.69      0.61      0.65      3734
           5       0.71      0.84      0.77     11568
           6       0.62      0.28      0.39       830

    accuracy                           0.70     32694
   macro avg       0.68      0.57      0.60     32694
weighted avg       0.69      0.70      0.69     32694

The epoch:4,marcoF1ScoresOcnli:0.824195
********************************confusion_matrix********************************
[[14006  2072   637]
 [ 2083 13470  1731]
 [  727  1640 14021]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.83      0.84      0.84     16715
           1       0.78      0.78      0.78     17284
           2       0.86      0.86      0.86     16388

    accuracy                           0.82     50387
   macro avg       0.82      0.82      0.82     50387
weighted avg       0.82      0.82      0.82     50387

The epoch:4,marcoF1ScoresTnews:0.646246
********************************confusion_matrix********************************
[[ 771   89  158    1   11   12   19   28   10   13   18   66    0   56
    14]
 [  62 3225  284   32   54   25   19  218   60   53  331   94    3  103
    29]
 [ 188  339 3838  194   50   23   53  145  100   90   86  209    0   61
   230]
 [  10   74  302 3493   44    8   50   81   38   53   71  109    0   13
   191]
 [  13   80   36   37 3433  262  110  131 1069   33   88  248   38  272
    31]
 [  15   36   24    9  251 1676   30   56   56    5   98   38    1   68
     3]
 [  30   55  111   39  130   35 3376   64  330   80  226  107    0   52
    40]
 [  35  272  122   72  102   52   30 2695  149   56   65  109    0   83
    41]
 [   3   46  104   21 1231   65  315  206 4084  115   49  127    2   69
   251]
 [  16  100   89   38   64    3   54   81  117 2400   61  966    0   29
   110]
 [  24  430   95   35   68   96  160   70   70   40 2202  314    0  243
    29]
 [  69   88  222   61  236   22   84   85  125  759  300 3334    0   58
    27]
 [   0    0    0    0  173    2    2    0    7    0    1    0  104    1
     0]
 [  76  113   48   10  275   84   42   86   59   30  216   84    0 2098
    10]
 [  10   70  300  121   25    4   40   46  245  113   25   35    0   21
  2816]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.58      0.61      0.60      1266
           1       0.64      0.70      0.67      4592
           2       0.67      0.68      0.68      5606
           3       0.84      0.77      0.80      4537
           4       0.56      0.58      0.57      5881
           5       0.71      0.71      0.71      2366
           6       0.77      0.72      0.75      4675
           7       0.68      0.69      0.68      3883
           8       0.63      0.61      0.62      6688
           9       0.62      0.58      0.60      4128
          10       0.57      0.57      0.57      3876
          11       0.57      0.61      0.59      5470
          12       0.70      0.36      0.47       290
          13       0.65      0.65      0.65      3231
          14       0.74      0.73      0.73      3871

    accuracy                           0.66     60360
   macro avg       0.66      0.64      0.65     60360
weighted avg       0.66      0.66      0.66     60360

The epoch:4,marcoF1ScoresTotal:0.691608
*********************************************start valid model**************************************
[ 1000 - th batch: valid loss is 0.802433 valid total precise is 0.665110 ]
The epoch:4,marcoF1ScoresOcemotion:0.521446
********************************confusion_matrix********************************
[[123  27   4  31   9 127  11]
 [ 46 159   1  43  11 108   6]
 [  0   4  17   7   4  14   0]
 [ 15  27   1 588  52  96   2]
 [  5  12   2  90 172  69   3]
 [ 47  52   7  82  44 801   3]
 [  9   5   0  18   1  23  22]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.50      0.37      0.43       332
           1       0.56      0.43      0.48       374
           2       0.53      0.37      0.44        46
           3       0.68      0.75      0.72       781
           4       0.59      0.49      0.53       353
           5       0.65      0.77      0.70      1036
           6       0.47      0.28      0.35        78

    accuracy                           0.63      3000
   macro avg       0.57      0.49      0.52      3000
weighted avg       0.62      0.63      0.62      3000

The epoch:4 ,marcoF1ScoresOcnli:0.801850
********************************confusion_matrix********************************
[[855  99  57]
 [152 715 134]
 [ 48 101 839]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.81      0.85      0.83      1011
           1       0.78      0.71      0.75      1001
           2       0.81      0.85      0.83       988

    accuracy                           0.80      3000
   macro avg       0.80      0.80      0.80      3000
weighted avg       0.80      0.80      0.80      3000

The epoch:4,marcoF1ScoresTnews:0.563411
********************************confusion_matrix********************************
[[ 22  11   7   1   0   1   1   5   1   2   1   3   0   3   2]
 [  6 131  26   0   4   2   1   6   2   8  19   9   0   8   3]
 [  7  30 158  13   5   2   4  13   8   8   7  14   0   2   9]
 [  0   5  17 160   4   1   8   4   4   1   1   4   0   0  12]
 [  2   5   2   3 138  19   6   5  54   2   5  12   3  17   2]
 [  1   2   0   2  16  75   1   4   4   1  10   1   0   2   0]
 [  1   3   4   2   6   3 156   3  24   2  15  10   0   3   2]
 [  1  21   6   7   8   1   1 116  16   5   2   6   0   9   1]
 [  0   2   9   4  64   3  22  12 184   9   5  12   0   5  25]
 [  1   6   6   6   4   0   4   4   9 111   2  55   0   4   8]
 [  2  20   9   5   2   7   6   5   5   4  90  14   0  15   1]
 [  6  13  10   5   8   3   4   4   6  60  17 146   0   4   0]
 [  0   0   0   0   5   0   0   0   1   0   0   0   6   0   0]
 [  1   7   3   1  14   6   1   3   8   0  10   3   0  90   2]
 [  1   4  21   6   2   1   0   1  15   2   4   7   0   1 113]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.43      0.37      0.40        60
           1       0.50      0.58      0.54       225
           2       0.57      0.56      0.57       280
           3       0.74      0.72      0.73       221
           4       0.49      0.50      0.50       275
           5       0.60      0.63      0.62       119
           6       0.73      0.67      0.69       234
           7       0.63      0.58      0.60       200
           8       0.54      0.52      0.53       356
           9       0.52      0.50      0.51       220
          10       0.48      0.49      0.48       185
          11       0.49      0.51      0.50       286
          12       0.67      0.50      0.57        12
          13       0.55      0.60      0.58       149
          14       0.63      0.63      0.63       178

    accuracy                           0.57      3000
   macro avg       0.57      0.56      0.56      3000
weighted avg       0.57      0.57      0.57      3000

The epoch:4,marcoF1ScoresTotal:0.628902
best epoch is:2 with best f1 is: 0.629338
*********************************************train model**************************************
current epoch:5
[ 1000 - th batch: valid loss is 0.460845 valid total precise is 0.719164 ]
[ 2000 - th batch: valid loss is 0.445779 valid total precise is 0.722917 ]
[ 3000 - th batch: valid loss is 0.439631 valid total precise is 0.722648 ]
[ 4000 - th batch: valid loss is 0.439254 valid total precise is 0.721569 ]
[ 5000 - th batch: valid loss is 0.436996 valid total precise is 0.721900 ]
[ 6000 - th batch: valid loss is 0.438057 valid total precise is 0.721361 ]
[ 7000 - th batch: valid loss is 0.438744 valid total precise is 0.721278 ]
[ 8000 - th batch: valid loss is 0.439350 valid total precise is 0.721215 ]
[ 9000 - th batch: valid loss is 0.440152 valid total precise is 0.721130 ]
[ 10000 - th batch: valid loss is 0.439505 valid total precise is 0.721694 ]
[ 11000 - th batch: valid loss is 0.438959 valid total precise is 0.722540 ]
[ 12000 - th batch: valid loss is 0.438890 valid total precise is 0.722977 ]
[ 13000 - th batch: valid loss is 0.438430 valid total precise is 0.723902 ]
[ 14000 - th batch: valid loss is 0.438306 valid total precise is 0.724361 ]
[ 15000 - th batch: valid loss is 0.437940 valid total precise is 0.725071 ]
