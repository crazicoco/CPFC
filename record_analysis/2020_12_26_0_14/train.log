Parameters:
root    :    /share/home/crazicoco/competition/CPFC
vocabIdName    :    vocab.txt
tokenizeModel    :    hfl/chinese-roberta-wwm-ext-large
pretrainModel    :    hfl/chinese-roberta-wwm-ext-large
saveModelAddress    :    saveModelBin/
processedDataDir    :    preprocessed_data
saveLabelIdName    :    label.pt
saveTrainIdName    :    train.pt
saveValidIdName    :    valid.pt
saveTestIdName    :    test.pt
batch_size    :    9
epoch_size    :    20
loss_calculate    :    cross-entroy
lr    :    2e-05
device    :    0
max_len    :    512
lossCalculateWay    :    general
accumulate    :    True
ifparallel    :    True
debug    :    False
logfileName    :    public
record_addr    :    /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_26_0_14
*********************************************train model**************************************
current epoch:0
[ 1000 - th batch: valid loss is 4.518696 valid total precise is 0.405072 ]
[ 2000 - th batch: valid loss is 3.406693 valid total precise is 0.455061 ]
[ 3000 - th batch: valid loss is 2.879765 valid total precise is 0.489274 ]
[ 4000 - th batch: valid loss is 2.550269 valid total precise is 0.512656 ]
[ 5000 - th batch: valid loss is 2.324310 valid total precise is 0.531462 ]
[ 6000 - th batch: valid loss is 2.153718 valid total precise is 0.544294 ]
[ 7000 - th batch: valid loss is 2.021510 valid total precise is 0.555032 ]
[ 8000 - th batch: valid loss is 1.914017 valid total precise is 0.563584 ]
[ 9000 - th batch: valid loss is 1.827266 valid total precise is 0.570705 ]
[ 10000 - th batch: valid loss is 1.755997 valid total precise is 0.575991 ]
[ 11000 - th batch: valid loss is 1.696112 valid total precise is 0.581174 ]
[ 12000 - th batch: valid loss is 1.643737 valid total precise is 0.586438 ]
[ 13000 - th batch: valid loss is 1.599856 valid total precise is 0.590062 ]
[ 14000 - th batch: valid loss is 1.558306 valid total precise is 0.594130 ]
[ 15000 - th batch: valid loss is 1.522352 valid total precise is 0.597462 ]
The epoch:0,marcoF1ScoresOcemotion:0.445375
********************************confusion_matrix********************************
[[1177  385   15  420   72 1695   19]
 [ 432 1349   12  560  103 1561   14]
 [  16   36  152   50   26  267    1]
 [ 187  259   10 5784  513 1432   15]
 [  79   92    6 1055 1484 1013    5]
 [ 657  445   25 1010  396 9020   15]
 [ 104   88    3  192   65  306   72]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.44      0.31      0.37      3783
           1       0.51      0.33      0.40      4031
           2       0.68      0.28      0.39       548
           3       0.64      0.71      0.67      8200
           4       0.56      0.40      0.46      3734
           5       0.59      0.78      0.67     11568
           6       0.51      0.09      0.15       830

    accuracy                           0.58     32694
   macro avg       0.56      0.41      0.45     32694
weighted avg       0.57      0.58      0.56     32694

The epoch:0,marcoF1ScoresOcnli:0.670892
********************************confusion_matrix********************************
[[11364  3650  1701]
 [ 3707 10763  2814]
 [ 1843  2916 11629]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.67      0.68      0.68     16715
           1       0.62      0.62      0.62     17284
           2       0.72      0.71      0.71     16388

    accuracy                           0.67     50387
   macro avg       0.67      0.67      0.67     50387
weighted avg       0.67      0.67      0.67     50387

The epoch:0,marcoF1ScoresTnews:0.526240
********************************confusion_matrix********************************
[[ 506  133  265    6   26   20   25   44   18   13   23   70    0   96
    21]
 [  49 2653  456   35   91   18   25  292   97   84  429  143    0  161
    59]
 [ 179  451 3450  224   84   26   67  167  157  106  103  234    0   75
   283]
 [   9  112  476 3056   67   11   93  106   64   68   83  141    2   23
   226]
 [   9   96   86   48 2819  295  172  166 1287   49  126  325   29  313
    61]
 [  20   57   36   10  311 1406   48   72   96    1  151   60    0   92
     6]
 [  28   83  158   55  180   46 3012   75  408   90  266  128    1   63
    82]
 [  36  333  198   96  152   52   49 2285  233   62   91  137    0  107
    52]
 [   7   68  190   38 1315   84  424  254 3529  148   69  199    5   93
   265]
 [  17  151  142   50   92    6   95   77  125 1972   88 1130    0   45
   138]
 [  27  473  162   43  127  118  193   81  111   57 1766  394    0  285
    39]
 [  69  144  332   94  297   34  112  124  186  814  320 2806    0   92
    46]
 [   0    2    1    1  231    4    3    0   15    0    1    0   29    3
     0]
 [  81  163   98   12  358  111   58  115  112   36  287  102    0 1675
    23]
 [   9   89  449  211   55    3   50   62  361  132   35   50    0   37
  2328]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.48      0.40      0.44      1266
           1       0.53      0.58      0.55      4592
           2       0.53      0.62      0.57      5606
           3       0.77      0.67      0.72      4537
           4       0.45      0.48      0.47      5881
           5       0.63      0.59      0.61      2366
           6       0.68      0.64      0.66      4675
           7       0.58      0.59      0.59      3883
           8       0.52      0.53      0.52      6688
           9       0.54      0.48      0.51      4128
          10       0.46      0.46      0.46      3876
          11       0.47      0.51      0.49      5470
          12       0.44      0.10      0.16       290
          13       0.53      0.52      0.52      3231
          14       0.64      0.60      0.62      3871

    accuracy                           0.55     60360
   macro avg       0.55      0.52      0.53     60360
weighted avg       0.56      0.55      0.55     60360

The epoch:0,marcoF1ScoresTotal:0.547503
*********************************************start valid model**************************************
[ 1000 - th batch: valid loss is 0.806233 valid total precise is 0.660105 ]
The epoch:0,marcoF1ScoresOcemotion:0.445375
********************************confusion_matrix********************************
[[118  35   1  33  11 130   4]
 [ 39 150   0  43  14 122   6]
 [  0   3  16   6   3  17   1]
 [ 11  19   1 579  75  96   0]
 [  7  11   3  72 194  64   2]
 [ 56  48   5  66  70 790   1]
 [  6   6   0  20   4  23  19]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.50      0.36      0.41       332
           1       0.55      0.40      0.46       374
           2       0.62      0.35      0.44        46
           3       0.71      0.74      0.72       781
           4       0.52      0.55      0.54       353
           5       0.64      0.76      0.69      1036
           6       0.58      0.24      0.34        78

    accuracy                           0.62      3000
   macro avg       0.59      0.49      0.52      3000
weighted avg       0.61      0.62      0.61      3000

The epoch:0 ,marcoF1ScoresOcnli:0.670892
********************************confusion_matrix********************************
[[868  98  45]
 [168 731 102]
 [ 72 116 800]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.78      0.86      0.82      1011
           1       0.77      0.73      0.75      1001
           2       0.84      0.81      0.83       988

    accuracy                           0.80      3000
   macro avg       0.80      0.80      0.80      3000
weighted avg       0.80      0.80      0.80      3000

The epoch:0,marcoF1ScoresTnews:0.526240
********************************confusion_matrix********************************
[[ 17  14   6   0   1   1   2   6   0   2   0   3   0   7   1]
 [  4 125  24   1   4   2   1  13   1   7  15  16   0  10   2]
 [  5  29 154  13   0   2   6  15   9   8   7  18   0   3  11]
 [  0   6  12 164   4   1   6   8   3   3   3   5   0   0   6]
 [  2   4   1   0 157  22   7  10  28   2   5  14   0  21   2]
 [  0   2   0   1  16  78   2   5   2   1   9   1   0   2   0]
 [  1   3   1   2  12   4 166   2  10   3  15   9   0   4   2]
 [  0  20   2   4   6   2   5 132  11   5   2   3   0   6   2]
 [  0   2   8   4  93   4  30  20 142  10   5  13   0   5  20]
 [  0   7   3   5   5   0   6   4   3 107   2  70   0   5   3]
 [  0  20   7   3   2   7   6   8   4   5  89  16   0  18   0]
 [  3  11   8   6  10   4   4  12   1  50  15 160   0   2   0]
 [  0   0   0   0  12   0   0   0   0   0   0   0   0   0   0]
 [  1   6   2   1  18  10   3   7   3   2   7   4   0  84   1]
 [  1   3  20   7   3   1   1   3  17   6   4   7   0   2 103]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.50      0.28      0.36        60
           1       0.50      0.56      0.52       225
           2       0.62      0.55      0.58       280
           3       0.78      0.74      0.76       221
           4       0.46      0.57      0.51       275
           5       0.57      0.66      0.61       119
           6       0.68      0.71      0.69       234
           7       0.54      0.66      0.59       200
           8       0.61      0.40      0.48       356
           9       0.51      0.49      0.50       220
          10       0.50      0.48      0.49       185
          11       0.47      0.56      0.51       286
          12       0.00      0.00      0.00        12
          13       0.50      0.56      0.53       149
          14       0.67      0.58      0.62       178

    accuracy                           0.56      3000
   macro avg       0.53      0.52      0.52      3000
weighted avg       0.57      0.56      0.56      3000

The epoch:0,marcoF1ScoresTotal:0.611183
save the pretrainModel in /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_26_0_14/save_model/roberta_best_dev_f1_0.6111832568346774.pt and the classifierModel in /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_26_0_14/save_model/classifier_best_dev_f1_0.6111832568346774.pt
best epoch is:0 with best f1 is: 0.611183
*********************************************train model**************************************
current epoch:1
[ 1000 - th batch: valid loss is 0.553507 valid total precise is 0.691247 ]
[ 2000 - th batch: valid loss is 0.559452 valid total precise is 0.693402 ]
[ 3000 - th batch: valid loss is 0.558296 valid total precise is 0.694417 ]
[ 4000 - th batch: valid loss is 0.558508 valid total precise is 0.694618 ]
[ 5000 - th batch: valid loss is 0.558778 valid total precise is 0.695095 ]
[ 6000 - th batch: valid loss is 0.560773 valid total precise is 0.693319 ]
[ 7000 - th batch: valid loss is 0.562466 valid total precise is 0.693528 ]
[ 8000 - th batch: valid loss is 0.559914 valid total precise is 0.694948 ]
[ 9000 - th batch: valid loss is 0.558577 valid total precise is 0.695670 ]
[ 10000 - th batch: valid loss is 0.558427 valid total precise is 0.695581 ]
[ 11000 - th batch: valid loss is 0.559401 valid total precise is 0.695902 ]
[ 12000 - th batch: valid loss is 0.558044 valid total precise is 0.697049 ]
[ 13000 - th batch: valid loss is 0.558349 valid total precise is 0.696900 ]
[ 14000 - th batch: valid loss is 0.559226 valid total precise is 0.696939 ]
[ 15000 - th batch: valid loss is 0.558351 valid total precise is 0.698032 ]
The epoch:1,marcoF1ScoresOcemotion:0.571158
********************************confusion_matrix********************************
[[1673  398   12  286   62 1321   31]
 [ 449 1866   10  423   89 1157   37]
 [  21   19  234   36   27  207    4]
 [ 155  241   14 6379  512  871   28]
 [  72   65    8  785 2106  682   16]
 [ 621  505   33  642  344 9390   33]
 [  94   90    5  150   53  230  208]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.54      0.44      0.49      3783
           1       0.59      0.46      0.52      4031
           2       0.74      0.43      0.54       548
           3       0.73      0.78      0.75      8200
           4       0.66      0.56      0.61      3734
           5       0.68      0.81      0.74     11568
           6       0.58      0.25      0.35       830

    accuracy                           0.67     32694
   macro avg       0.65      0.53      0.57     32694
weighted avg       0.66      0.67      0.66     32694

The epoch:1,marcoF1ScoresOcnli:0.806500
********************************confusion_matrix********************************
[[13776  2241   698]
 [ 2370 13140  1774]
 [  884  1820 13684]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.81      0.82      0.82     16715
           1       0.76      0.76      0.76     17284
           2       0.85      0.84      0.84     16388

    accuracy                           0.81     50387
   macro avg       0.81      0.81      0.81     50387
weighted avg       0.81      0.81      0.81     50387

The epoch:1,marcoF1ScoresTnews:0.610775
********************************confusion_matrix********************************
[[ 709   96  197    4   11   14   15   31   10   13   19   52    0   81
    14]
 [  77 3009  330   34   69   19   17  259   69   73  366  108    1  117
    44]
 [ 186  368 3687  229   42   28   61  163  122   93   96  214    0   73
   244]
 [  10   88  359 3379   48   16   62   89   42   66   56  111    0   18
   193]
 [  17   69   54   46 3282  261  128  145 1104   41   93  254   63  287
    37]
 [  23   41   27   12  265 1571   34   63   70    5  132   31    0   91
     1]
 [  33   65  130   37  166   36 3289   65  322   78  243  107    0   59
    45]
 [  40  317  147   68  118   45   34 2559  178   60   79  104    0   92
    42]
 [   6   63  118   35 1227   76  374  211 3928  132   49  151    9   71
   238]
 [  17  119   98   45   60    6   77   75  120 2279   74 1010    0   34
   114]
 [  27  440  105   30   91   96  169   78   71   43 2084  359    0  246
    37]
 [  77  108  225   83  261   33  111  117  148  753  276 3175    0   67
    36]
 [   0    0    0    0  182    3    2    0   11    0    1    0   91    0
     0]
 [  88  153   48    8  294   93   62  100   74   26  232   85    0 1957
    11]
 [  15   77  331  163   41    3   45   51  264  129   27   44    0   24
  2657]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.54      0.56      0.55      1266
           1       0.60      0.66      0.63      4592
           2       0.63      0.66      0.64      5606
           3       0.81      0.74      0.78      4537
           4       0.53      0.56      0.55      5881
           5       0.68      0.66      0.67      2366
           6       0.73      0.70      0.72      4675
           7       0.64      0.66      0.65      3883
           8       0.60      0.59      0.59      6688
           9       0.60      0.55      0.58      4128
          10       0.54      0.54      0.54      3876
          11       0.55      0.58      0.56      5470
          12       0.55      0.31      0.40       290
          13       0.61      0.61      0.61      3231
          14       0.72      0.69      0.70      3871

    accuracy                           0.62     60360
   macro avg       0.62      0.60      0.61     60360
weighted avg       0.63      0.62      0.62     60360

The epoch:1,marcoF1ScoresTotal:0.662811
*********************************************start valid model**************************************
[ 1000 - th batch: valid loss is 0.824893 valid total precise is 0.663775 ]
The epoch:1,marcoF1ScoresOcemotion:0.571158
********************************confusion_matrix********************************
[[113  24   1  24   8 158   4]
 [ 43 161   0  34   6 127   3]
 [  2   2  15   6   3  18   0]
 [ 20  34   1 562  57 107   0]
 [  9  11   1  73 183  74   2]
 [ 54  54   3  67  45 813   0]
 [ 12   5   0  19   2  25  15]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.45      0.34      0.39       332
           1       0.55      0.43      0.48       374
           2       0.71      0.33      0.45        46
           3       0.72      0.72      0.72       781
           4       0.60      0.52      0.56       353
           5       0.61      0.78      0.69      1036
           6       0.62      0.19      0.29        78

    accuracy                           0.62      3000
   macro avg       0.61      0.47      0.51      3000
weighted avg       0.62      0.62      0.61      3000

The epoch:1 ,marcoF1ScoresOcnli:0.806500
********************************confusion_matrix********************************
[[847  84  80]
 [126 692 183]
 [ 37  82 869]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.84      0.84      0.84      1011
           1       0.81      0.69      0.74      1001
           2       0.77      0.88      0.82       988

    accuracy                           0.80      3000
   macro avg       0.80      0.80      0.80      3000
weighted avg       0.80      0.80      0.80      3000

The epoch:1,marcoF1ScoresTnews:0.610775
********************************confusion_matrix********************************
[[ 23  11   3   1   1   0   1   5   0   2   0   5   0   7   1]
 [  7 135  18   2   5   2   1   7   2   5  16   7   0  16   2]
 [  9  34 146  20   2   1   6  10   9   6   6  12   0   6  13]
 [  1   5   7 181   4   1   7   1   3   2   3   3   0   0   3]
 [  2   5   2   1 121  16  11   4  55   3   5  13   9  25   3]
 [  0   4   1   2  21  76   1   2   2   1   5   2   0   2   0]
 [  2   4   2   4   6   4 168   1  17   2  13   5   0   5   1]
 [  3  25   3  13   7   1   3 107  12   5   3   7   0   8   3]
 [  0   2   8   7  56   3  29  14 176  15   4   5   1  10  26]
 [  2   8   4   7   5   0   8   4   3 141   1  23   0   7   7]
 [  2  18  10  10   3   7   8   4   3   4  76  18   0  22   0]
 [  4  15   6   8   8   5   8   2   4  81   9 128   0   8   0]
 [  0   0   0   0   4   0   0   0   0   0   0   0   8   0   0]
 [  2   4   2   1  13   4   3   4   5   0   7   2   0 101   1]
 [  1   5  14  14   1   1   0   1  11   1   5   3   0   5 116]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.40      0.38      0.39        60
           1       0.49      0.60      0.54       225
           2       0.65      0.52      0.58       280
           3       0.67      0.82      0.74       221
           4       0.47      0.44      0.45       275
           5       0.63      0.64      0.63       119
           6       0.66      0.72      0.69       234
           7       0.64      0.54      0.58       200
           8       0.58      0.49      0.53       356
           9       0.53      0.64      0.58       220
          10       0.50      0.41      0.45       185
          11       0.55      0.45      0.49       286
          12       0.44      0.67      0.53        12
          13       0.45      0.68      0.54       149
          14       0.66      0.65      0.66       178

    accuracy                           0.57      3000
   macro avg       0.55      0.58      0.56      3000
weighted avg       0.57      0.57      0.56      3000

The epoch:1,marcoF1ScoresTotal:0.623781
save the pretrainModel in /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_26_0_14/save_model/roberta_best_dev_f1_0.6237813268931655.pt and the classifierModel in /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_26_0_14/save_model/classifier_best_dev_f1_0.6237813268931655.pt
best epoch is:1 with best f1 is: 0.623781
*********************************************train model**************************************
current epoch:2
[ 1000 - th batch: valid loss is 0.316969 valid total precise is 0.759537 ]
[ 2000 - th batch: valid loss is 0.293882 valid total precise is 0.765827 ]
[ 3000 - th batch: valid loss is 0.282781 valid total precise is 0.768330 ]
[ 4000 - th batch: valid loss is 0.278583 valid total precise is 0.766719 ]
[ 5000 - th batch: valid loss is 0.277532 valid total precise is 0.766353 ]
[ 6000 - th batch: valid loss is 0.276582 valid total precise is 0.765905 ]
[ 7000 - th batch: valid loss is 0.275625 valid total precise is 0.766014 ]
[ 8000 - th batch: valid loss is 0.274853 valid total precise is 0.766137 ]
[ 9000 - th batch: valid loss is 0.274964 valid total precise is 0.765443 ]
[ 10000 - th batch: valid loss is 0.275660 valid total precise is 0.764699 ]
[ 11000 - th batch: valid loss is 0.275593 valid total precise is 0.765423 ]
[ 12000 - th batch: valid loss is 0.276278 valid total precise is 0.765490 ]
[ 13000 - th batch: valid loss is 0.276601 valid total precise is 0.765691 ]
[ 14000 - th batch: valid loss is 0.276938 valid total precise is 0.765991 ]
[ 15000 - th batch: valid loss is 0.277405 valid total precise is 0.765792 ]
The epoch:2,marcoF1ScoresOcemotion:0.682177
********************************confusion_matrix********************************
[[2184  383   10  176   44  959   27]
 [ 432 2410    7  262   56  838   26]
 [  17   27  299   26   22  155    2]
 [ 107  205   17 6925  414  499   33]
 [  38   40    4  606 2620  419    7]
 [ 553  424   23  386  241 9917   24]
 [  95   84    4  110   52  159  326]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.64      0.58      0.61      3783
           1       0.67      0.60      0.63      4031
           2       0.82      0.55      0.66       548
           3       0.82      0.84      0.83      8200
           4       0.76      0.70      0.73      3734
           5       0.77      0.86      0.81     11568
           6       0.73      0.39      0.51       830

    accuracy                           0.75     32694
   macro avg       0.74      0.65      0.68     32694
weighted avg       0.75      0.75      0.75     32694

The epoch:2,marcoF1ScoresOcnli:0.848541
********************************confusion_matrix********************************
[[14377  1884   454]
 [ 1848 14088  1348]
 [  636  1501 14251]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.85      0.86      0.86     16715
           1       0.81      0.82      0.81     17284
           2       0.89      0.87      0.88     16388

    accuracy                           0.85     50387
   macro avg       0.85      0.85      0.85     50387
weighted avg       0.85      0.85      0.85     50387

The epoch:2,marcoF1ScoresTnews:0.696821
********************************confusion_matrix********************************
[[ 845   76  144    3    5   10   14   23    8   11   20   45    0   51
    11]
 [  66 3441  219   24   60   13   10  185   39   52  294   70    0   85
    34]
 [ 143  293 4136  174   27   19   49  110   97   75   60  180    0   49
   194]
 [   6   64  293 3624   35   12   52   71   31   58   53   69    2   15
   152]
 [  15   50   32   32 3705  211   94  110  994   35   68  213   64  236
    22]
 [  13   23   18    9  252 1734   31   44   44    1   97   28    1   71
     0]
 [  21   62   93   29  125   30 3542   51  281   62  204   82    0   63
    30]
 [  31  238  100   56   81   33   26 2896  111   63   75   86    0   58
    29]
 [   5   40   87   20 1130   49  284  165 4401  105   46  110    7   54
   185]
 [  13   76   80   33   34    5   64   67   80 2624   59  866    1   33
    93]
 [  20  356   74   22   72   78  135   61   43   32 2457  298    0  205
    23]
 [  52   82  187   60  206   20   70   79  116  673  236 3612    0   52
    25]
 [   0    0    0    0  130    3    1    0    8    0    0    0  148    0
     0]
 [  70  106   34   11  243   71   41   62   47   23  185   61    0 2270
     7]
 [  13   55  243  130   28    3   36   36  217  103   23   32    0   17
  2935]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.64      0.67      0.66      1266
           1       0.69      0.75      0.72      4592
           2       0.72      0.74      0.73      5606
           3       0.86      0.80      0.83      4537
           4       0.60      0.63      0.62      5881
           5       0.76      0.73      0.74      2366
           6       0.80      0.76      0.78      4675
           7       0.73      0.75      0.74      3883
           8       0.68      0.66      0.67      6688
           9       0.67      0.64      0.65      4128
          10       0.63      0.63      0.63      3876
          11       0.63      0.66      0.64      5470
          12       0.66      0.51      0.58       290
          13       0.70      0.70      0.70      3231
          14       0.78      0.76      0.77      3871

    accuracy                           0.70     60360
   macro avg       0.70      0.69      0.70     60360
weighted avg       0.70      0.70      0.70     60360

The epoch:2,marcoF1ScoresTotal:0.742513
*********************************************start valid model**************************************
[ 1000 - th batch: valid loss is 0.859348 valid total precise is 0.670559 ]
The epoch:2,marcoF1ScoresOcemotion:0.682177
********************************confusion_matrix********************************
[[100  25   3  31  15 149   9]
 [ 37 160   1  45  11 116   4]
 [  1   3  15   5   8  14   0]
 [  6  24   1 575  57 115   3]
 [  4  10   2  75 186  74   2]
 [ 38  49   4  68  54 820   3]
 [  5   9   0  21   3  22  18]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.52      0.30      0.38       332
           1       0.57      0.43      0.49       374
           2       0.58      0.33      0.42        46
           3       0.70      0.74      0.72       781
           4       0.56      0.53      0.54       353
           5       0.63      0.79      0.70      1036
           6       0.46      0.23      0.31        78

    accuracy                           0.62      3000
   macro avg       0.57      0.48      0.51      3000
weighted avg       0.61      0.62      0.61      3000

The epoch:2 ,marcoF1ScoresOcnli:0.848541
********************************confusion_matrix********************************
[[862 110  39]
 [132 748 121]
 [ 48 116 824]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.83      0.85      0.84      1011
           1       0.77      0.75      0.76      1001
           2       0.84      0.83      0.84       988

    accuracy                           0.81      3000
   macro avg       0.81      0.81      0.81      3000
weighted avg       0.81      0.81      0.81      3000

The epoch:2,marcoF1ScoresTnews:0.696821
********************************confusion_matrix********************************
[[ 25  12   5   0   1   0   1   6   0   1   1   2   0   4   2]
 [  9 136  16   1   4   2   2  13   3   5  17   5   0  10   2]
 [ 10  35 146  16   2   1   7  12   9   4   6  12   0   5  15]
 [  1   5  10 175   3   1   7   3   4   1   1   3   0   0   7]
 [  2   4   2   1 150  20   6   6  42   1   5  11   7  15   3]
 [  0   3   0   0  13  82   2   7   2   1   8   1   0   0   0]
 [  2   4   4   3   8   2 154   4  26   1  17   4   0   4   1]
 [  4  19   3   4   8   2   1 124  15   4   4   3   0   6   3]
 [  0   4   9   4  85   4  19  15 166  12   5   7   0   5  21]
 [  1  11   5   5   6   0   4   7  10 106   2  53   0   4   6]
 [  2  23  10   5   6  11   4   7   2   2  81  15   0  16   1]
 [  5  14   8   8  13   4   2   8   6  35  10 166   0   7   0]
 [  0   0   0   0   5   0   0   0   1   0   0   0   6   0   0]
 [  2   7   2   0  15   4   2   6   8   1  10   2   0  89   1]
 [  1   5  15   8   2   1   2   1  12   2   3   2   0   4 120]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.39      0.42      0.40        60
           1       0.48      0.60      0.54       225
           2       0.62      0.52      0.57       280
           3       0.76      0.79      0.78       221
           4       0.47      0.55      0.50       275
           5       0.61      0.69      0.65       119
           6       0.72      0.66      0.69       234
           7       0.57      0.62      0.59       200
           8       0.54      0.47      0.50       356
           9       0.60      0.48      0.54       220
          10       0.48      0.44      0.46       185
          11       0.58      0.58      0.58       286
          12       0.46      0.50      0.48        12
          13       0.53      0.60      0.56       149
          14       0.66      0.67      0.67       178

    accuracy                           0.58      3000
   macro avg       0.56      0.57      0.57      3000
weighted avg       0.58      0.58      0.57      3000

The epoch:2,marcoF1ScoresTotal:0.628390
save the pretrainModel in /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_26_0_14/save_model/roberta_best_dev_f1_0.6283897867192771.pt and the classifierModel in /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_26_0_14/save_model/classifier_best_dev_f1_0.6283897867192771.pt
best epoch is:2 with best f1 is: 0.628390
*********************************************train model**************************************
current epoch:3
[ 1000 - th batch: valid loss is 0.116346 valid total precise is 0.829941 ]
[ 2000 - th batch: valid loss is 0.109178 valid total precise is 0.834695 ]
[ 3000 - th batch: valid loss is 0.105679 valid total precise is 0.837538 ]
[ 4000 - th batch: valid loss is 0.102896 valid total precise is 0.838487 ]
[ 5000 - th batch: valid loss is 0.100718 valid total precise is 0.839857 ]
[ 6000 - th batch: valid loss is 0.099499 valid total precise is 0.840436 ]
[ 7000 - th batch: valid loss is 0.098866 valid total precise is 0.840247 ]
[ 8000 - th batch: valid loss is 0.098561 valid total precise is 0.839258 ]
[ 9000 - th batch: valid loss is 0.098016 valid total precise is 0.839439 ]
[ 10000 - th batch: valid loss is 0.097630 valid total precise is 0.839740 ]
[ 11000 - th batch: valid loss is 0.097702 valid total precise is 0.839571 ]
[ 12000 - th batch: valid loss is 0.097485 valid total precise is 0.840014 ]
[ 13000 - th batch: valid loss is 0.097835 valid total precise is 0.839364 ]
[ 14000 - th batch: valid loss is 0.098130 valid total precise is 0.839274 ]
[ 15000 - th batch: valid loss is 0.098335 valid total precise is 0.839197 ]
The epoch:3,marcoF1ScoresOcemotion:0.805218
********************************confusion_matrix********************************
[[ 2822   258     7    86    24   556    30]
 [  278  3136     9   143    27   418    20]
 [   13    19   368    25    21   100     2]
 [   57   120    10  7533   245   217    18]
 [   16    27     3   328  3157   193    10]
 [  377   280    14   164   128 10587    18]
 [   90    66     4    66    43    99   462]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.77      0.75      0.76      3783
           1       0.80      0.78      0.79      4031
           2       0.89      0.67      0.76       548
           3       0.90      0.92      0.91      8200
           4       0.87      0.85      0.86      3734
           5       0.87      0.92      0.89     11568
           6       0.82      0.56      0.66       830

    accuracy                           0.86     32694
   macro avg       0.85      0.78      0.81     32694
weighted avg       0.86      0.86      0.86     32694

The epoch:3,marcoF1ScoresOcnli:0.882135
********************************confusion_matrix********************************
[[14908  1458   349]
 [ 1493 14734  1057]
 [  457  1154 14777]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.88      0.89      0.89     16715
           1       0.85      0.85      0.85     17284
           2       0.91      0.90      0.91     16388

    accuracy                           0.88     50387
   macro avg       0.88      0.88      0.88     50387
weighted avg       0.88      0.88      0.88     50387

The epoch:3,marcoF1ScoresTnews:0.792473
********************************confusion_matrix********************************
[[ 999   45   98    1    2    4    8   12    2    6   16   30    1   34
     8]
 [  39 3832  147   13   35    8    7  126   29   27  204   49    0   60
    16]
 [ 109  172 4619  112   11   13   35   72   65   49   50  134    0   35
   130]
 [   5   54  168 3953   24    5   30   53   23   47   39   49    0    8
    79]
 [   5   35   17    9 4296  141   69   59  800   25   54  149   38  168
    16]
 [   9   17    6    5  156 1958   27   25   24    2   72   25    1   39
     0]
 [  16   45   80   21   81   26 3850   23  206   43  168   60    0   35
    21]
 [  14  144   61   38   53   17   15 3276   70   33   42   69    0   30
    21]
 [   4   27   57    9  903   35  191   93 5003   78   30   92    6   28
   132]
 [  12   52   52   30   25    1   38   47   58 3003   39  684    0   25
    62]
 [  17  235   47   19   34   66  113   42   35   18 2890  207    0  140
    13]
 [  31   55  132   31  171   12   39   50   73  536  180 4124    0   25
    11]
 [   0    0    0    0   91    2    1    0    5    0    0    0  191    0
     0]
 [  47   53   13    0  196   42   14   35   39   17  133   35    0 2594
    13]
 [   8   26  175   84   18    2   24   22  136   72    9   30    0   11
  3254]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.76      0.79      0.77      1266
           1       0.80      0.83      0.82      4592
           2       0.81      0.82      0.82      5606
           3       0.91      0.87      0.89      4537
           4       0.70      0.73      0.72      5881
           5       0.84      0.83      0.83      2366
           6       0.86      0.82      0.84      4675
           7       0.83      0.84      0.84      3883
           8       0.76      0.75      0.75      6688
           9       0.76      0.73      0.74      4128
          10       0.74      0.75      0.74      3876
          11       0.72      0.75      0.74      5470
          12       0.81      0.66      0.72       290
          13       0.80      0.80      0.80      3231
          14       0.86      0.84      0.85      3871

    accuracy                           0.79     60360
   macro avg       0.80      0.79      0.79     60360
weighted avg       0.79      0.79      0.79     60360

The epoch:3,marcoF1ScoresTotal:0.826609
*********************************************start valid model**************************************
[ 1000 - th batch: valid loss is 1.096978 valid total precise is 0.654321 ]
The epoch:3,marcoF1ScoresOcemotion:0.805218
********************************confusion_matrix********************************
[[117  50   5  24  13 112  11]
 [ 36 186   2  39  12  87  12]
 [  3   6  15   6   4  12   0]
 [ 18  39   1 562  61  93   7]
 [ 15  18   3  86 174  53   4]
 [ 66  90  12  72  61 729   6]
 [  6   7   1  19   1  21  23]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.45      0.35      0.39       332
           1       0.47      0.50      0.48       374
           2       0.38      0.33      0.35        46
           3       0.70      0.72      0.71       781
           4       0.53      0.49      0.51       353
           5       0.66      0.70      0.68      1036
           6       0.37      0.29      0.33        78

    accuracy                           0.60      3000
   macro avg       0.51      0.48      0.49      3000
weighted avg       0.59      0.60      0.60      3000

The epoch:3 ,marcoF1ScoresOcnli:0.882135
********************************confusion_matrix********************************
[[824 130  57]
 [123 732 146]
 [ 40 117 831]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.83      0.82      0.82      1011
           1       0.75      0.73      0.74      1001
           2       0.80      0.84      0.82       988

    accuracy                           0.80      3000
   macro avg       0.80      0.80      0.80      3000
weighted avg       0.80      0.80      0.80      3000

The epoch:3,marcoF1ScoresTnews:0.792473
********************************confusion_matrix********************************
[[ 22  12   8   2   1   1   1   6   0   1   1   3   0   2   0]
 [  5 140  24   1   4   3   0   8   4   8  14   5   0   8   1]
 [  6  27 164  12   3   1   4  11  13   4   6  14   0   3  12]
 [  0   7  15 169   1   1   6   3   3   2   1   5   0   0   8]
 [  1   4   3   1 121   9   4   3  69   1  13  20   9  14   3]
 [  0   4   1   2  16  74   2   2   4   0  12   2   0   0   0]
 [  2   5   3   3   9   3 149   4  22   1  17  10   0   6   0]
 [  2  23   7   5   6   2   1 111  21   5   4   7   0   4   2]
 [  0   2  12   6  60   1  18  13 191  14   5   7   1   3  23]
 [  0   7   7   7   7   0   2   4  10 130   2  38   0   1   5]
 [  3  18   9   2   3   2   5   6   4   2 100  17   0  14   0]
 [  4   9  17   4  10   2   1   6   9  71  11 139   0   3   0]
 [  0   0   0   0   4   0   0   0   1   0   0   0   7   0   0]
 [  3   8   4   0  18   7   2   7  11   1  16   3   0  68   1]
 [  1   4  22   6   2   1   0   2  18   2   5   2   0   2 111]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.45      0.37      0.40        60
           1       0.52      0.62      0.57       225
           2       0.55      0.59      0.57       280
           3       0.77      0.76      0.77       221
           4       0.46      0.44      0.45       275
           5       0.69      0.62      0.65       119
           6       0.76      0.64      0.69       234
           7       0.60      0.56      0.58       200
           8       0.50      0.54      0.52       356
           9       0.54      0.59      0.56       220
          10       0.48      0.54      0.51       185
          11       0.51      0.49      0.50       286
          12       0.41      0.58      0.48        12
          13       0.53      0.46      0.49       149
          14       0.67      0.62      0.65       178

    accuracy                           0.57      3000
   macro avg       0.56      0.56      0.56      3000
weighted avg       0.57      0.57      0.57      3000

The epoch:3,marcoF1ScoresTotal:0.616140
best epoch is:2 with best f1 is: 0.628390
*********************************************train model**************************************
current epoch:4
[ 1000 - th batch: valid loss is 0.065204 valid total precise is 0.865532 ]
[ 2000 - th batch: valid loss is 0.055028 valid total precise is 0.877272 ]
[ 3000 - th batch: valid loss is 0.050229 valid total precise is 0.880812 ]
[ 4000 - th batch: valid loss is 0.046863 valid total precise is 0.884916 ]
[ 5000 - th batch: valid loss is 0.044670 valid total precise is 0.886844 ]
[ 6000 - th batch: valid loss is 0.043119 valid total precise is 0.887759 ]
[ 7000 - th batch: valid loss is 0.041937 valid total precise is 0.888222 ]
[ 8000 - th batch: valid loss is 0.041059 valid total precise is 0.888694 ]
[ 9000 - th batch: valid loss is 0.040305 valid total precise is 0.888914 ]
[ 10000 - th batch: valid loss is 0.039869 valid total precise is 0.888967 ]
[ 11000 - th batch: valid loss is 0.039344 valid total precise is 0.889404 ]
[ 12000 - th batch: valid loss is 0.039053 valid total precise is 0.889157 ]
[ 13000 - th batch: valid loss is 0.038696 valid total precise is 0.889821 ]
[ 14000 - th batch: valid loss is 0.038361 valid total precise is 0.890222 ]
[ 15000 - th batch: valid loss is 0.038126 valid total precise is 0.890259 ]
