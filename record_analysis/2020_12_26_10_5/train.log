Parameters:
root    :    /share/home/crazicoco/competition/CPFC
vocabIdName    :    vocab.txt
tokenizeModel    :    hfl/chinese-roberta-wwm-ext-large
pretrainModel    :    hfl/chinese-roberta-wwm-ext-large
saveModelAddress    :    saveModelBin/
processedDataDir    :    preprocessed_data
saveLabelIdName    :    label.pt
saveTrainIdName    :    train.pt
saveValidIdName    :    valid.pt
saveTestIdName    :    test.pt
batch_size    :    10
epoch_size    :    20
loss_calculate    :    cross-entroy
lr    :    2e-05
device    :    0
max_len    :    512
lossCalculateWay    :    general
accumulate    :    True
ifparallel    :    True
debug    :    False
logfileName    :    public
record_addr    :    /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_26_10_5
*********************************************train model**************************************
current epoch:0
[ 1000 - th batch: valid loss is 4.602987 valid total precise is 0.404104 ]
[ 2000 - th batch: valid loss is 3.430709 valid total precise is 0.457829 ]
[ 3000 - th batch: valid loss is 2.879509 valid total precise is 0.491164 ]
[ 4000 - th batch: valid loss is 2.540887 valid total precise is 0.517354 ]
[ 5000 - th batch: valid loss is 2.310801 valid total precise is 0.535627 ]
[ 6000 - th batch: valid loss is 2.136846 valid total precise is 0.550725 ]
[ 7000 - th batch: valid loss is 2.005440 valid total precise is 0.560151 ]
[ 8000 - th batch: valid loss is 1.898351 valid total precise is 0.568896 ]
[ 9000 - th batch: valid loss is 1.811948 valid total precise is 0.575186 ]
[ 10000 - th batch: valid loss is 1.740069 valid total precise is 0.581348 ]
[ 11000 - th batch: valid loss is 1.678659 valid total precise is 0.586035 ]
[ 12000 - th batch: valid loss is 1.626892 valid total precise is 0.589291 ]
[ 13000 - th batch: valid loss is 1.581148 valid total precise is 0.592669 ]
[ 14000 - th batch: valid loss is 1.540936 valid total precise is 0.595514 ]
The epoch:0,marcoF1ScoresOcemotion:0.448483
********************************confusion_matrix********************************
[[1208  368   12  401   73 1700   21]
 [ 435 1367    6  535   96 1577   15]
 [  20   28  150   51   26  273    0]
 [ 188  270   12 5732  496 1480   22]
 [  70   73    6 1064 1432 1080    9]
 [ 618  495   26  958  378 9076   17]
 [ 102   76    2  196   41  330   83]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.46      0.32      0.38      3783
           1       0.51      0.34      0.41      4031
           2       0.70      0.27      0.39       548
           3       0.64      0.70      0.67      8200
           4       0.56      0.38      0.46      3734
           5       0.58      0.78      0.67     11568
           6       0.50      0.10      0.17       830

    accuracy                           0.58     32694
   macro avg       0.57      0.41      0.45     32694
weighted avg       0.57      0.58      0.56     32694

The epoch:0,marcoF1ScoresOcnli:0.659530
********************************confusion_matrix********************************
[[11195  3711  1809]
 [ 3857 10408  3019]
 [ 1799  3001 11588]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.66      0.67      0.67     16715
           1       0.61      0.60      0.61     17284
           2       0.71      0.71      0.71     16388

    accuracy                           0.66     50387
   macro avg       0.66      0.66      0.66     50387
weighted avg       0.66      0.66      0.66     50387

The epoch:0,marcoF1ScoresTnews:0.527873
********************************confusion_matrix********************************
[[ 510  143  276    7   24   17   24   44   24   14   29   61    0   74
    19]
 [  48 2670  445   50   86   22   26  295  113   95  416  128    0  149
    49]
 [ 168  458 3447  245   85   24   67  193  159   94   89  234    0   85
   258]
 [   4  115  466 3045   92   13   77  116   72   74   80  110    0   24
   249]
 [  14  108   88   59 2826  283  153  190 1307   51  120  311   24  302
    45]
 [  17   66   33   12  314 1400   49   73   97    4  152   49    0   98
     2]
 [  29   87  158   54  193   44 3008   89  406   82  257  144    0   70
    54]
 [  28  345  183   98  147   52   45 2335  217   64   92  131    0  100
    46]
 [   2   73  158   48 1343   84  386  271 3556  150   73  196    3   85
   260]
 [  10  138  138   59   73    7   90  100  160 1945   85 1136    0   47
   140]
 [  21  467  165   31  119  114  197  111  122   59 1779  381    0  267
    43]
 [  63  132  333  114  305   38  117  133  212  825  301 2760    0   98
    39]
 [   0    0    0    0  239    3    2    0   16    0    0    1   28    1
     0]
 [  75  177   79   13  357  108   59  117  108   38  281  110    0 1690
    19]
 [  12  102  424  186   51    7   59   80  339  131   31   56    0   35
  2358]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.51      0.40      0.45      1266
           1       0.53      0.58      0.55      4592
           2       0.54      0.61      0.57      5606
           3       0.76      0.67      0.71      4537
           4       0.45      0.48      0.47      5881
           5       0.63      0.59      0.61      2366
           6       0.69      0.64      0.67      4675
           7       0.56      0.60      0.58      3883
           8       0.51      0.53      0.52      6688
           9       0.54      0.47      0.50      4128
          10       0.47      0.46      0.46      3876
          11       0.48      0.50      0.49      5470
          12       0.51      0.10      0.16       290
          13       0.54      0.52      0.53      3231
          14       0.66      0.61      0.63      3871

    accuracy                           0.55     60360
   macro avg       0.56      0.52      0.53     60360
weighted avg       0.56      0.55      0.55     60360

The epoch:0,marcoF1ScoresTotal:0.545295
*********************************************start valid model**************************************
The epoch:0,marcoF1ScoresOcemotion:0.510401
********************************confusion_matrix********************************
[[110  16   0  33   7 161   5]
 [ 47 119   2  47  11 143   5]
 [  2   2  17   8   3  14   0]
 [ 12  10   1 596  50 112   0]
 [  4   8   3  93 167  76   2]
 [ 50  31   4  79  49 820   3]
 [  7   6   0  20   1  23  21]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.47      0.33      0.39       332
           1       0.62      0.32      0.42       374
           2       0.63      0.37      0.47        46
           3       0.68      0.76      0.72       781
           4       0.58      0.47      0.52       353
           5       0.61      0.79      0.69      1036
           6       0.58      0.27      0.37        78

    accuracy                           0.62      3000
   macro avg       0.60      0.47      0.51      3000
weighted avg       0.61      0.62      0.60      3000

The epoch:0 ,marcoF1ScoresOcnli:0.793017
********************************confusion_matrix********************************
[[844  94  73]
 [130 665 206]
 [ 37  73 878]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.83      0.83      0.83      1011
           1       0.80      0.66      0.73      1001
           2       0.76      0.89      0.82       988

    accuracy                           0.80      3000
   macro avg       0.80      0.80      0.79      3000
weighted avg       0.80      0.80      0.79      3000

The epoch:0,marcoF1ScoresTnews:0.554084
********************************confusion_matrix********************************
[[ 28   7   7   0   2   0   0   5   0   1   0   2   0   6   2]
 [ 12 114  28   0   5   2   1  14   2   4  19   9   0  13   2]
 [ 14  28 147  10   4   1   4  13  11   3   6  16   0   3  20]
 [  0   7  15 156   4   1   5   5   3   2   2   7   0   0  14]
 [  2   4   1   1 133  15   5   6  63   3   3  11   6  19   3]
 [  1   3   0   2  16  75   0   5   4   1   9   1   0   2   0]
 [  3   2   4   3   8   3 150   2  29   2  12  10   0   3   3]
 [  5  22   3   5   9   2   1 114  16   3   2   7   0   7   4]
 [  0   1   5   4  63   3  14  16 189   8   3  14   1   6  29]
 [  2   6   5   3   4   0   3   2   8  94   1  77   0   3  12]
 [  3  16   9   3   3   7  10   7   3   4  83  15   0  19   3]
 [  9   7  10   7   9   4   2   6   8  30  19 167   0   5   3]
 [  0   0   0   0   5   0   0   0   1   0   0   0   6   0   0]
 [  4   5   2   2  17   2   3   3   5   0   5   2   0  98   1]
 [  2   2  14   3   0   1   0   1  15   2   4   4   0   1 129]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.33      0.47      0.39        60
           1       0.51      0.51      0.51       225
           2       0.59      0.53      0.55       280
           3       0.78      0.71      0.74       221
           4       0.47      0.48      0.48       275
           5       0.65      0.63      0.64       119
           6       0.76      0.64      0.69       234
           7       0.57      0.57      0.57       200
           8       0.53      0.53      0.53       356
           9       0.60      0.43      0.50       220
          10       0.49      0.45      0.47       185
          11       0.49      0.58      0.53       286
          12       0.46      0.50      0.48        12
          13       0.53      0.66      0.59       149
          14       0.57      0.72      0.64       178

    accuracy                           0.56      3000
   macro avg       0.56      0.56      0.55      3000
weighted avg       0.57      0.56      0.56      3000

The epoch:0,marcoF1ScoresTotal:0.619167
save the pretrainModel in /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_26_10_5/save_model/roberta_best_dev_f1_0.6191672690788604.pt and the classifierModel in /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_26_10_5/save_model/classifier_best_dev_f1_0.6191672690788604.pt
best epoch is:0 with best f1 is: 0.619167
*********************************************train model**************************************
current epoch:1
[ 1000 - th batch: valid loss is 0.635741 valid total precise is 0.703704 ]
[ 2000 - th batch: valid loss is 0.588800 valid total precise is 0.708504 ]
[ 3000 - th batch: valid loss is 0.575698 valid total precise is 0.708469 ]
[ 4000 - th batch: valid loss is 0.567658 valid total precise is 0.708152 ]
[ 5000 - th batch: valid loss is 0.561949 valid total precise is 0.706741 ]
[ 6000 - th batch: valid loss is 0.559210 valid total precise is 0.705568 ]
[ 7000 - th batch: valid loss is 0.557865 valid total precise is 0.704401 ]
[ 8000 - th batch: valid loss is 0.555226 valid total precise is 0.703813 ]
[ 9000 - th batch: valid loss is 0.553358 valid total precise is 0.703567 ]
[ 10000 - th batch: valid loss is 0.552964 valid total precise is 0.702720 ]
[ 11000 - th batch: valid loss is 0.551300 valid total precise is 0.702946 ]
[ 12000 - th batch: valid loss is 0.550470 valid total precise is 0.702700 ]
[ 13000 - th batch: valid loss is 0.550025 valid total precise is 0.702454 ]
[ 14000 - th batch: valid loss is 0.550195 valid total precise is 0.701836 ]
The epoch:1,marcoF1ScoresOcemotion:0.574797
********************************confusion_matrix********************************
[[1703  403   16  251   58 1314   38]
 [ 471 1882   11  395   92 1152   28]
 [  25   31  233   42   27  189    1]
 [ 156  239   12 6388  530  846   29]
 [  60   71    5  843 2085  663    7]
 [ 642  490   33  581  325 9476   21]
 [ 117   66    4  144   44  243  212]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.54      0.45      0.49      3783
           1       0.59      0.47      0.52      4031
           2       0.74      0.43      0.54       548
           3       0.74      0.78      0.76      8200
           4       0.66      0.56      0.60      3734
           5       0.68      0.82      0.74     11568
           6       0.63      0.26      0.36       830

    accuracy                           0.67     32694
   macro avg       0.65      0.54      0.57     32694
weighted avg       0.67      0.67      0.66     32694

The epoch:1,marcoF1ScoresOcnli:0.811801
********************************confusion_matrix********************************
[[13866  2187   662]
 [ 2300 13223  1761]
 [  771  1840 13777]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.82      0.83      0.82     16715
           1       0.77      0.77      0.77     17284
           2       0.85      0.84      0.85     16388

    accuracy                           0.81     50387
   macro avg       0.81      0.81      0.81     50387
weighted avg       0.81      0.81      0.81     50387

The epoch:1,marcoF1ScoresTnews:0.612832
********************************confusion_matrix********************************
[[ 703  105  172    4   12   15   21   33    8   13   23   61    0   83
    13]
 [  62 3031  339   41   70   20   19  236   81   60  355  102    0  135
    41]
 [ 188  369 3697  221   47   29   52  168  132   95   79  211    0   71
   247]
 [  12   96  322 3410   53    9   60   85   49   62   51  110    0   23
   195]
 [  11   80   48   34 3273  257  136  156 1112   50  100  249   63  283
    29]
 [  22   40   20   11  255 1588   38   67   56   10  139   28    0   88
     4]
 [  23   77  116   45  155   36 3284   64  340   67  243  114    0   54
    57]
 [  33  296  138   75  116   50   43 2610  170   58   75   97    0   74
    48]
 [   5   46  114   30 1257   78  352  221 3923  135   57  143    8   78
   241]
 [  12  113  100   39   59    3   71   83  111 2336   73  983    0   35
   110]
 [  26  443  119   33   94   91  184   95   79   44 2044  345    0  248
    31]
 [  64  103  246   82  236   30   89  110  155  769  284 3177    1   81
    43]
 [   0    0    0    1  182    4    1    0   11    0    0    1   88    1
     1]
 [ 100  149   46    9  314   85   49   99   69   27  217   83    0 1971
    13]
 [  17   75  311  160   42    4   45   55  292  109   26   42    0   25
  2668]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.55      0.56      0.55      1266
           1       0.60      0.66      0.63      4592
           2       0.64      0.66      0.65      5606
           3       0.81      0.75      0.78      4537
           4       0.53      0.56      0.54      5881
           5       0.69      0.67      0.68      2366
           6       0.74      0.70      0.72      4675
           7       0.64      0.67      0.66      3883
           8       0.60      0.59      0.59      6688
           9       0.61      0.57      0.59      4128
          10       0.54      0.53      0.53      3876
          11       0.55      0.58      0.57      5470
          12       0.55      0.30      0.39       290
          13       0.61      0.61      0.61      3231
          14       0.71      0.69      0.70      3871

    accuracy                           0.63     60360
   macro avg       0.63      0.61      0.61     60360
weighted avg       0.63      0.63      0.63     60360

The epoch:1,marcoF1ScoresTotal:0.666477
*********************************************start valid model**************************************
The epoch:1,marcoF1ScoresOcemotion:0.494458
********************************confusion_matrix********************************
[[126  27   2  52   8 110   7]
 [ 56 133   1  87   3  90   4]
 [  0   4  16  11   3  12   0]
 [ 14  16   1 654  19  76   1]
 [  8   7   3 143 139  51   2]
 [ 69  47   8 156  41 712   3]
 [  7   4   0  29   0  18  20]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.45      0.38      0.41       332
           1       0.56      0.36      0.43       374
           2       0.52      0.35      0.42        46
           3       0.58      0.84      0.68       781
           4       0.65      0.39      0.49       353
           5       0.67      0.69      0.68      1036
           6       0.54      0.26      0.35        78

    accuracy                           0.60      3000
   macro avg       0.57      0.47      0.49      3000
weighted avg       0.60      0.60      0.58      3000

The epoch:1 ,marcoF1ScoresOcnli:0.790846
********************************confusion_matrix********************************
[[887  72  52]
 [200 647 154]
 [ 63  76 849]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.77      0.88      0.82      1011
           1       0.81      0.65      0.72      1001
           2       0.80      0.86      0.83       988

    accuracy                           0.79      3000
   macro avg       0.80      0.79      0.79      3000
weighted avg       0.80      0.79      0.79      3000

The epoch:1,marcoF1ScoresTnews:0.558833
********************************confusion_matrix********************************
[[ 19  11   8   0   0   0   1   5   0   1   2   5   0   7   1]
 [  5 136  20   1   2   3   0   6   3   4  23  11   0   8   3]
 [  5  34 150  11   0   2   3  11  11   6  10  19   0   3  15]
 [  0   5  13 165   3   1   5   4   3   2   3   7   0   0  10]
 [  1   7   2   1  97  16   4   3  82   2  12  19   4  23   2]
 [  0   2   1   1  11  74   1   4   5   1  16   2   0   1   0]
 [  2   3   2   2   6   4 151   3  25   3  19   9   0   4   1]
 [  4  25   4   5   6   1   3 104  21   4   6   7   0   8   2]
 [  0   1   7   6  44   1  16  12 216  12   6  12   1   4  18]
 [  1   8   6   5   3   0   2   1  11 100   1  72   0   4   6]
 [  1  18   8   3   0   4   3   4   3   3 117  12   0   9   0]
 [  3   8  11   2   4   3   2   8   8  47  21 163   0   5   1]
 [  0   0   0   0   6   0   0   0   1   0   0   0   5   0   0]
 [  1   6   2   2   8   2   5   2   8   0  15   4   0  94   0]
 [  1   3  15   4   2   1   0   3  18   4   4   4   0   1 118]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.44      0.32      0.37        60
           1       0.51      0.60      0.55       225
           2       0.60      0.54      0.57       280
           3       0.79      0.75      0.77       221
           4       0.51      0.35      0.42       275
           5       0.66      0.62      0.64       119
           6       0.77      0.65      0.70       234
           7       0.61      0.52      0.56       200
           8       0.52      0.61      0.56       356
           9       0.53      0.45      0.49       220
          10       0.46      0.63      0.53       185
          11       0.47      0.57      0.52       286
          12       0.50      0.42      0.45        12
          13       0.55      0.63      0.59       149
          14       0.67      0.66      0.66       178

    accuracy                           0.57      3000
   macro avg       0.57      0.55      0.56      3000
weighted avg       0.58      0.57      0.57      3000

The epoch:1,marcoF1ScoresTotal:0.614712
best epoch is:0 with best f1 is: 0.619167
*********************************************train model**************************************
current epoch:2
[ 1000 - th batch: valid loss is 0.276715 valid total precise is 0.778278 ]
[ 2000 - th batch: valid loss is 0.269142 valid total precise is 0.777239 ]
[ 3000 - th batch: valid loss is 0.265792 valid total precise is 0.778326 ]
[ 4000 - th batch: valid loss is 0.262750 valid total precise is 0.777844 ]
[ 5000 - th batch: valid loss is 0.259494 valid total precise is 0.778516 ]
[ 6000 - th batch: valid loss is 0.259434 valid total precise is 0.777313 ]
[ 7000 - th batch: valid loss is 0.259031 valid total precise is 0.776011 ]
[ 8000 - th batch: valid loss is 0.259411 valid total precise is 0.774834 ]
[ 9000 - th batch: valid loss is 0.260369 valid total precise is 0.773353 ]
[ 10000 - th batch: valid loss is 0.260728 valid total precise is 0.772427 ]
[ 11000 - th batch: valid loss is 0.261519 valid total precise is 0.771297 ]
[ 12000 - th batch: valid loss is 0.262091 valid total precise is 0.770948 ]
[ 13000 - th batch: valid loss is 0.262314 valid total precise is 0.770721 ]
[ 14000 - th batch: valid loss is 0.262907 valid total precise is 0.769862 ]
The epoch:2,marcoF1ScoresOcemotion:0.686570
********************************confusion_matrix********************************
[[2206  357   12  175   43  949   41]
 [ 418 2433    8  254   55  829   34]
 [  24   25  297   20   33  147    2]
 [ 114  196   10 6971  402  480   27]
 [  36   57    6  608 2605  411   11]
 [ 577  429   29  344  242 9932   15]
 [ 109   69    2  113   36  154  347]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.63      0.58      0.61      3783
           1       0.68      0.60      0.64      4031
           2       0.82      0.54      0.65       548
           3       0.82      0.85      0.84      8200
           4       0.76      0.70      0.73      3734
           5       0.77      0.86      0.81     11568
           6       0.73      0.42      0.53       830

    accuracy                           0.76     32694
   macro avg       0.74      0.65      0.69     32694
weighted avg       0.76      0.76      0.75     32694

The epoch:2,marcoF1ScoresOcnli:0.850630
********************************confusion_matrix********************************
[[14435  1809   471]
 [ 1886 14039  1359]
 [  586  1450 14352]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.85      0.86      0.86     16715
           1       0.81      0.81      0.81     17284
           2       0.89      0.88      0.88     16388

    accuracy                           0.85     50387
   macro avg       0.85      0.85      0.85     50387
weighted avg       0.85      0.85      0.85     50387

The epoch:2,marcoF1ScoresTnews:0.700257
********************************confusion_matrix********************************
[[ 842   86  142    2    6    5   15   17    8    9   19   47    0   56
    12]
 [  57 3438  226   26   47   18   16  191   44   54  274   77    0   95
    29]
 [ 156  296 4158  165   32   22   42  103   88   76   67  174    0   37
   190]
 [   6   75  254 3702   41    9   39   75   23   43   49   70    1   13
   137]
 [   7   49   30   24 3721  208   89  111 1022   39   72  207   64  219
    19]
 [  12   30   18    7  228 1761   25   43   45    3   97   31    0   64
     2]
 [  22   59   87   25  110   24 3586   42  279   57  208   98    0   43
    35]
 [  23  235  102   53   91   42   24 2920  120   46   63   78    0   58
    28]
 [   4   42   83   21 1129   54  272  144 4435  102   37  112    7   61
   185]
 [  11   76   71   37   55    3   55   67   90 2665   45  847    0   23
    83]
 [  24  358   79   32   69   73  139   59   49   35 2468  277    0  187
    27]
 [  47   85  163   53  222   21   88   81   96  647  231 3671    0   50
    15]
 [   0    0    0    0  146    2    2    0    8    0    0    2  130    0
     0]
 [  69  100   30    8  257   64   28   64   50   24  181   61    0 2286
     9]
 [  10   51  236  110   28    2   37   38  206  101   21   31    0   14
  2986]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.65      0.67      0.66      1266
           1       0.69      0.75      0.72      4592
           2       0.73      0.74      0.74      5606
           3       0.87      0.82      0.84      4537
           4       0.60      0.63      0.62      5881
           5       0.76      0.74      0.75      2366
           6       0.80      0.77      0.79      4675
           7       0.74      0.75      0.75      3883
           8       0.68      0.66      0.67      6688
           9       0.68      0.65      0.66      4128
          10       0.64      0.64      0.64      3876
          11       0.63      0.67      0.65      5470
          12       0.64      0.45      0.53       290
          13       0.71      0.71      0.71      3231
          14       0.79      0.77      0.78      3871

    accuracy                           0.71     60360
   macro avg       0.71      0.69      0.70     60360
weighted avg       0.71      0.71      0.71     60360

The epoch:2,marcoF1ScoresTotal:0.745819
*********************************************start valid model**************************************
The epoch:2,marcoF1ScoresOcemotion:0.502127
********************************confusion_matrix********************************
[[142  18   2  23  18 123   6]
 [ 67 136   1  41  12 110   7]
 [  2   2  16   6   6  14   0]
 [ 27  18   1 547  71 116   1]
 [ 15   4   2  70 184  75   3]
 [ 84  43   8  48  56 791   6]
 [ 15   7   1  18   4  15  18]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.40      0.43      0.42       332
           1       0.60      0.36      0.45       374
           2       0.52      0.35      0.42        46
           3       0.73      0.70      0.71       781
           4       0.52      0.52      0.52       353
           5       0.64      0.76      0.69      1036
           6       0.44      0.23      0.30        78

    accuracy                           0.61      3000
   macro avg       0.55      0.48      0.50      3000
weighted avg       0.61      0.61      0.60      3000

The epoch:2 ,marcoF1ScoresOcnli:0.805046
********************************confusion_matrix********************************
[[866  91  54]
 [163 713 125]
 [ 46 102 840]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.81      0.86      0.83      1011
           1       0.79      0.71      0.75      1001
           2       0.82      0.85      0.84       988

    accuracy                           0.81      3000
   macro avg       0.81      0.81      0.81      3000
weighted avg       0.81      0.81      0.80      3000

The epoch:2,marcoF1ScoresTnews:0.570187
********************************confusion_matrix********************************
[[ 20  11   8   2   0   1   3   4   0   1   2   1   0   4   3]
 [  4 132  28   1   2   5   0   9   7   3  15   4   0  12   3]
 [  4  27 163   9   1   3   6  10  12   6   7  16   0   3  13]
 [  0   7  11 165   5   2   5   2   3   3   1   5   0   0  12]
 [  1   2   3   0 123  20   3   1  76   3   7  15   6  12   3]
 [  0   2   1   1  13  86   1   3   4   0   6   1   0   1   0]
 [  2   4   2   4   7   6 142   5  30   3  13   9   0   5   2]
 [  4  23   3   7   7   5   1 101  22   5   2   9   0   7   4]
 [  0   0   6   4  45   6  14   8 226   9   5  11   2   2  18]
 [  1   8   6   3   4   0   2   1  15 133   1  35   0   3   8]
 [  3  18   8   5   5  10   6   5   4   3  85  14   0  19   0]
 [  4   8  14   4   8   4   1   7  11  57  12 150   0   6   0]
 [  0   0   0   0   3   0   0   0   1   0   0   0   8   0   0]
 [  1   5   3   1  17  11   2   2   9   1   8   4   0  83   2]
 [  2   3  15   2   3   2   1   1  18   5   3   3   0   2 118]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.43      0.33      0.38        60
           1       0.53      0.59      0.56       225
           2       0.60      0.58      0.59       280
           3       0.79      0.75      0.77       221
           4       0.51      0.45      0.47       275
           5       0.53      0.72      0.61       119
           6       0.76      0.61      0.67       234
           7       0.64      0.51      0.56       200
           8       0.52      0.63      0.57       356
           9       0.57      0.60      0.59       220
          10       0.51      0.46      0.48       185
          11       0.54      0.52      0.53       286
          12       0.50      0.67      0.57        12
          13       0.52      0.56      0.54       149
          14       0.63      0.66      0.65       178

    accuracy                           0.58      3000
   macro avg       0.57      0.58      0.57      3000
weighted avg       0.58      0.58      0.58      3000

The epoch:2,marcoF1ScoresTotal:0.625787
save the pretrainModel in /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_26_10_5/save_model/roberta_best_dev_f1_0.6257867795149347.pt and the classifierModel in /share/home/crazicoco/competition/CPFC/record_analysis/2020_12_26_10_5/save_model/classifier_best_dev_f1_0.6257867795149347.pt
best epoch is:2 with best f1 is: 0.625787
*********************************************train model**************************************
current epoch:3
[ 1000 - th batch: valid loss is 0.108144 valid total precise is 0.840440 ]
[ 2000 - th batch: valid loss is 0.103379 valid total precise is 0.844722 ]
[ 3000 - th batch: valid loss is 0.101691 valid total precise is 0.844848 ]
[ 4000 - th batch: valid loss is 0.098849 valid total precise is 0.846312 ]
[ 5000 - th batch: valid loss is 0.096904 valid total precise is 0.847029 ]
[ 6000 - th batch: valid loss is 0.095335 valid total precise is 0.847891 ]
[ 7000 - th batch: valid loss is 0.094590 valid total precise is 0.846535 ]
[ 8000 - th batch: valid loss is 0.094168 valid total precise is 0.845806 ]
[ 9000 - th batch: valid loss is 0.093665 valid total precise is 0.845938 ]
[ 10000 - th batch: valid loss is 0.093195 valid total precise is 0.845975 ]
[ 11000 - th batch: valid loss is 0.092927 valid total precise is 0.845777 ]
[ 12000 - th batch: valid loss is 0.092826 valid total precise is 0.845295 ]
[ 13000 - th batch: valid loss is 0.092951 valid total precise is 0.844119 ]
[ 14000 - th batch: valid loss is 0.093262 valid total precise is 0.843232 ]
The epoch:3,marcoF1ScoresOcemotion:0.809068
********************************confusion_matrix********************************
[[ 2811   251     9    82    28   569    33]
 [  320  3105     7   123    31   428    17]
 [   18    23   370    14    22    99     2]
 [   60   118    11  7535   236   224    16]
 [   16    30     2   344  3146   188     8]
 [  381   259    14   141   120 10635    18]
 [  104    50     1    64    27    96   488]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.76      0.74      0.75      3783
           1       0.81      0.77      0.79      4031
           2       0.89      0.68      0.77       548
           3       0.91      0.92      0.91      8200
           4       0.87      0.84      0.86      3734
           5       0.87      0.92      0.89     11568
           6       0.84      0.59      0.69       830

    accuracy                           0.86     32694
   macro avg       0.85      0.78      0.81     32694
weighted avg       0.86      0.86      0.86     32694

The epoch:3,marcoF1ScoresOcnli:0.885312
********************************confusion_matrix********************************
[[14979  1396   340]
 [ 1477 14780  1027]
 [  424  1143 14821]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.89      0.90      0.89     16715
           1       0.85      0.86      0.85     17284
           2       0.92      0.90      0.91     16388

    accuracy                           0.88     50387
   macro avg       0.89      0.89      0.89     50387
weighted avg       0.88      0.88      0.88     50387

The epoch:3,marcoF1ScoresTnews:0.796634
********************************confusion_matrix********************************
[[ 972   64  109    4    5    4    6   12    3    4   12   18    0   42
    11]
 [  39 3864  169   15   28    9    8  108   29   24  190   38    1   59
    11]
 [  97  196 4658  116   20   18   24   70   62   42   45  110    0   33
   115]
 [   1   50  144 4002   25    3   28   39   23   40   38   53    1    8
    82]
 [   5   35   23   16 4313  151   52   59  786   29   51  150   41  159
    11]
 [   8   18   14    5  158 1967   26   29   24    2   66   20    0   29
     0]
 [  11   39   57   20   69   14 3908   27  202   38  168   57    0   40
    25]
 [  12  142   70   35   60   23   13 3274   76   24   51   50    1   33
    19]
 [   4   23   51    9  854   33  188  104 5080   62   28   92    6   32
   122]
 [   8   52   38   25   27    0   41   37   71 3030   44  681    0   21
    53]
 [  15  236   39   12   51   53  106   39   29   22 2961  185    0  121
     7]
 [  27   46  117   31  136   18   40   53   77  574  170 4134    0   32
    15]
 [   0    0    0    0   96    3    0    0    7    0    0    0  184    0
     0]
 [  47   55   17    1  173   37   25   45   42   16  117   29    0 2619
     8]
 [   9   23  145   72   20    3   30   25  151   70   13   21    0   12
  3277]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.77      0.77      0.77      1266
           1       0.80      0.84      0.82      4592
           2       0.82      0.83      0.83      5606
           3       0.92      0.88      0.90      4537
           4       0.71      0.73      0.72      5881
           5       0.84      0.83      0.84      2366
           6       0.87      0.84      0.85      4675
           7       0.83      0.84      0.84      3883
           8       0.76      0.76      0.76      6688
           9       0.76      0.73      0.75      4128
          10       0.75      0.76      0.76      3876
          11       0.73      0.76      0.74      5470
          12       0.79      0.63      0.70       290
          13       0.81      0.81      0.81      3231
          14       0.87      0.85      0.86      3871

    accuracy                           0.80     60360
   macro avg       0.80      0.79      0.80     60360
weighted avg       0.80      0.80      0.80     60360

The epoch:3,marcoF1ScoresTotal:0.830338
*********************************************start valid model**************************************
The epoch:3,marcoF1ScoresOcemotion:0.483082
********************************confusion_matrix********************************
[[110  50   2  27  10 119  14]
 [ 35 177   1  37  10 102  12]
 [  1   5  13   6   6  14   1]
 [ 20  42   1 567  54  88   9]
 [ 12  15   3  82 166  68   7]
 [ 52 103   6  70  62 732  11]
 [ 10   9   1  19   4  12  23]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.46      0.33      0.38       332
           1       0.44      0.47      0.46       374
           2       0.48      0.28      0.36        46
           3       0.70      0.73      0.71       781
           4       0.53      0.47      0.50       353
           5       0.64      0.71      0.67      1036
           6       0.30      0.29      0.30        78

    accuracy                           0.60      3000
   macro avg       0.51      0.47      0.48      3000
weighted avg       0.59      0.60      0.59      3000

The epoch:3 ,marcoF1ScoresOcnli:0.797846
********************************confusion_matrix********************************
[[841 111  59]
 [139 709 153]
 [ 38 103 847]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.83      0.83      0.83      1011
           1       0.77      0.71      0.74      1001
           2       0.80      0.86      0.83       988

    accuracy                           0.80      3000
   macro avg       0.80      0.80      0.80      3000
weighted avg       0.80      0.80      0.80      3000

The epoch:3,marcoF1ScoresTnews:0.579694
********************************confusion_matrix********************************
[[ 27  11   4   1   0   0   3   3   0   1   2   3   0   4   1]
 [  5 140  16   4   5   2   2   6   5   3  15   7   0  12   3]
 [  9  35 147  12   4   2   8   9  15   3   6  17   0   2  11]
 [  0   5  12 177   2   1   7   1   3   0   0   8   0   0   5]
 [  1   6   2   0 135  13   6   4  57   0   7  19   6  16   3]
 [  0   3   1   1  12  77   4   3   6   0  10   1   0   1   0]
 [  2   6   1   5  11   3 154   2  25   0  13   5   0   5   2]
 [  6  27   3   9   5   2   2 107  14   4   0   8   0   9   4]
 [  0   2   5   8  69   1  16  12 201   4   6  10   0   5  17]
 [  1  11   5   4   6   0   4   1  15 101   2  59   0   3   8]
 [  3  23   6   4   6   4  10   3   3   2  90  11   0  19   1]
 [  5  11   6   5  11   2   5   5   9  30  16 174   0   6   1]
 [  0   0   0   0   3   0   0   0   1   0   0   0   8   0   0]
 [  1   6   2   1  13   8   6   4   8   0   9   4   0  87   0]
 [  2   4  13   7   4   1   1   1  18   4   5   3   0   2 113]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           0       0.44      0.45      0.44        60
           1       0.48      0.62      0.54       225
           2       0.66      0.53      0.58       280
           3       0.74      0.80      0.77       221
           4       0.47      0.49      0.48       275
           5       0.66      0.65      0.66       119
           6       0.68      0.66      0.67       234
           7       0.66      0.54      0.59       200
           8       0.53      0.56      0.55       356
           9       0.66      0.46      0.54       220
          10       0.50      0.49      0.49       185
          11       0.53      0.61      0.57       286
          12       0.57      0.67      0.62        12
          13       0.51      0.58      0.54       149
          14       0.67      0.63      0.65       178

    accuracy                           0.58      3000
   macro avg       0.58      0.58      0.58      3000
weighted avg       0.59      0.58      0.58      3000

The epoch:3,marcoF1ScoresTotal:0.620207
best epoch is:2 with best f1 is: 0.625787
*********************************************train model**************************************
current epoch:4
